{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eMQ9LKrNcHA",
        "outputId": "0d87f033-f1a6-4586-eb47-58a039f7f506"
      },
      "source": [
        "!pip install dm_env\n",
        "! pip install bsuite\n",
        "! pip install dm-env\n",
        "! pip install jax\n",
        "! pip install rlax\n",
        "! pip install git+https://github.com/deepmind/dm-haiku\n",
        "! pip install optax\n",
        "! pip install colabtools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dm_env in /usr/local/lib/python3.7/dist-packages (1.5)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from dm_env) (0.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from dm_env) (1.19.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from dm_env) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->dm_env) (1.15.0)\n",
            "Requirement already satisfied: bsuite in /usr/local/lib/python3.7/dist-packages (0.3.5)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from bsuite) (0.16.2)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.7/dist-packages (from bsuite) (2.0.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bsuite) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bsuite) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bsuite) (1.4.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from bsuite) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bsuite) (1.19.5)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from bsuite) (0.17.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from bsuite) (0.12.0)\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.7/dist-packages (from bsuite) (1.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from bsuite) (1.1.5)\n",
            "Requirement already satisfied: plotnine in /usr/local/lib/python3.7/dist-packages (from bsuite) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from dm-env->bsuite) (0.1.6)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->bsuite) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->bsuite) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->bsuite) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bsuite) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bsuite) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bsuite) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bsuite) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->bsuite) (2018.9)\n",
            "Requirement already satisfied: mizani>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->bsuite) (0.6.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->bsuite) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from plotnine->bsuite) (0.5.1)\n",
            "Requirement already satisfied: descartes>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->bsuite) (1.1.0)\n",
            "Requirement already satisfied: palettable in /usr/local/lib/python3.7/dist-packages (from mizani>=0.6.0->plotnine->bsuite) (3.3.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->bsuite) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->bsuite) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->bsuite) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->bsuite) (2.6.2)\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.7/dist-packages (1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from dm-env) (1.19.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from dm-env) (0.12.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from dm-env) (0.1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->dm-env) (1.15.0)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (0.2.19)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from jax) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax) (1.15.0)\n",
            "Requirement already satisfied: rlax in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rlax) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from rlax) (1.19.5)\n",
            "Requirement already satisfied: chex>=0.0.8 in /usr/local/lib/python3.7/dist-packages (from rlax) (0.0.8)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from rlax) (0.1.70+cuda110)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from rlax) (0.2.19)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.9.0->rlax) (1.15.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.8->rlax) (0.1.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.8->rlax) (0.11.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->rlax) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->rlax) (1.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->rlax) (1.4.1)\n",
            "Collecting git+https://github.com/deepmind/dm-haiku\n",
            "  Cloning https://github.com/deepmind/dm-haiku to /tmp/pip-req-build-h5c1wy5n\n",
            "  Running command git clone -q https://github.com/deepmind/dm-haiku /tmp/pip-req-build-h5c1wy5n\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (0.12.0)\n",
            "Requirement already satisfied: jmp>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (0.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (1.19.5)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (0.8.9)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.5.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->dm-haiku==0.0.5.dev0) (1.15.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (0.0.9)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax) (0.0.8)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.1.70+cuda110)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from optax) (1.19.5)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.2.19)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->optax) (1.15.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.11.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax) (1.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax) (1.4.1)\n",
            "Requirement already satisfied: colabtools in /usr/local/lib/python3.7/dist-packages (0.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSGsXEd4sOu7",
        "outputId": "588bd4d9-7d7d-4704-ec36-8f7aba8e4b04"
      },
      "source": [
        "! pip install colabtools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: colabtools in /usr/local/lib/python3.7/dist-packages (0.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT4NeklL7BZi"
      },
      "source": [
        "#@title imports\n",
        "from google.colab import files\n",
        "import colabtools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib.patches import Rectangle, Polygon\n",
        "from IPython.display import clear_output\n",
        "%matplotlib inline\n",
        "# from colabtools import adhoc_import\n",
        "import dm_env\n",
        "from collections import defaultdict\n",
        "\n",
        "import functools\n",
        "import collections\n",
        "\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "\n",
        "Environment = collections.namedtuple('Environment', 'step reset')\n",
        "\n",
        "tmap = jax.tree_multimap\n",
        "treduce = jax.tree_util.tree_reduce\n",
        "\n",
        "\n",
        "import functools\n",
        "\n",
        "from typing import Any, Callable, Mapping, NamedTuple, Tuple\n",
        "\n",
        "import dm_env\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "# import ml_collections\n",
        "import rlax\n",
        "\n",
        "tmap = jax.tree_multimap\n",
        "add = lambda x, y: x + y\n",
        "tree_add = lambda x, y: tmap(add, x, y)\n",
        "tree_sub = lambda x, y: tmap(lambda x, y: x - y, x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LiaoTMGNtsw",
        "cellView": "code"
      },
      "source": [
        "#@title TD(lambda) agent\n",
        "\n",
        "class Agent(NamedTuple):\n",
        "  step: Callable[..., Any]\n",
        "  first_step: Callable[..., Any]\n",
        "  get_v: Callable[..., Any]\n",
        "  get_mu: Callable[..., Any]\n",
        "  get_pi: Callable[..., Any]\n",
        "  get_f: Callable[..., Any]\n",
        "\n",
        "class AgentState(NamedTuple):\n",
        "\n",
        "  \"\"\"Agent state.\"\"\"\n",
        "  rng_key: jnp.ndarray\n",
        "  w_v: Any\n",
        "  w_z: Any\n",
        "  w_x: Any\n",
        "  e_v: Any\n",
        "  e_x: Any\n",
        "  e_z: Any\n",
        "  v_opt_state: Any\n",
        "  x_opt_state: Any\n",
        "  z_opt_state: Any\n",
        "  f_opt_state: Any\n",
        "  trace_decay: float\n",
        "  obs: Any\n",
        "  action: Any\n",
        "  f: Any\n",
        "  w_f: Any\n",
        "  e_f: Any\n",
        "  followon_decay: Any\n",
        "\n",
        "def get_config(agent_name, env_id, hyper):\n",
        "  \"\"\"Hyper-parameters for this agent.\"\"\"\n",
        "  config = {}\n",
        "  config[\"init\"] = init\n",
        "  config[\"cfg\"] = {}\n",
        "  config[\"cfg\"][\"discount\"] = hyper[\"discount\"]#1.\n",
        "  config[\"cfg\"][\"trace_parameter\"] = hyper[\"lambda\"] #0.\n",
        "\n",
        "  config[\"cfg\"][\"v_optimiser_kwargs\"] = {}\n",
        "  config[\"cfg\"][\"v_optimiser_kwargs\"][\"learning_rate\"] = hyper[\"alpha_v\"]\n",
        "  config[\"cfg\"][\"v_optimiser_kwargs\"][\"b1\"] = 0.9\n",
        "  config[\"cfg\"][\"v_optimiser_kwargs\"][\"b2\"] = 0.999\n",
        "  config[\"cfg\"][\"v_optimiser_kwargs\"][\"eps\"] = 1e-4\n",
        "  config[\"cfg\"][\"v_optimiser_kwargs\"][\"momentum\"] = 0.9\n",
        "  config[\"cfg\"][\"v_optimiser_kwargs\"][\"d\"] = hyper[\"d\"]\n",
        "\n",
        "  config[\"cfg\"][\"f_optimiser_kwargs\"] = {}\n",
        "  config[\"cfg\"][\"f_optimiser_kwargs\"][\"learning_rate\"] = hyper[\"alpha_f\"]\n",
        "  config[\"cfg\"][\"f_optimiser_kwargs\"][\"b1\"] = 0.9\n",
        "  config[\"cfg\"][\"f_optimiser_kwargs\"][\"b2\"] = 0.999\n",
        "  config[\"cfg\"][\"f_optimiser_kwargs\"][\"eps\"] = 1e-4\n",
        "  config[\"cfg\"][\"f_optimiser_kwargs\"][\"momentum\"] = 0.9\n",
        "  config[\"cfg\"][\"f_optimiser_kwargs\"][\"d\"] = hyper[\"df\"]\n",
        "\n",
        "  config[\"cfg\"][\"z_optimiser_kwargs\"] = {}\n",
        "  config[\"cfg\"][\"z_optimiser_kwargs\"][\"learning_rate\"] = hyper[\"alpha_z\"]\n",
        "  config[\"cfg\"][\"z_optimiser_kwargs\"][\"b1\"] = 0.9\n",
        "  config[\"cfg\"][\"z_optimiser_kwargs\"][\"b2\"] = 0.999\n",
        "  config[\"cfg\"][\"z_optimiser_kwargs\"][\"eps\"] = 1e-4\n",
        "  config[\"cfg\"][\"z_optimiser_kwargs\"][\"momentum\"] = 0.9\n",
        "  config[\"cfg\"][\"z_optimiser_kwargs\"][\"d\"] = hyper[\"dz\"]\n",
        "\n",
        "  if env_id == \"FiveStateMDP\" or env_id == \"TabularFiveStateMDP\":\n",
        "    config[\"cfg\"][\"pi\"] = [0., 1.] # left, right\n",
        "    config[\"cfg\"][\"mu\"] = [0.66, 0.33] # left, right\n",
        "    config[\"cfg\"][\"use_special_v_param_init\"] = False\n",
        "  else:\n",
        "    config[\"cfg\"][\"pi\"] = [1., 0.] # solid, dashed\n",
        "    config[\"cfg\"][\"mu\"] = [1/6, 5/6] # solid, dashed\n",
        "    config[\"cfg\"][\"use_special_v_param_init\"] = True\n",
        "\n",
        "  # Default is the td\n",
        "  config[\"cfg\"][\"use_post_corr\"] = False\n",
        "  config[\"cfg\"][\"use_prior_corr\"] = False\n",
        "  config[\"cfg\"][\"nonlinear_et\"] = False\n",
        "  config[\"cfg\"][\"eta_f\"] = 1. # use instantaneous emphasis\n",
        "  config[\"cfg\"][\"eta_x_f\"] = 1.\n",
        "  config[\"cfg\"][\"eta_v\"] = 1.\n",
        "  config[\"cfg\"][\"eta_z\"] = 1.\n",
        "  config[\"cfg\"][\"c_f\"] = np.inf\n",
        "  config[\"cfg\"][\"beta\"] = hyper[\"beta\"]\n",
        "  config[\"cfg\"][\"positive_followon\"] = hyper[\"positive_followon\"]\n",
        "\n",
        "  config[\"cfg\"][\"nonlinear_et\"] = False\n",
        "\n",
        "  if agent_name.endswith(\"ET(0)\"):\n",
        "    config[\"cfg\"][\"eta_v\"] = 0. # use expected traces\n",
        "    config[\"cfg\"][\"eta_z\"] = 0. # learn expected traces with td\n",
        "  if agent_name.endswith(\"ET(1)\"):\n",
        "    config[\"cfg\"][\"eta_v\"] = 0. # use expected traces\n",
        "    config[\"cfg\"][\"eta_z\"] = 1. # learn expected traces with mc\n",
        "\n",
        "  if agent_name.startswith(\"Off\"):\n",
        "    config[\"cfg\"][\"use_post_corr\"] = True\n",
        "\n",
        "  if agent_name.startswith(\"ETD\") or agent_name.startswith(\"eet\"):\n",
        "    config[\"cfg\"][\"use_post_corr\"] = True # use posterior corrections -- importance sampling\n",
        "    config[\"cfg\"][\"use_prior_corr\"] = True # use prior corr -- distr corr w emphasis\n",
        "\n",
        "  if agent_name.startswith(\"X(1)-\"):\n",
        "    config[\"cfg\"][\"use_post_corr\"] = True # use posterior corrections -- importance sampling\n",
        "    config[\"cfg\"][\"use_prior_corr\"] = True # use prior corr -- distr corr w emphasis\n",
        "    config[\"cfg\"][\"eta_f\"] = 0. # use expected emphasis\n",
        "    config[\"cfg\"][\"eta_x_f\"] = 1. # learn emphasis through mc\n",
        "\n",
        "  if agent_name.startswith(\"X(0)-\"):\n",
        "    config[\"cfg\"][\"use_post_corr\"] = True # use posterior corrections -- importance sampling\n",
        "    config[\"cfg\"][\"use_prior_corr\"] = True # use prior corr -- distr corr w emphasis\n",
        "    config[\"cfg\"][\"eta_f\"] = 0. # use expected emphasis\n",
        "    config[\"cfg\"][\"eta_x_f\"] = 0. # learn emphasis through td\n",
        "\n",
        "#   if agent_name.startswith(\"eta_x\"):\n",
        "#     config[\"cfg\"].use_post_corr = True # use posterior corrections -- importance sampling\n",
        "#     config[\"cfg\"].use_prior_corr = True # use prior corr -- distr corr w emphasis\n",
        "#     config[\"cfg\"].eta_f = eta # use expected emphasis with eta else instantaneous emphasis\n",
        "#     config[\"cfg\"].eta_x_f = 1. # learn emphasis through mc\n",
        "\n",
        "#   if clipped:\n",
        "#     config[\"cfg\"][\"c_f\"] = 1.\n",
        "\n",
        "  return config\n",
        "\n",
        "#@title Default title text\n",
        "def first_step(\n",
        "    timestep: dm_env.TimeStep,\n",
        "    agent_state: AgentState,\n",
        "    policy: Callable[..., Any],\n",
        ") -> Tuple[Any, AgentState]:\n",
        "  rng_key, policy_key = jax.random.split(agent_state.rng_key)\n",
        "  action = policy(policy_key, timestep.observation, agent_state)\n",
        "  agent_state = agent_state._replace(\n",
        "      rng_key=rng_key, obs=timestep.observation, action=action)\n",
        "  return action, agent_state\n",
        "\n",
        "\n",
        "def step(\n",
        "    # stateful things\n",
        "    timestep: dm_env.TimeStep,\n",
        "    agent_state: AgentState,\n",
        "    # functions\n",
        "    x_scale_fn: Callable[..., Any],\n",
        "    v_scale_fn: Callable[..., Any],\n",
        "    z_scale_fn: Callable[..., Any],\n",
        "    x_fn: Callable[..., Any],\n",
        "    v_fn: Callable[..., Any],\n",
        "    dv_fn: Callable[..., Any],\n",
        "    z_fn: Callable[..., Any],\n",
        "    dzloss_fn: Callable[..., Any],\n",
        "    policy: Callable[..., Any],\n",
        "    f_scale_fn: Callable[..., Any],\n",
        "    f_fn: Callable[..., Any],\n",
        "    df_fn: Callable[..., Any],\n",
        "    rho_fn: Callable[..., Any],\n",
        "    # hyper-parameters\n",
        "    discount: float,\n",
        "    trace_parameter: float,\n",
        "    eta_v: float,\n",
        "    eta_z: float,\n",
        "    eta_f: float,\n",
        "    eta_x_f: float,\n",
        "    beta: float,\n",
        "    use_prior_corr: bool,\n",
        ") -> Tuple[Any, AgentState, Mapping[str, Any]]:  # hyper-parameters\n",
        "  \"\"\"One step of the agent.\"\"\"\n",
        "  # Map action structure to an int\n",
        "  action = jax.tree_leaves(agent_state.action)[0]\n",
        "  reward = timestep.reward\n",
        "  discount = timestep.discount * discount\n",
        "  next_obs = timestep.observation\n",
        "  episode_end = timestep.last()\n",
        "  (f, e_f, e_v,\n",
        "   e_x, e_z) = (agent_state.f, agent_state.e_f, agent_state.e_v,\n",
        "                agent_state.e_x, agent_state.e_z )\n",
        "  x_f = 0\n",
        "  del timestep\n",
        "  trace_decay = agent_state.trace_decay\n",
        "  (w_v, w_x,\n",
        "   w_z, w_f)  = (agent_state.w_v, agent_state.w_x,\n",
        "                    agent_state.w_z, agent_state.w_f)\n",
        "  obs = agent_state.obs\n",
        "  f_opt_state = agent_state.f_opt_state\n",
        "  rng_key, policy_key = jax.random.split(agent_state.rng_key)\n",
        "\n",
        "  ### Compute values\n",
        "  # Compute the features x(s)\n",
        "  x = x_fn(w_x, obs)\n",
        "  next_x = x_fn(w_x, next_obs)\n",
        "\n",
        "  # Compute value v(s)\n",
        "  v = v_fn(w_v, x)\n",
        "  # import pdb;pdb.set_trace()\n",
        "  # Compute gradient dv(s)/dw, d log pi(s, a)/dw\n",
        "  dv_head, dv_torso = dv_fn(w_v, w_x, obs)\n",
        "\n",
        "  # Compute v(s) at the next time step\n",
        "  v_next = v_fn(w_v, next_x)\n",
        "\n",
        "  rho_post, rho_prior = rho_fn(action)\n",
        "  # Pick new action\n",
        "  # We do this before updating the weights to avoid forwarding twice\n",
        "  rng_key, policy_key = jax.random.split(agent_state.rng_key)\n",
        "  a_next = policy(policy_key, next_obs, agent_state)\n",
        "\n",
        "  ### Expected trace\n",
        "  # Compute the expected trace: z(s) ~= E[ γ λ e_{t-1} | S_t=s ]\n",
        "  z = z_fn(w_z, x)\n",
        "  # Decay all traces\n",
        "  e_v, e_z, e_x = tmap(lambda e_i: trace_decay * e_i, (e_v, e_z, e_x))\n",
        "\n",
        "  # Compute update for the expected trace\n",
        "  zloss, dw_z = dzloss_fn(w_z, x, e_z)\n",
        "\n",
        "  # Compute mixture traces η γ λ e_{t-1} + (1 - η) z(S_t)\n",
        "  # Note: z(S_t) ~= E[ γ λ e_{t-1} | S_t ]\n",
        "  e_v = tmap(lambda e_i, z_i: eta_v * e_i + (1 - eta_v) * z_i, e_v, z)\n",
        "  e_z = tmap(lambda e_i, z_i: eta_z * e_i + (1 - eta_z) * z_i, e_z, z)\n",
        "\n",
        "  f_error = 0\n",
        "  if use_prior_corr:\n",
        "    # Decay all traces\n",
        "    e_f = agent_state.followon_decay * e_f\n",
        "    f = agent_state.followon_decay * f\n",
        "    # Compute expected follow-on\n",
        "    x_f = f_fn(w_f, obs)\n",
        "\n",
        "    # Learn expected follow-on\n",
        "    df = df_fn(w_f, w_x, obs)\n",
        "    f_error = e_f - x_f\n",
        "    dw_f =  tmap(lambda df_i: f_error * df_i, df)\n",
        "    dw_f, f_opt_state = f_scale_fn(dw_f, state=f_opt_state)\n",
        "    w_f = tmap(lambda x, y: x + y, w_f, dw_f)\n",
        "\n",
        "    # Compute the traces as eta interpolations between TD and MC\n",
        "    f = eta_f * f + (1 - eta_f) * x_f + 1\n",
        "    e_f = eta_x_f * e_f + (1 - eta_x_f) * x_f + 1\n",
        "\n",
        "  # Compute the actual emphasis from the follow-on\n",
        "  m = trace_parameter + (1 - trace_parameter) * f\n",
        "\n",
        "  ### Add gradient to traces\n",
        "  tree_add_weighted = lambda x, y, z: tmap(lambda x, y: x + y * z, x, y)\n",
        "  e_v = tree_add_weighted(e_v, dv_head, m)\n",
        "  e_z = tree_add_weighted(e_z, dv_head, m)\n",
        "  e_x = tree_add_weighted(e_x, dv_torso, m)\n",
        "\n",
        "  ### Update values\n",
        "  # Compute term that composes the multi-step λ return\n",
        "  r_plus_next_v = reward + (1 - trace_parameter) * discount * v_next\n",
        "  compute_dw = lambda e_i, dv_i: rho_post * (r_plus_next_v * e_i - v * dv_i * m)\n",
        "  # Compute update for the values\n",
        "  dw_v, dw_x = tmap(compute_dw, (e_v, e_x), (dv_head, dv_torso))\n",
        "  dw_v, v_opt_state = v_scale_fn(dw_v, state=agent_state.v_opt_state)\n",
        "  dw_x, x_opt_state = x_scale_fn(dw_x, state=agent_state.x_opt_state)\n",
        "  dw_z, z_opt_state = z_scale_fn(dw_z, state=agent_state.z_opt_state)\n",
        "\n",
        "  # Update weights\n",
        "  w_v = tmap(lambda x, y: x + y, w_v, dw_v)\n",
        "  w_x = tmap(lambda x, y: x + y, w_x, dw_x)\n",
        "  w_z = tree_sub(w_z, dw_z)  # subtract, for gradient descent\n",
        "\n",
        "  # import pdb; pdb.set_trace()\n",
        "  # Compute trace decay to apply at the next time step\n",
        "  trace_decay = discount * trace_parameter\n",
        "  trace_decay *= 1 - jnp.float32(episode_end)\n",
        "  followon_decay = rho_prior * jnp.minimum(discount, beta) * (1 - jnp.float32(episode_end))\n",
        "\n",
        "  # Add some things to log\n",
        "  log_dict = dict(v=v_next, f=f, e_f=e_f, x_f=x_f,\n",
        "                  zloss=zloss,\n",
        "                  rho_prior=rho_prior,\n",
        "                  rho_post=rho_post,\n",
        "                  discount=discount, f_td_or_mc_error=f_error,\n",
        "                  td_error=reward + discount * v_next - v)\n",
        "\n",
        "  # Assemble new agent state\n",
        "  agent_state = AgentState(\n",
        "      rng_key=rng_key,\n",
        "      w_v=w_v,\n",
        "      w_z=w_z,\n",
        "      w_x=w_x,\n",
        "      w_f=w_f,\n",
        "      e_v=e_v,\n",
        "      e_z=e_z,\n",
        "      e_x=e_x,\n",
        "      e_f=e_f,\n",
        "      f=f,\n",
        "      followon_decay=followon_decay,\n",
        "      trace_decay=trace_decay,\n",
        "      v_opt_state=v_opt_state,\n",
        "      f_opt_state=f_opt_state,\n",
        "      x_opt_state=x_opt_state,\n",
        "      z_opt_state=z_opt_state,\n",
        "      obs=next_obs,\n",
        "      action=a_next\n",
        "      )\n",
        "\n",
        "  return a_next, agent_state, log_dict\n",
        "\n",
        "\n",
        "def init(\n",
        "    rng_key: jnp.ndarray,\n",
        "    network_spec: str,\n",
        "    action_spec: Any,\n",
        "    observation_spec: Any,\n",
        "    discount: float,\n",
        "    trace_parameter: float,\n",
        "    v_optimiser_kwargs: Mapping[str, Any],\n",
        "    f_optimiser_kwargs: Mapping[str, Any],\n",
        "    z_optimiser_kwargs: Mapping[str, Any],\n",
        "    pi: Any,\n",
        "    mu: Any,\n",
        "    use_prior_corr: bool,\n",
        "    use_post_corr: bool,\n",
        "    use_special_v_param_init: bool,\n",
        "    eta_f: float,\n",
        "    eta_x_f: float,\n",
        "    eta_v: float,\n",
        "    eta_z: float,\n",
        "    c_f: float,\n",
        "    beta: float,\n",
        "    positive_followon: bool,\n",
        "    nonlinear_et: bool\n",
        ") -> Tuple[Agent, AgentState]:\n",
        "  \"\"\"Initialise TD(λ) agent.\"\"\"\n",
        "  # Check the action spec\n",
        "  action_structure = check_simple_action_spec(action_spec)\n",
        "  pi = jnp.asarray(pi)\n",
        "  mu = jnp.asarray(mu)\n",
        "  # Create random keys\n",
        "  net_key_x, net_key_v, net_key_z, net_key_f, agent_key = jax.random.split(rng_key, 5)\n",
        "\n",
        "  # Create Haiku network, and initialise its weights\n",
        "  x_fn, w_x = create_torso(net_key_x, network_spec, observation_spec)\n",
        "  # Create haiku action-value network, and initialise its weights\n",
        "  dummy_observation = dummy(observation_spec)\n",
        "  dummy_x = x_fn(w_x, dummy_observation)\n",
        "  if use_special_v_param_init:\n",
        "    v_fn_, w_v = create_v_head(net_key_v, dummy_x,\n",
        "                            with_bias=False)\n",
        "                            # w_init=lambda _1, _2:\n",
        "                            # np.array([[1.], [1.], [1.], [1.],\n",
        "                                              # [1.], [10.], [1.]]))\n",
        "    v_fn = lambda w, x: jnp.squeeze(v_fn_(w, x), -1)\n",
        "  else:\n",
        "    v_fn_, w_v = create_v_head(net_key_v, dummy_x,\n",
        "                            with_bias=False)\n",
        "    v_fn = lambda w, x: jnp.squeeze(v_fn_(w, x), -1)\n",
        "\n",
        "  f_fn_, w_f = create_v_head(net_key_f, dummy_x)\n",
        "  if positive_followon:\n",
        "    f_fn = lambda w, x: jax.nn.relu(jnp.squeeze(f_fn_(w, x), -1))\n",
        "  else:\n",
        "    f_fn = lambda w, x: jnp.squeeze(f_fn_(w, x), -1)\n",
        "\n",
        "  def rho_fn(action):\n",
        "    # import pdb; pdb.set_trace()\n",
        "    rho_prior = pi[action]/mu[action]\n",
        "    rho_post = rho_prior\n",
        "    if not use_post_corr:\n",
        "      rho_post = 1\n",
        "\n",
        "    return rho_post, rho_prior\n",
        "    # return jnp.minimum(pi[action]/mu[action], c_f)\n",
        "\n",
        "  # Create function for the gradients of the v function\n",
        "  dv_fn = jax.grad(\n",
        "      lambda w_v, w_x, o: v_fn(w_v, x_fn(w_x, o)), argnums=(0, 1))\n",
        "  # Create function for the gradients of the v function\n",
        "  df_fn = jax.grad(lambda w_f, w_x, o: f_fn(w_f, x_fn(w_x, o)))\n",
        "\n",
        "  # Initialise eligibility traces\n",
        "  e_v, e_z, e_x = tmap(jnp.zeros_like, (w_v, w_v, w_x))\n",
        "\n",
        "  (dvdw, _) = dv_fn(w_v, w_x, dummy_observation)\n",
        "  if nonlinear_et:\n",
        "    z_fn, w_z = create_nonlinear_z_head(net_key_z, dummy_x, dvdw)\n",
        "  else:\n",
        "    z_fn, w_z = create_z_head(net_key_z, dummy_x, dvdw)\n",
        "\n",
        "  # Create loss function for the expected trace\n",
        "  def zloss(w_z, x, e):\n",
        "    total_size = sum([e_i.size for e_i in jax.tree_leaves(e)])\n",
        "    z = z_fn(w_z, x)\n",
        "    sum_of_squares = tmap(lambda z_i, e_i: jnp.sum((z_i - e_i)**2), z, e)\n",
        "    return 0.5 * sum(jax.tree_leaves(sum_of_squares)) / total_size\n",
        "\n",
        "  # Gradient of the expected trace loss (also outputs the loss, for logging)\n",
        "  dzloss_fn = jax.value_and_grad(zloss)\n",
        "\n",
        "  # Create softmax policy\n",
        "  def policy(rng_key, obs, agent_state):\n",
        "    # import pdb; pdb.set_trace()\n",
        "    cpi = jnp.cumsum(mu)\n",
        "    rnd = jax.random.uniform(rng_key)\n",
        "    a =  jnp.argmax(cpi > rnd, axis=-1)\n",
        "    a = jax.tree_unflatten(action_structure, [a])\n",
        "    return a\n",
        "\n",
        "  def get_v(all_states, agent_state):\n",
        "    v_all_states = jax.vmap(lambda obs: v_fn(agent_state.w_v,\n",
        "                                             x_fn(agent_state.w_x, obs)))(jnp.asarray(all_states))\n",
        "    return v_all_states\n",
        "\n",
        "  def get_f(all_states, agent_state):\n",
        "    f_all_states = jax.vmap(lambda obs: f_fn(agent_state.w_f,\n",
        "                                             x_fn(agent_state.w_x, obs)))(jnp.asarray(all_states))\n",
        "    return f_all_states\n",
        "\n",
        "  def get_mu():\n",
        "    return mu\n",
        "\n",
        "  def get_pi():\n",
        "    return pi\n",
        "\n",
        "  # Create optimiser (used to transform gradients into updates)\n",
        "  init_opt, x_adamify = create_optimiser(**v_optimiser_kwargs)\n",
        "  x_opt_state = init_opt(w_x)\n",
        "  init_opt, v_adamify = create_optimiser(**v_optimiser_kwargs)\n",
        "  v_opt_state = init_opt(w_v)\n",
        "\n",
        "  init_opt, f_adamify = create_optimiser(**f_optimiser_kwargs)\n",
        "  f_opt_state = init_opt(w_f)\n",
        "\n",
        "  # Create expected trace optimiser (used to transform gradients into updates)\n",
        "  init_opt, z_adamify = create_optimiser(**z_optimiser_kwargs)\n",
        "  z_opt_state = init_opt(w_z)\n",
        "\n",
        "  # Create initial agent state\n",
        "  agent_state = AgentState(\n",
        "      rng_key=agent_key,\n",
        "      w_v=w_v,\n",
        "      w_z=w_z,\n",
        "      w_x=w_x,\n",
        "      w_f=w_f,\n",
        "      e_v=e_v,\n",
        "      e_z=e_z,\n",
        "      e_x=e_x,\n",
        "      e_f=1.,\n",
        "      f=1.,\n",
        "      trace_decay=0.,\n",
        "      followon_decay=0.,\n",
        "      x_opt_state=x_opt_state,\n",
        "      v_opt_state=v_opt_state,\n",
        "      z_opt_state=z_opt_state,\n",
        "      f_opt_state=f_opt_state,\n",
        "      obs=None,\n",
        "      action=None)\n",
        "\n",
        "  # Create the step function, pre-inputting fixed things (e.g., functions,\n",
        "  # hyper-parameters)\n",
        "  step_fn = functools.partial(\n",
        "      step,\n",
        "      x_scale_fn=x_adamify,\n",
        "      x_fn=x_fn,\n",
        "      v_scale_fn=v_adamify,\n",
        "      v_fn=v_fn,\n",
        "      dv_fn=dv_fn,\n",
        "      z_scale_fn=z_adamify,\n",
        "      z_fn=z_fn,\n",
        "      dzloss_fn=dzloss_fn,\n",
        "      f_scale_fn=f_adamify,\n",
        "      f_fn=f_fn,\n",
        "      df_fn=df_fn,\n",
        "      rho_fn=rho_fn,\n",
        "      policy=policy,\n",
        "      discount=discount,\n",
        "      use_prior_corr=use_prior_corr,\n",
        "      trace_parameter=trace_parameter,\n",
        "      eta_v=eta_v,\n",
        "      eta_z=eta_z,\n",
        "      eta_f=eta_f,\n",
        "      eta_x_f=eta_x_f,\n",
        "      beta=beta,\n",
        "      )\n",
        "\n",
        "  # Create the reset function, for use at the beginning of episodes.\n",
        "  first_step_fn = functools.partial(first_step, policy=policy)\n",
        "\n",
        "#   agent = Agent(step=step_fn, first_step=first_step_fn,\n",
        "#                 get_v=get_v, get_mu=get_mu,\n",
        "#                 get_pi=get_pi, get_f=get_f)\n",
        "  agent = Agent(step=jax.jit(step_fn), first_step=jax.jit(first_step_fn),\n",
        "                get_v=jax.jit(get_v), get_mu=jax.jit(get_mu),\n",
        "                get_pi=jax.jit(get_pi), get_f=jax.jit(get_f))\n",
        "  return agent, agent_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N0e_j4Uy29E",
        "cellView": "code"
      },
      "source": [
        "#@title Aux functions: smooth, create_optimiser...\n",
        "# def smooth(x, m):\n",
        "#   n = max([1, len(x)//m])\n",
        "#   return np.convolve(x, np.ones(n)/n, 'valid')\n",
        "\n",
        "def smooth(x, m):\n",
        "  if m <= 1:\n",
        "    return x\n",
        "  n = max([1, len(x)//m])\n",
        "  return np.convolve(x, np.ones(n)/n, 'valid')\n",
        "\n",
        "def check_simple_observation_spec(observation_spec):\n",
        "  specs = jax.tree_leaves(observation_spec)\n",
        "  if len(specs) > 1:\n",
        "    raise ValueError('Complex observations not supported. Found observation '\n",
        "                     f'spec: {observation_spec}')\n",
        "\n",
        "\n",
        "def check_simple_action_spec(action_spec):\n",
        "  specs, structure = jax.tree_flatten(action_spec)\n",
        "  all_disc = np.all(list(spec.dtype in [np.int32, np.int64] for spec in specs))\n",
        "  if len(specs) > 1 or not all_disc:\n",
        "    raise ValueError('Learning algorithms can currently only support '\n",
        "                     'environments with a single discrete action. Action spec: '\n",
        "                     f'{action_spec}')\n",
        "  return structure\n",
        "\n",
        "\n",
        "def create_optimiser(b1, b2, eps, learning_rate, momentum, d):\n",
        "    def schedule_fn(t):\n",
        "      return (1/(t+1))**d\n",
        "    if learning_rate is None:\n",
        "      return optax.chain(\n",
        "        # optax.trace(momentum, nesterov=False),\n",
        "        optax.scale_by_schedule(schedule_fn),\n",
        "        # optax.scale(learning_rate),\n",
        "      )\n",
        "    else:\n",
        "        return optax.chain(\n",
        "            # optax.trace(momentum, nesterov=False),\n",
        "            # optax.scale_by_adam(b1=b1, b2=b2, eps=eps),\n",
        "            optax.scale(learning_rate),\n",
        "        )\n",
        "\n",
        "def dummy(observation_spec):\n",
        "  return jax.tree_map(\n",
        "      lambda x: jnp.zeros(x.shape, dtype=x.dtype), observation_spec)\n",
        "\n",
        "def _get_num_actions(action_spec):\n",
        "  check_simple_action_spec(action_spec)\n",
        "  return jax.tree_leaves(action_spec)[0].num_values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ATQSGHaCEpof"
      },
      "source": [
        "#@title FiveStateMDP\n",
        "from typing import Any, Dict\n",
        "\n",
        "from bsuite.environments import base\n",
        "\n",
        "import dm_env\n",
        "from dm_env import specs\n",
        "import numpy as np\n",
        "class FiveStateMDP(base.Environment):\n",
        "  \"\"\"FiveStateMDP environment.\"\"\"\n",
        "\n",
        "  def __init__(self, seed, obs_type=\"features\"):\n",
        "    \"\"\"Builds a FiveStateMDP environment with 5 state and 2 actions.\n",
        "\n",
        "    Args:\n",
        "      seed: int\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "\n",
        "    self._nrng = np.random.RandomState(seed)\n",
        "    self._n_states = 5\n",
        "    self._n_actions = 2\n",
        "    self._position = 2\n",
        "    # S x A\n",
        "    # self._mu = np.asarray(, dtype=np.float32)\n",
        "    # self._mu_all_states = np.asarray(self._n_states * [self._mu])\n",
        "    # self._pi = np.asarray([0., 1.], dtype=np.float32)\n",
        "    # self._pi = np.asarray(self._n_states * [self._pi])\n",
        "    # S x n_features\n",
        "    if obs_type == \"onehot\":\n",
        "      self._x = np.eye(self._n_states)\n",
        "      self._n_features = self._n_states\n",
        "    else:\n",
        "      self._x = np.asarray(\n",
        "                [[1.,0.,0.],\n",
        "                [1.,1.,0.],\n",
        "                [0.,1.,0.],\n",
        "                [0.,1.,1.],\n",
        "                [0.,0.,1.]])\n",
        "      self._n_features = 3\n",
        "    # A x S x S\n",
        "    self._p = np.asarray([[[1., 0., 0., 0., 0.], # Left\n",
        "                           [1., 0., 0., 0., 0.],\n",
        "                           [0., 1., 0., 0., 0.],\n",
        "                           [0., 0., 1., 0., 0.],\n",
        "                           [0., 0., 0., 1., 0.]],\n",
        "                          [[0., 1., 0., 0., 0.], # Right\n",
        "                           [0., 0., 1., 0., 0.],\n",
        "                           [0., 0., 0., 1., 0.],\n",
        "                           [0., 0., 0., 0., 1.],\n",
        "                           [0., 0., 0., 0., 1.]]])\n",
        "    # A x S x S\n",
        "    self._r = np.ones((self._n_actions, self._n_states, self._n_states))\n",
        "    self._discounts = np.asarray([0, 1, 1, 1, 0])\n",
        "    # self._true_v_pi = np.asarray([4, 3, 2, 1, 1], dtype=np.float64)\n",
        "\n",
        "  def _get_observation(self):\n",
        "    obs = self._x[self._position]\n",
        "    return obs\n",
        "\n",
        "  def get_all_states(self):\n",
        "    return self._x\n",
        "\n",
        "  def get_q_pi(self, pi, discount=None):\n",
        "    pi = np.asarray(self._n_states * [pi])\n",
        "    discount = 1. if discount is None else discount\n",
        "    discounts = np.full((self._n_states), discount)\n",
        "    discounts *= self._discounts\n",
        "    disc_p = np.einsum('kij, j->kij', self._p, discounts)\n",
        "    disc_ppi = np.einsum('kij, jm->ikjm', disc_p, pi)\n",
        "    disc_ppi_flat = np.reshape(disc_ppi, (self._n_states * self._n_actions, self._n_states * self._n_actions))\n",
        "    rpi = np.einsum(\"kij, kij->ik\", self._r, self._p)\n",
        "    rpi_flat = np.reshape(rpi, (-1))\n",
        "    q = np.linalg.solve(np.eye(self._n_states * self._n_actions) - disc_ppi_flat, rpi_flat)\n",
        "    q = np.reshape(q, (self._n_states, self._n_actions))\n",
        "    return q\n",
        "\n",
        "  def get_sa_stationary(self, pi, discount=None):\n",
        "    pi = np.asarray(self._n_states * [pi])\n",
        "    discount = 1. if discount is None else discount\n",
        "    discounts = np.full((self._n_states), discount)\n",
        "    # discounts *= self._discounts\n",
        "    disc_p = np.einsum('kij, j->kij', self._p, discounts)\n",
        "    disc_ppi = np.einsum('kij, ik->ij', disc_p, pi)\n",
        "    A = np.eye(self._n_states) - disc_ppi\n",
        "    A = np.vstack((A.T, np.ones(self._n_states)))\n",
        "    b = np.matrix([0] * self._n_states + [1]).T\n",
        "    d_pi = np.linalg.lstsq(A, b)[0]\n",
        "    d_pi = np.array(d_pi.T)[0]\n",
        "    d_sa_pi = np.einsum('i, ik->ik', d_pi, pi)\n",
        "    return d_sa_pi\n",
        "\n",
        "#   def get_stationary(self, pi, discount=None):\n",
        "#     pi = np.asarray(self._n_states * [pi])\n",
        "#     discount = 1. if discount is None else discount\n",
        "#     discounts = np.full((self._n_states), discount)\n",
        "#     # discounts *= self._discounts\n",
        "#     disc_p = np.einsum('kij, j->kij', self._p, discounts)\n",
        "#     disc_ppi = np.einsum('kij, ik->ij', disc_p, pi)\n",
        "#     A = np.eye(self._n_states) - disc_ppi\n",
        "#     A = np.vstack((A.T, np.ones(self._n_states)))\n",
        "#     b = np.matrix([0] * self._n_states + [1]).T\n",
        "#     d_pi = np.linalg.lstsq(A, b)[0]\n",
        "#     d_pi = np.array(d_pi.T)[0]\n",
        "#     return d_pi\n",
        "  def get_stationary(self, pi, discount=1.0, T=100):\n",
        "    dS = self._n_states\n",
        "    dA = self._n_actions\n",
        "    state_visitation = np.zeros((dS, 1))\n",
        "    state_visitation[2] = 1\n",
        "    pi = np.asarray(self._n_states * [pi])\n",
        "    sa_visit_t = np.zeros((dS, dA, T))\n",
        "\n",
        "    norm_factor = 0.0\n",
        "    for i in range(T):\n",
        "        sa_visit = state_visitation * pi\n",
        "        cur_discount = (discount ** i)\n",
        "        sa_visit_t[:, :, i] = cur_discount * sa_visit\n",
        "        norm_factor += cur_discount\n",
        "        # sum-out (SA)S\n",
        "        new_state_visitation = np.einsum('ij,jik->k', sa_visit, self._p)\n",
        "        state_visitation = np.expand_dims(new_state_visitation, axis=1)\n",
        "    d_sa = np.sum(sa_visit_t, axis=2) / norm_factor\n",
        "    d_s = np.sum(d_sa * pi, axis=-1)\n",
        "    return d_s\n",
        "\n",
        "  def get_v_pi(self, pi, discount=None):\n",
        "    discount = 1. if discount is None else discount\n",
        "    discounts = np.full((self._n_states), discount)\n",
        "    discounts *= self._discounts\n",
        "    pi = np.asarray(self._n_states * [pi])\n",
        "    disc_p = np.einsum('kij, j->kij', self._p, discounts)\n",
        "    disc_ppi = np.einsum('kij, ik->ij', disc_p, pi)\n",
        "    rpi = np.einsum('kij, kij, ik->i', self._r, self._p, pi)\n",
        "    v = np.linalg.inv(np.eye(self._n_states) - disc_ppi).dot(rpi)\n",
        "    return v\n",
        "\n",
        "  def get_f_pi(self, pi, mu, discount=None):\n",
        "    discount = 1. if discount is None else discount\n",
        "    discounts = np.full((self._n_states), discount)\n",
        "    discounts *= self._discounts\n",
        "    pi = np.asarray(self._n_states * [pi])\n",
        "    d_mu = self.get_stationary(mu, discount)\n",
        "    disc_p = np.einsum('kij, j->kij', self._p, discounts)\n",
        "    disc_ppi = np.einsum('kij, ik->ij', disc_p, pi)\n",
        "    rpi = np.einsum('kij, kij, ik->i', self._r, self._p, pi)\n",
        "    f = d_mu.dot(np.linalg.inv(np.eye(self._n_states) - disc_ppi))\n",
        "    return f\n",
        "\n",
        "  # def get_stationary(self, pi, discount=None):\n",
        "  #   pi = np.asarray(self._n_states * [pi])\n",
        "  #   discount = 1. if discount is None else discount\n",
        "  #   discounts = np.full((self._n_states), discount)\n",
        "  #   # discounts *= self._discounts\n",
        "  #   disc_p = np.einsum('kij, j->kij', self._p, discounts)\n",
        "  #   disc_ppi = np.einsum('kij, ik->ij', disc_p, pi)\n",
        "  #   A = np.eye(self._n_states) - disc_ppi\n",
        "  #   A = np.vstack((A.T, np.ones(self._n_states)))\n",
        "  #   b = np.matrix([0] * self._n_states + [1]).T\n",
        "  #   d_pi = np.linalg.lstsq(A, b)[0]\n",
        "  #   d_pi = np.array(d_pi.T)[0]\n",
        "  #   return d_pi\n",
        "\n",
        "  # def get_v_pi(self, pi, discount=None):\n",
        "  #   discount = 1. if discount is None else discount\n",
        "  #   discounts = np.full((self._n_states), discount)\n",
        "  #   discounts *= self._discounts\n",
        "  #   pi = np.asarray(self._n_states * [pi])\n",
        "  #   disc_p = np.einsum('kij, j->kij', self._p, discounts)\n",
        "  #   disc_ppi = np.einsum('kij, ik->ij', disc_p, pi)\n",
        "  #   rpi = np.einsum('kij, kij, ik->i', self._r, self._p, pi)\n",
        "  #   v = np.linalg.inv(np.eye(self._n_states) - disc_ppi).dot(rpi)\n",
        "  #   return v\n",
        "\n",
        "  def _reset(self) -> dm_env.TimeStep:\n",
        "    self._position = 2\n",
        "    observation = self._get_observation()\n",
        "    return dm_env.restart(observation)\n",
        "\n",
        "  def _step(self, action: int) -> dm_env.TimeStep:\n",
        "    new_position = self._nrng.choice(range(self._n_states),\n",
        "                                     p=self._p[action][self._position])\n",
        "    reward = self._r[action][self._position][new_position]\n",
        "    self._position = new_position\n",
        "    next_observation = self._get_observation()\n",
        "    return dm_env.transition(reward=reward,\n",
        "                             discount=self._discounts[self._position],\n",
        "                             observation=next_observation)\n",
        "\n",
        "  def observation_spec(self):\n",
        "    return specs.Array(shape=(self._n_features,), dtype=np.float32)\n",
        "\n",
        "  def action_spec(self):\n",
        "    return specs.DiscreteArray(self._n_actions, name='action')\n",
        "\n",
        "  def _save(self, observation):\n",
        "    self._raw_observation = (observation * 255).astype(np.uint8)\n",
        "\n",
        "  @property\n",
        "  def optimal_return(self):\n",
        "    # Returns the maximum total reward achievable in an episode.\n",
        "    return 10\n",
        "\n",
        "  def bsuite_info(self) -> Dict[str, Any]:\n",
        "    return {}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJF8jRKZRljM",
        "outputId": "1b2a8576-3bd5-4eae-9bb1-bd9b7b960304"
      },
      "source": [
        "#@title env test\n",
        "env = FiveStateMDP(42)\n",
        "v_pi = env.get_v_pi(pi=[1, 0])\n",
        "\n",
        "d_mu = env.get_stationary(pi=[0.66, 0.33])\n",
        "print(env.get_stationary(pi=[0, 1]))\n",
        "print(d_mu)\n",
        "pi_ = np.asarray(env._n_states * [[0,1]])\n",
        "disc_p = np.einsum('kij, j->kij', env._p, env._discounts)\n",
        "disc_ppi = np.einsum('kij, ik->ij', disc_p, pi_)\n",
        "print(d_mu.dot(np.linalg.inv(np.eye(env._n_states) - disc_ppi)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.   0.   0.01 0.01 0.98]\n",
            "[0.16932769 0.08878801 0.05064273 0.02447705 0.0119599 ]\n",
            "[0.16932769 0.2581157  0.30875843 0.33323549 0.0119599 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgZJ1I4Keke6"
      },
      "source": [
        "#@title runner\n",
        "def run(\n",
        "    number_of_episodes = -1,\n",
        "    number_of_steps = 1e3,\n",
        "    log_every_steps = 10,\n",
        "    log_every_episodes = 10,\n",
        "    seeds=1,\n",
        "    hyperparams=None,\n",
        "    custom_hyperparams=None,\n",
        "    envs = ['FiveStateMDP'],\n",
        "    network=\"linear\",\n",
        "    verbose=False,\n",
        "    agents=[(\"td\", False, None)],\n",
        "    ):\n",
        "\n",
        "  stats_keys = [\"td_error\", \"rewards\", \"value_errors\",\n",
        "                            \"values\", \"f_td_or_mc_errors\",\n",
        "                            \"f_exp_errors\", \"zloss\", \"rhos_post\",\n",
        "                            \"f_var_errors\", \"value_weights\"]\n",
        "  all_envs_stats = defaultdict(list)\n",
        "\n",
        "  for env_id in envs:\n",
        "    agents_stats = defaultdict(list)\n",
        "    hyper = {}\n",
        "    for agent_name in agents:\n",
        "      agents_params = {}\n",
        "      for k, v in hyperparams.items():\n",
        "        agents_params[k] = v\n",
        "        if agent_name in custom_hyperparams.keys() and\\\n",
        "          k in custom_hyperparams[agent_name].keys():\n",
        "          agents_params[k] = custom_hyperparams[agent_name][k]\n",
        "    #   import pdb;pdb.set_trace()\n",
        "      for hyper_values in itertools.product(*agents_params.values()):\n",
        "        seeds_stats = defaultdict(list)\n",
        "        for v, k in zip(hyper_values, agents_params.keys()):\n",
        "          hyper[k] = v\n",
        "        for s in range(seeds):\n",
        "          stats = defaultdict(list)\n",
        "\n",
        "          agent_config = get_config(agent_name, env_id=env_id,\n",
        "                                    hyper=hyper)\n",
        "          if env_id == \"FiveStateMDP\":\n",
        "            env = FiveStateMDP(seed=4321+s)\n",
        "          elif env_id == \"TabularFiveStateMDP\":\n",
        "            env = FiveStateMDP(seed=4321+s, obs_type=\"onehot\")\n",
        "          else:\n",
        "            env = BairdMDP(seed=4321+s)\n",
        "\n",
        "          agent, agent_state = agent_config`[\"init\"](\n",
        "              rng_key=jax.random.PRNGKey(4321+s),\n",
        "              network_spec=(network or env_id),\n",
        "              action_spec=env.action_spec(),\n",
        "              observation_spec=env.observation_spec(),\n",
        "              **agent_config[\"cfg\"])\n",
        "\n",
        "          timestep = None\n",
        "          episode_timesteps = 0\n",
        "          t = 0\n",
        "          ep = 0\n",
        "          ep_return = 0\n",
        "\n",
        "          while(True):\n",
        "            # Reset environment and pick first action\n",
        "            if not timestep or timestep.last():\n",
        "              timestep = env.reset()\n",
        "              action, agent_state = agent.first_step(timestep, agent_state)\n",
        "              all_states = env.get_all_states()\n",
        "              v_pi = agent.get_v(all_states, agent_state)\n",
        "              true_v_pi = env.get_v_pi(agent.get_pi())\n",
        "              d_mu = env.get_stationary(agent.get_mu())\n",
        "              true_f_pi = env.get_f_pi(agent.get_pi(), agent.get_mu())\n",
        "            #   print(true_v_pi)\n",
        "            #   print(v_pi)\n",
        "            #   print(d_mu)\n",
        "            #   print(f'Initial value function v(w_0) is {v_pi}')\n",
        "              # exit(0)\n",
        "            # import pdb;pdb.set_trace()\n",
        "            # Take the current action in the environment\n",
        "            timestep = env.step(action)\n",
        "            # Step the agent (learns, and gives new action)\n",
        "            action, agent_state, log_dict = agent.step(\n",
        "                timestep=timestep, agent_state=agent_state)\n",
        "\n",
        "            episode_timesteps += 1\n",
        "            ep_return += timestep.reward\n",
        "            t += 1\n",
        "\n",
        "            if timestep.last():\n",
        "              ep_timesteps.append(episode_timesteps)\n",
        "              episode_timesteps = 0\n",
        "              ep += 1\n",
        "              returns.append(ep_return)\n",
        "              ep_return = 0\n",
        "\n",
        "            if timestep.last() or \\\n",
        "              (number_of_steps > -1 and t % log_every_steps == 0):\n",
        "                # Log instantaneous reward\n",
        "                # print(log_dict[\"td_error\"])\n",
        "                stats[\"rewards\"].append(timestep.reward)\n",
        "                # Log td errors\n",
        "                stats[\"td_error\"].append(log_dict[\"td_error\"])\n",
        "                # Log the values/action-values\n",
        "                stats[\"values\"].append(log_dict[\"v\"])\n",
        "                # Log the td or the mc error for the follow-on trace\n",
        "                stats[\"f_td_or_mc_errors\"].append(log_dict[\"f_td_or_mc_error\"])\n",
        "                stats[\"zloss\"].append(log_dict[\"zloss\"])\n",
        "                # Log value error\n",
        "                v_pi = agent.get_v(all_states, agent_state)\n",
        "                # print(v_pi)\n",
        "                ve = np.average((true_v_pi - v_pi)**2, weights=d_mu)\n",
        "                stats[\"value_errors\"].append(ve)\n",
        "                f_pi = agent.get_f(all_states, agent_state)\n",
        "                fe = np.average((true_f_pi - f_pi)**2, weights=d_mu)\n",
        "                stats[\"f_exp_errors\"].append(fe)\n",
        "                # Log the instantaneous variance\n",
        "                f_var_e = (log_dict[\"f\"] - f_pi[env._position])**2\n",
        "                stats[\"f_var_errors\"].append(f_var_e)\n",
        "                # w = np.asarray(agent_state.w[\"linear\"][\"w\"].reshape((-1)))\n",
        "                # value_weights.append(w)\n",
        "                stats[\"rhos_prior\"].append(log_dict[\"rho_prior\"])\n",
        "                stats[\"rhos_post\"].append(log_dict[\"rho_post\"])\n",
        "\n",
        "            # if t % log_every == 0 and verbose:\n",
        "            # #   print(f'steps: {t:10}',\n",
        "            # #         f', f_mc_error: {log_dict[\"f_error\"]}',\n",
        "            # #                 f', f: {log_dict[\"f\"]}',\n",
        "            # #                 f', e_f: {log_dict[\"e_f\"]}',\n",
        "            # #                 f', x_f: {log_dict[\"x_f\"]}',\n",
        "            # #                 )\n",
        "            #     recent_rhos = np.mean(rhos[-log_every:])\n",
        "            #     recent_avg_reward = np.mean(rewards[-log_every:])\n",
        "            #     recent_avg_td_error = np.mean(td_errors[-log_every:])\n",
        "            #     recent_ve = np.mean(value_errors[-log_every:])\n",
        "            #     recent_values = np.mean(values[-log_every:])\n",
        "            #     recent_f_td_or_mc_errors = np.mean(f_errors[-log_every:])\n",
        "            #     recent_f_exp_errors = np.mean(f_errors[-log_every:])\n",
        "            #     recent_f_var_errors = np.mean(f_errors[-log_every:])\n",
        "            #     print(f'steps: {t:10}',\n",
        "            #           f', mean last {log_every} avg reward: {recent_avg_reward}'\n",
        "            #           f', td errors: {recent_avg_td_error}',\n",
        "            #           f', ve: {recent_ve}',\n",
        "            #           f', values: {recent_values}',\n",
        "            #           f', rhos: {recent_rhos}')\n",
        "            if (number_of_steps > -1 and t > number_of_steps) or \\\n",
        "            (number_of_episodes > -1 and ep > number_of_episodes):\n",
        "              break\n",
        "\n",
        "          for k in stats_keys:\n",
        "            seeds_stats[k].append(stats[k])\n",
        "\n",
        "        for k in stats_keys:\n",
        "            agents_stats[k].append(seeds_stats[k])\n",
        "    for k in stats_keys:\n",
        "        all_envs_stats[k].append(agents_stats[k])\n",
        "\n",
        "  return all_envs_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKkYbirez3-Q"
      },
      "source": [
        "#@title nets\n",
        "def dummy(observation_spec):\n",
        "  return jax.tree_map(\n",
        "      lambda x: jnp.zeros(x.shape, dtype=x.dtype), observation_spec)\n",
        "\n",
        "def linear_net(observation_spec, with_bias=True, w_init=None):\n",
        "  check_simple_observation_spec(observation_spec)\n",
        "\n",
        "  def fun(obs, num_actions):\n",
        "    if w_init is not None:\n",
        "      q = hk.Linear(num_actions, with_bias=with_bias, w_init=w_init)\n",
        "    else:\n",
        "      q = hk.Linear(num_actions, with_bias=with_bias)\n",
        "    return q(obs)\n",
        "  return fun\n",
        "\n",
        "\n",
        "def mlp_net(observation_spec):\n",
        "  check_simple_observation_spec(observation_spec)\n",
        "\n",
        "  def fun(obs, num_actions):\n",
        "    net = hk.Sequential([\n",
        "        hk.Linear(20),\n",
        "        jax.nn.relu,\n",
        "        # hk.Linear(20),\n",
        "        # jax.nn.relu,\n",
        "    ])\n",
        "    x = net(obs)\n",
        "    q = hk.Linear(num_actions)\n",
        "    return q(x)\n",
        "  return fun\n",
        "\n",
        "def mlp2_net(observation_spec):\n",
        "  check_simple_observation_spec(observation_spec)\n",
        "\n",
        "  def fun(obs, num_actions):\n",
        "    net = hk.Sequential([\n",
        "        hk.Linear(20),\n",
        "        jax.nn.relu,\n",
        "        hk.Linear(20),\n",
        "        jax.nn.relu,\n",
        "    ])\n",
        "    x = net(obs)\n",
        "    q = hk.Linear(num_actions)\n",
        "    return q(x)\n",
        "  return fun\n",
        "\n",
        "def mlp_linear_torso_net(observation_spec):\n",
        "  check_simple_observation_spec(observation_spec)\n",
        "\n",
        "  def fun(obs):\n",
        "    return obs\n",
        "  return fun\n",
        "\n",
        "def mlp_torso_net(observation_spec):\n",
        "  check_simple_observation_spec(observation_spec)\n",
        "\n",
        "  def fun(obs):\n",
        "    net = hk.Sequential([\n",
        "        hk.Linear(20),\n",
        "        jax.nn.relu,\n",
        "        # hk.Linear(20),\n",
        "        # jax.nn.relu,\n",
        "    ])\n",
        "    return net(obs)\n",
        "  return fun\n",
        "\n",
        "def mlp2_torso_net(observation_spec):\n",
        "  check_simple_observation_spec(observation_spec)\n",
        "\n",
        "  def fun(obs):\n",
        "    net = hk.Sequential([\n",
        "        hk.Linear(20),\n",
        "        jax.nn.relu,\n",
        "        hk.Linear(20),\n",
        "        jax.nn.relu,\n",
        "    ])\n",
        "    return net(obs)\n",
        "  return fun\n",
        "\n",
        "def create_torso(\n",
        "    rng_key: jnp.ndarray,\n",
        "    network_spec: str,\n",
        "    observation_spec: Any,\n",
        "):\n",
        "  if network_spec == \"linear\":\n",
        "    net = mlp_linear_torso_net(observation_spec)\n",
        "  elif network_spec == \"mlp\":\n",
        "    net = mlp_torso_net(observation_spec)\n",
        "  else:\n",
        "    net = mlp2_torso_net(observation_spec)\n",
        "\n",
        "  init, apply_fn = hk.without_apply_rng(hk.transform(net))\n",
        "  dummy_observation = jax.tree_map(lambda x: jnp.zeros(x.shape, dtype=x.dtype),\n",
        "                                   observation_spec)\n",
        "  w = init(rng_key, obs=dummy_observation)\n",
        "  return apply_fn, w\n",
        "\n",
        "def create_q_head(\n",
        "    rng_key: jnp.ndarray,\n",
        "    dummy_x: Any,\n",
        "    action_spec: Any,\n",
        "):\n",
        "  \"\"\"Pick and initialise a haiku network.\"\"\"\n",
        "  num_actions = _get_num_actions(action_spec)\n",
        "\n",
        "  init, q_fn = hk.without_apply_rng(\n",
        "      hk.transform(functools.partial(q_head, num_actions=num_actions)))\n",
        "\n",
        "  w = init(rng_key, x=dummy_x)\n",
        "  return q_fn, w\n",
        "\n",
        "def create_v_head(\n",
        "    rng_key: jnp.ndarray,\n",
        "    dummy_x: Any,\n",
        "    with_bias: bool = True,\n",
        "    w_init: Any = None\n",
        "):\n",
        "  \"\"\"Pick and initialise a haiku network.\"\"\"\n",
        "  init, v_fn = hk.without_apply_rng(\n",
        "      hk.transform(functools.partial(v_head,\n",
        "                                     with_bias=with_bias,\n",
        "                                     w_init=w_init)))\n",
        "\n",
        "  w = init(rng_key, x=dummy_x)\n",
        "  return v_fn, w\n",
        "\n",
        "def create_nonlinear_z_head(\n",
        "    rng_key: jnp.ndarray,\n",
        "    dummy_x: Any,\n",
        "    trace: Any,\n",
        "):\n",
        "  \"\"\"Pick and initialise a haiku network.\"\"\"\n",
        "  init_fn, z_fn = hk.without_apply_rng(\n",
        "      hk.transform(functools.partial(_non_linear_z_head, trace=trace)))\n",
        "\n",
        "  w_z = init_fn(rng_key, x=dummy_x)\n",
        "  return z_fn, w_z\n",
        "\n",
        "def create_z_head(\n",
        "    rng_key: jnp.ndarray,\n",
        "    dummy_x: Any,\n",
        "    trace: Any,\n",
        "):\n",
        "  \"\"\"Pick and initialise a haiku network.\"\"\"\n",
        "  init_fn, z_fn = hk.without_apply_rng(\n",
        "      hk.transform(functools.partial(_z_head, trace=trace)))\n",
        "\n",
        "  w_z = init_fn(rng_key, x=dummy_x)\n",
        "  return z_fn, w_z\n",
        "\n",
        "def _non_linear_z_head(x, trace):\n",
        "  \"\"\"Creates a network head for the expected eligibility trace.\n",
        "\n",
        "  The small network learns to estimate the gradients of the q-head network.\n",
        "\n",
        "  Args:\n",
        "      x: input of the expected trace net,\n",
        "      trace: the trace,\n",
        "\n",
        "  Returns:\n",
        "      The expected trace z.\n",
        "  \"\"\"\n",
        "  trace_flat, trace_tree = jax.tree_flatten(trace)\n",
        "\n",
        "  expected_traces = []\n",
        "  for trace_i in trace_flat:\n",
        "    net = hk.Sequential([\n",
        "        hk.Linear(20),\n",
        "        jax.nn.relu,\n",
        "        # hk.Linear(20),\n",
        "        # jax.nn.relu,\n",
        "    ])\n",
        "    x = net(x)\n",
        "    x = hk.Linear(np.prod(trace_i.shape))(x)\n",
        "    x = jnp.reshape(x, trace_i.shape)\n",
        "    expected_traces.append(x)\n",
        "\n",
        "  z = jax.tree_unflatten(trace_tree, expected_traces)\n",
        "  return z\n",
        "\n",
        "def _z_head(x, trace):\n",
        "  \"\"\"Creates a network head for the expected eligibility trace.\n",
        "\n",
        "  The small network learns to estimate the gradients of the q-head network.\n",
        "\n",
        "  Args:\n",
        "      x: input of the expected trace net,\n",
        "      trace: the trace,\n",
        "\n",
        "  Returns:\n",
        "      The expected trace z.\n",
        "  \"\"\"\n",
        "  trace_flat, trace_tree = jax.tree_flatten(trace)\n",
        "\n",
        "  expected_traces = []\n",
        "  for trace_i in trace_flat:\n",
        "    x = hk.Linear(np.prod(trace_i.shape))(x)\n",
        "    x = jnp.reshape(x, trace_i.shape)\n",
        "    expected_traces.append(x)\n",
        "\n",
        "  z = jax.tree_unflatten(trace_tree, expected_traces)\n",
        "  return z\n",
        "\n",
        "def q_head(x, num_actions):\n",
        "  q = hk.Linear(num_actions)\n",
        "  return q(x)\n",
        "\n",
        "def v_head(x, with_bias=None, w_init=None):\n",
        "  if w_init is not None:\n",
        "    v = hk.Linear(1, with_bias=with_bias, w_init=w_init)\n",
        "  else:\n",
        "    v = hk.Linear(1, with_bias=with_bias)\n",
        "  return v(x)\n",
        "\n",
        "\n",
        "def create_v_net(\n",
        "    rng_key: jnp.ndarray,\n",
        "    network_spec: str,\n",
        "    observation_spec: Any,\n",
        "    with_bias: bool = True,\n",
        "    w_init: Any = None\n",
        "):\n",
        "  \"\"\"Pick and initialise a haiku network.\"\"\"\n",
        "\n",
        "  # Usually this is a genrl environment id, so we extract domain name and use\n",
        "  # that to select an agent network.\n",
        "  if network_spec == \"linear\":\n",
        "    net = linear_net(observation_spec, with_bias, w_init)\n",
        "  else:\n",
        "    net = mlp_net(observation_spec, with_bias, w_init)\n",
        "\n",
        "  init, v_fn = hk.without_apply_rng(\n",
        "      hk.transform(functools.partial(net, num_actions=1)))\n",
        "  dummy_observation = jax.tree_map(lambda x: jnp.zeros(x.shape, dtype=x.dtype),\n",
        "                                   observation_spec)\n",
        "  w = init(rng_key, obs=dummy_observation)\n",
        "  return v_fn, w\n",
        "\n",
        "def create_net(\n",
        "    rng_key: jnp.ndarray,\n",
        "    network_spec: str,\n",
        "    observation_spec: Any,\n",
        "    action_spec: Any,\n",
        "    with_bias: bool = True,\n",
        "):\n",
        "  \"\"\"Pick and initialise a Haiku network.\"\"\"\n",
        "\n",
        "  # Usually this is a genrl environment id, so we extract domain name and use\n",
        "  # that to select an agent network.\n",
        "  if network_spec == \"linear\":\n",
        "    net = linear_net(observation_spec, with_bias)\n",
        "  else:\n",
        "    net = mlp_net(observation_spec, with_bias)\n",
        "  num_actions = _get_num_actions(action_spec)\n",
        "\n",
        "  init, q_fn = hk.without_apply_rng(\n",
        "      hk.transform(functools.partial(net, num_actions=num_actions)))\n",
        "  dummy_observation = jax.tree_map(lambda x: jnp.zeros(x.shape, dtype=x.dtype),\n",
        "                                   observation_spec)\n",
        "  w = init(rng_key, obs=dummy_observation)\n",
        "  return q_fn, w\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "b6LI3M13QdBt"
      },
      "source": [
        "#@title Plot lims\n",
        "fig_lims = {\n",
        "            \"FiveStateMDP\": {\"td_error\": [-50, 50],\n",
        "                \"value_error\": [0, 50],\n",
        "                \"value\": [0, 50],\n",
        "                \"f_td_or_mc_error\": [-1000, 10000],\n",
        "                \"f_exp_error\": [0, 10000],\n",
        "                \"f_var_error\": [0, 10000],\n",
        "                \"value_weights\": [-10000, 10000],\n",
        "                \"zloss\": [-5000, 1000],\n",
        "                \"return\": [0, 5000],\n",
        "                \"rewards\": [0, 5000],\n",
        "                \"ep_timesteps\": [0, 10000],\n",
        "                \"rhos_post\": [-5000, 5000],\n",
        "                },\n",
        "            \"TabularFiveStateMDP\": {\"td_error\": [-5000, 5000],\n",
        "                \"value_error\": [-5000, 5000],\n",
        "                \"rewards\": [-5000, 5000],\n",
        "                \"value\": [-5000, 5000],\n",
        "                \"return\": [-5000, 5000],\n",
        "                \"zloss\": [-5000, 5000],\n",
        "                \"ep_timesteps\": [-5000, 5000],\n",
        "                \"f_td_or_mc_error\": [-5000, 5000],\n",
        "                \"f_exp_error\": [-5000, 5000],\n",
        "                \"f_var_error\": [-5000, 5000],\n",
        "                \"value_weights\": [-5000, 5000],\n",
        "                \"rhos_post\": [-5000, 5000],\n",
        "                },\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "uSqFFDoC5CKA"
      },
      "source": [
        "def save_fig_pdf(fig, name):\n",
        "  from colabtools import fileedit\n",
        "  file = '/tmp/{}.pdf'.format(name)\n",
        "  with open(file, 'wb') as f:\n",
        "    fig.savefig(f, facecolor='none', edgecolor='none', format='pdf', bbox_inches=\"tight\")\n",
        "  fileedit.download_file(file) # this uses the python interface to %download_file\n",
        "\n",
        "def save_fig_png(fig, name):\n",
        "  from colabtools import fileedit\n",
        "  file = '/tmp/{}.pdf'.format(name)\n",
        "  with open(file, 'wb') as f:\n",
        "    fig.savefig(f, facecolor='none', edgecolor='none', format='png', bbox_inches=\"tight\")\n",
        "  fileedit.download_file(file) # this uses the python interface to %download_file\n",
        "\n",
        "#@title plotting\n",
        "COLORS = (\n",
        "\n",
        "'#dfc27d',\n",
        "# '#bf812d',\n",
        "'#01665e',\n",
        "'#80cdc1',\n",
        "\n",
        "# '#f6e8c3',\n",
        "# '#c7eae5',\n",
        "# '#35978f',\n",
        "'#8c510a',\n",
        "\n",
        "# # '#f6e8c3',\n",
        "# # '#c7eae5',\n",
        "# '#80cdc1',\n",
        "# # '#35978f',\n",
        "# '#01665e',\n",
        "\n",
        "# '#8c510a',\n",
        "# '#bf812d',\n",
        "# '#dfc27d',\n",
        "# '#a6cee3',\n",
        "#     '#8c510a',\n",
        "# # '#bf812d',\n",
        "# '#dfc27d',\n",
        "# # '#f6e8c3',\n",
        "# '#c7eae5',\n",
        "# # '#80cdc1',\n",
        "# '#35978f',\n",
        "# # '#01665e',\n",
        "# # '#a6cee3',\n",
        "#     '#8c510a',\n",
        "# # '#bf812d',\n",
        "# '#dfc27d',\n",
        "# # '#f6e8c3',\n",
        "# '#c7eae5',\n",
        "# '#80cdc1',\n",
        "# # '#35978f',\n",
        "# '#01665e',\n",
        "# '#253494',\n",
        "# '#2c7fb8',\n",
        "# '#41b6c4',\n",
        "# '#7fcdbb',\n",
        "# '#c7e9b4',\n",
        "# '#ffffcc',\n",
        ")\n",
        "def make_axis_nice(ax, fontsize):\n",
        "  ax.xaxis.label.set_fontsize(fontsize)\n",
        "  ax.yaxis.label.set_fontsize(fontsize)\n",
        "  ax.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",\n",
        "                 labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
        "  ax.spines[\"top\"].set_visible(False)\n",
        "  ax.spines[\"bottom\"].set(visible=True, color='black', lw=2)\n",
        "  ax.spines[\"right\"].set_visible(False)\n",
        "  ax.spines[\"left\"].set(visible=True, color='black', lw=2)\n",
        "  ax.get_xaxis().tick_bottom()\n",
        "  ax.get_yaxis().tick_left()\n",
        "  ax.xaxis.grid(False)\n",
        "  ax.yaxis.grid(linestyle=\"--\", lw=0.5, color=\"black\", alpha=0.25)\n",
        "  ax.tick_params(labelsize=fontsize)\n",
        "\n",
        "def add_subplot(env_id, data, num_ticks,\n",
        "                seeds, agents, data_key, subplot_title, description, ax, smoothing=1,\n",
        "                fontsize=20, custom_hyperparams=None, hyperparams=None):\n",
        "  i = 0\n",
        "\n",
        "  for agent in agents:\n",
        "    agents_params = {}\n",
        "    for k, v in hyperparams.items():\n",
        "        agents_params[k] = v\n",
        "        if agent in custom_hyperparams.keys() and\\\n",
        "         k in custom_hyperparams[agent].keys():\n",
        "          agents_params[k] = custom_hyperparams[agent][k]\n",
        "    hyper = {}\n",
        "    # print(agents_params.values())\n",
        "    for hyper_values in itertools.product(*agents_params.values()):\n",
        "      for v, k in zip(hyper_values, agents_params.keys()):\n",
        "            hyper[k] = v\n",
        "    #   print(hyper_values)\n",
        "      if len(data[i]) == 0:\n",
        "        continue\n",
        "\n",
        "      mean = np.mean(data[i], axis=0)\n",
        "      data_std = np.std(data[i], axis=0)\n",
        "    #   if len(mean) <= smoothing:\n",
        "    #       continue\n",
        "\n",
        "      mean = smooth(mean, smoothing)[:1000]\n",
        "\n",
        "      x_mean = range(0, len(mean) * smoothing, smoothing)\n",
        "      data_std = smooth(data_std, smoothing)[:1000]\n",
        "\n",
        "      if \"alpha_v_f\" in list(hyper.keys()):\n",
        "        hyper[\"alpha_v\"] = hyper[\"alpha_v_f\"][0]\n",
        "        hyper[\"alpha_f\"] = hyper[\"alpha_v_f\"][1]\n",
        "      agent_label = (r'{}'.format(agent) +\n",
        "                       \"{}{}{}{}\".format(\n",
        "                        r',$\\alpha_v={}$'.format(hyper[\"alpha_v\"]) if hyper[\"alpha_v\"] is not None and (\"alpha_v\" in list(agents_params.keys()) and len(agents_params[\"alpha_v\"]) > 1 or \"alpha_v\" not in list(agents_params.keys())) else r', $d={}$'.format(hyper[\"d\"]) if hyper[\"d\"] is not None and len(agents_params[\"d\"]) > 1 else '',\n",
        "                        r',$\\alpha_z={}$'.format(hyper[\"alpha_z\"]) if hyper[\"alpha_z\"] is not None and len(agents_params[\"alpha_z\"]) > 1 else r', $dz={}$' if hyper['dz'] is not None and len(agents_params[\"dz\"]) > 1 else '',\n",
        "                        r',$\\alpha_f={}$'.format(hyper[\"alpha_f\"]) if hyper[\"alpha_f\"] is not None and (\"alpha_f\" in list(agents_params.keys()) and len(agents_params[\"alpha_f\"]) > 1 or \"alpha_f\" not in list(agents_params.keys())) else r', $df={}$'.format(hyper[\"df\"]) if hyper[\"df\"] is not None and len(agents_params[\"df\"]) > 1 else '',\n",
        "                        r',$\\beta={}$'.format(hyper[\"beta\"]) if hyper[\"beta\"] < 100 and len(agents_params[\"beta\"]) > 1 else ''))\n",
        "      ax.plot(x_mean, mean,\n",
        "                ':' if agent.startswith('X') else '-' ,\n",
        "                lw=4,\n",
        "                color=COLORS[i % len(COLORS)], alpha=1.,\n",
        "                label=agent_label)\n",
        "      print(f\"{agent_label}_{i}_{COLORS[i % len(COLORS)]}\")\n",
        "    #   import pdb;pdb.set_trace()\n",
        "      ax.fill_between(x=x_mean, y1=mean - data_std / np.sqrt(seeds),\n",
        "                      y2=mean +  data_std / np.sqrt(seeds),\n",
        "              color=COLORS[i % len(COLORS)], alpha=0.2)\n",
        "    #   for s in range(seeds):\n",
        "    #     if len(data[i][s]) <= smoothing:\n",
        "    #       continue\n",
        "    #     ax.plot(smooth(data[i][s], smoothing),\n",
        "    #             '-', lw=3,\n",
        "    #             color=COLORS[i % len(COLORS)], alpha=0.2)\n",
        "      i += 1\n",
        "#   ax.set_title(subplot_title, fontdict=dict(fontsize=fontsize))\n",
        "  make_axis_nice(ax, fontsize)\n",
        "  ax.set_xlabel(\"Steps\")\n",
        "  ax.set_ylabel(subplot_title)\n",
        "#   ax.set_yscale('log')\n",
        "  ax.set_title(description, fontsize=fontsize)\n",
        "\n",
        "#   ylim = ax.get_ylim()\n",
        "#   d = (np.minimum(fig_lims[env_id][data_key][1], ylim[1]) -\n",
        "#         np.maximum(fig_lims[env_id][data_key][0], ylim[0])) / 100\n",
        "#   ax.set_ylim(np.maximum(fig_lims[env_id][data_key][0], ylim[0]) - d,\n",
        "#           np.minimum(fig_lims[env_id][data_key][1], ylim[1]) + d)\n",
        "  return ax\n",
        "\n",
        "def plot_statistics(env_id, agents,\n",
        "                    statistics,\n",
        "                    custom_hyperparams,\n",
        "                    hyperparams,\n",
        "                    seeds, num_ticks=5,\n",
        "                    smoothing=1,\n",
        "                    fontsize=20,\n",
        "                    cols=4,\n",
        "                    rows=4,\n",
        "                    legend_bbox_to_anchor=(0., 1.05),\n",
        "                    legend_ncol=6,\n",
        "                    legend_loc='upper left',\n",
        "                    ):\n",
        "  fig = plt.figure(figsize=(cols*5, rows*4))\n",
        "#   fig.suptitle(env_id, fontsize=fontsize)\n",
        "  stats_index = 1\n",
        "  handle_list = []\n",
        "  label_list = []\n",
        "  for stats_key, stats in statistics.items():\n",
        "    if len(stats[\"data\"]) > 0:\n",
        "      ax = plt.subplot(rows, cols, stats_index)\n",
        "      ax = add_subplot(agents=agents, env_id=env_id, smoothing=smoothing, hyperparams=hyperparams,\n",
        "                  seeds=seeds, description=stats[\"description\"],\n",
        "                   custom_hyperparams=custom_hyperparams,\n",
        "                  ax=ax, fontsize=fontsize, data=stats[\"data\"], subplot_title=stats[\"y\"],\n",
        "                  data_key=stats_key, num_ticks=num_ticks)\n",
        "      handles, labels = ax.get_legend_handles_labels()\n",
        "      for handle, label in zip(handles, labels):\n",
        "          if label not in label_list:\n",
        "            handle_list.append(handle)\n",
        "            label_list.append(label)\n",
        "      stats_index += 1\n",
        "      fig.add_subplot(ax)\n",
        "#   print(label_list)\n",
        "  fig.legend(handle_list, label_list,\n",
        "             loc=legend_loc, prop={'size': fontsize},\n",
        "             bbox_to_anchor=legend_bbox_to_anchor,\n",
        "             frameon=False,\n",
        "            labelspacing=0.5,\n",
        "            columnspacing=0.5,\n",
        "            handletextpad=0.5,\n",
        "            handlelength=2.,\n",
        "             fancybox=False, shadow=False,\n",
        "             ncol=legend_ncol)#, fancybox=True, shadow=True)\n",
        "#   fig.tight_layout(pad=5)\n",
        "#   fig.subplots_adjust(top=0.80)\n",
        "  with open(\"stats.png\", 'wb') as f:\n",
        "    fig.savefig(f, format='pdf', bbox_inches=\"tight\")\n",
        "  files.download(\"stats.png\")\n",
        "#\n",
        "#   fig.savefig(, facecolor='none', edgecolor='none', format='pdf', bbox_inches=\"tight\")\n",
        "#   fileedit.download_file(file) # this uses the python interface to %download_file\n",
        "\n",
        "#   save_fig_pdf(fig, 'graph')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsZ4Ijx44zJJ"
      },
      "source": [
        "#@title OffTD - lr sweep\n",
        "stats_lr = {}\n",
        "agents = [\n",
        "          \"OffTD\"\n",
        "          ]\n",
        "custom_hyperparams = {}\n",
        "hyperparams = {\n",
        "                \"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [0.1, 0.01, 0.001],\n",
        "               \"alpha_f\": [1e-2],\n",
        "               \"alpha_z\": [1e-2],\n",
        "               \"nonlinear_et\": [False],\n",
        "              \"clipped\": [False],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 5\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats_td_lr = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "stats_lr[agents[0]] = stats_td_lr\n",
        "stats_td_lr = stats_lr[agents[0]]\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\"td_error\": {\"data\": stats_td_lr[\"td_error\"][k],\n",
        "                             \"description\": r'$\\delta$'\n",
        "                             },\n",
        "                \"value_error\": {\"data\": stats_td_lr[\"value_errors\"][k],\n",
        "                             \"description\": r'VE($d_\\mu$)'\n",
        "                             },\n",
        "                \"value\": {\"data\": stats_td_lr[\"values\"][k],\n",
        "                             \"description\": r'$v_w / q_w$'\n",
        "                             },\n",
        "                \"f_td_or_mc_error\": {\"data\": stats_td_lr[\"f_td_or_mc_errors\"][k],\n",
        "                             \"description\": r'$\\delta_F$'\n",
        "                             },\n",
        "                \"f_exp_error\": {\"data\": stats_td_lr[\"f_exp_errors\"][k],\n",
        "                             \"description\": r'F bias'\n",
        "                             },\n",
        "                \"f_var_error\": {\"data\": stats_td_lr[\"f_var_errors\"][k],\n",
        "                             \"description\": r'F variance'\n",
        "                             },\n",
        "                \"rhos_post\": {\"data\": stats_td_lr[\"rhos_post\"][k],\n",
        "                             \"description\": 'rho post'\n",
        "                             },\n",
        "                \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                                  \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                             \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=25,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(0.17, 0.88),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=3, rows=3,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ksOfH_JjFX-"
      },
      "source": [
        "#@title ETD - lr sweep\n",
        "\n",
        "agents = [\n",
        "          \"ETD\"\n",
        "          ]\n",
        "custom_hyperparams = {}\n",
        "hyperparams = {\n",
        "               \"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [0.1, 0.01, 0.001],\n",
        "               \"alpha_f\": [1e-2],\n",
        "               \"alpha_z\": [1e-2],\n",
        "               \"nonlinear_et\": [False],\n",
        "              \"clipped\": [False],\n",
        "              \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 5\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats_etd_lr = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      verbose=False,\n",
        "                                      agents=agents)\n",
        "stats_lr[agents[0]] = stats_etd_lr\n",
        "stats_td_lr = stats_lr[agents[0]]\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\"td_error\": {\"data\": stats_td_lr[\"td_error\"][k],\n",
        "                             \"description\": r'$\\delta$'\n",
        "                             },\n",
        "                \"value_error\": {\"data\": stats_td_lr[\"value_errors\"][k],\n",
        "                             \"description\": r'VE($d_\\mu$)'\n",
        "                             },\n",
        "                \"value\": {\"data\": stats_td_lr[\"values\"][k],\n",
        "                             \"description\": r'$v_w / q_w$'\n",
        "                             },\n",
        "                \"f_td_or_mc_error\": {\"data\": stats_td_lr[\"f_td_or_mc_errors\"][k],\n",
        "                             \"description\": r'$\\delta_F$'\n",
        "                             },\n",
        "                \"f_exp_error\": {\"data\": stats_td_lr[\"f_exp_errors\"][k],\n",
        "                             \"description\": r'F bias'\n",
        "                             },\n",
        "                \"f_var_error\": {\"data\": stats_td_lr[\"f_var_errors\"][k],\n",
        "                             \"description\": r'F variance'\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                             \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=25,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(0.17, 0.88),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=3, rows=3,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIN3JvnOgGzX"
      },
      "source": [
        "#@title ETD - beta sweep\n",
        "\n",
        "agents = [\n",
        "          \"ETD\"\n",
        "          ]\n",
        "custom_hyperparams = {}\n",
        "hyperparams = {\n",
        "               \"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [0.001],\n",
        "               \"alpha_f\": [1e-2],\n",
        "               \"alpha_z\": [1e-2],\n",
        "               \"nonlinear_et\": [False],\n",
        "              \"clipped\": [False],\n",
        "              \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [0., 0.3, 0.6, 0.9, np.inf],\n",
        "              }\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 5\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats_etd_lr = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      verbose=False,\n",
        "                                      agents=agents)\n",
        "stats_lr[agents[0]] = stats_etd_lr\n",
        "stats_td_lr = stats_lr[agents[0]]\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\"td_error\": {\"data\": stats_td_lr[\"td_error\"][k],\n",
        "                             \"description\": r'$\\delta$'\n",
        "                             },\n",
        "                \"value_error\": {\"data\": stats_td_lr[\"value_errors\"][k],\n",
        "                             \"description\": r'VE($d_\\mu$)'\n",
        "                             },\n",
        "                \"value\": {\"data\": stats_td_lr[\"values\"][k],\n",
        "                             \"description\": r'$v_w / q_w$'\n",
        "                             },\n",
        "                \"f_td_or_mc_error\": {\"data\": stats_td_lr[\"f_td_or_mc_errors\"][k],\n",
        "                             \"description\": r'$\\delta_F$'\n",
        "                             },\n",
        "                \"f_exp_error\": {\"data\": stats_td_lr[\"f_exp_errors\"][k],\n",
        "                             \"description\": r'F bias'\n",
        "                             },\n",
        "                \"f_var_error\": {\"data\": stats_td_lr[\"f_var_errors\"][k],\n",
        "                             \"description\": r'F variance'\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                             \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=25,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(0.17, 0.88),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=3, rows=3,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IizfuB78kMkt"
      },
      "source": [
        "#@title X(1)-ETD - lr sweep\n",
        "\n",
        "agents = [\n",
        "          \"X(1)-ETD\"\n",
        "          ]\n",
        "custom_hyperparams = {}\n",
        "hyperparams = {\n",
        "               \"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v_f\": [(0.1, 0.1), (0.01, 0.1), (0.001, 1e-2)],\n",
        "               \"alpha_z\": [1e-2],\n",
        "               \"nonlinear_et\": [False],\n",
        "              \"clipped\": [False],\n",
        "              \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 10\n",
        "\n",
        "number_of_steps = int(1e3)\n",
        "stats_td_lr = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "stats_lr[agents[0]] = stats_td_lr\n",
        "stats_td_lr = stats_lr[agents[0]]\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\"td_error\": {\"data\": stats_td_lr[\"td_error\"][k],\n",
        "                             \"description\": r'$\\delta$'\n",
        "                             },\n",
        "                \"value_error\": {\"data\": stats_td_lr[\"value_errors\"][k],\n",
        "                             \"description\": r'VE($d_\\mu$)'\n",
        "                             },\n",
        "                \"value\": {\"data\": stats_td_lr[\"values\"][k],\n",
        "                             \"description\": r'$v_w / q_w$'\n",
        "                             },\n",
        "                \"f_td_or_mc_error\": {\"data\": stats_td_lr[\"f_td_or_mc_errors\"][k],\n",
        "                             \"description\": r'$\\delta_F$'\n",
        "                             },\n",
        "                \"f_exp_error\": {\"data\": stats_td_lr[\"f_exp_errors\"][k],\n",
        "                             \"description\": r'F bias'\n",
        "                             },\n",
        "                \"f_var_error\": {\"data\": stats_td_lr[\"f_var_errors\"][k],\n",
        "                             \"description\": r'F variance'\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                             \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=25,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(0.17, 0.88),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=3, rows=3,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMYicuhcZhsd"
      },
      "source": [
        "#@title X(1)-ETD - lr_f sweep\n",
        "\n",
        "agents = [\n",
        "          \"X(1)-ETD\"\n",
        "          ]\n",
        "custom_hyperparams = {}\n",
        "hyperparams = {\n",
        "               \"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [0.001],\n",
        "               \"alpha_f\": [0.1, 0.01, 0.001],\n",
        "               \"alpha_z\": [1e-2],\n",
        "               \"nonlinear_et\": [False],\n",
        "              \"clipped\": [False],\n",
        "              \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 5\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats_td_lr = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "stats_lr[agents[0]] = stats_td_lr\n",
        "stats_td_lr = stats_lr[agents[0]]\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\"td_error\": {\"data\": stats_td_lr[\"td_error\"][k],\n",
        "                             \"description\": r'$\\delta$'\n",
        "                             },\n",
        "                \"value_error\": {\"data\": stats_td_lr[\"value_errors\"][k],\n",
        "                             \"description\": r'VE($d_\\mu$)'\n",
        "                             },\n",
        "                \"value\": {\"data\": stats_td_lr[\"values\"][k],\n",
        "                             \"description\": r'$v_w / q_w$'\n",
        "                             },\n",
        "                \"f_td_or_mc_error\": {\"data\": stats_td_lr[\"f_td_or_mc_errors\"][k],\n",
        "                             \"description\": r'$\\delta_F$'\n",
        "                             },\n",
        "                \"f_exp_error\": {\"data\": stats_td_lr[\"f_exp_errors\"][k],\n",
        "                             \"description\": r'F bias'\n",
        "                             },\n",
        "                \"f_var_error\": {\"data\": stats_td_lr[\"f_var_errors\"][k],\n",
        "                             \"description\": r'F variance'\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                             \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=25,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(0.17, 0.88),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=3, rows=3,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYgEkcvhl4z4"
      },
      "source": [
        "#@title X(0)-ETD - lr sweep\n",
        "\n",
        "agents = [\n",
        "          \"X(0)-ETD\"\n",
        "          ]\n",
        "custom_hyperparams = {}\n",
        "hyperparams = {\n",
        "               \"discount\": [1.],\n",
        "               \"lambda\": [0.0],\n",
        "               \"alpha_v_f\": [(0.1, 0.1), (0.01, 0.1), (0.001, 1e-2)],\n",
        "               \"alpha_z\": [1e-2],\n",
        "               \"nonlinear_et\": [False],\n",
        "              \"clipped\": [False],\n",
        "              \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 5\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats_td_lr = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "stats_lr[agents[0]] = stats_td_lr\n",
        "stats_td_lr = stats_lr[agents[0]]\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\"td_error\": {\"data\": stats_td_lr[\"td_error\"][k],\n",
        "                             \"description\": r'$\\delta$'\n",
        "                             },\n",
        "                \"value_error\": {\"data\": stats_td_lr[\"value_errors\"][k],\n",
        "                             \"description\": r'VE($d_\\mu$)'\n",
        "                             },\n",
        "                \"value\": {\"data\": stats_td_lr[\"values\"][k],\n",
        "                             \"description\": r'$v_w / q_w$'\n",
        "                             },\n",
        "                \"f_td_or_mc_error\": {\"data\": stats_td_lr[\"f_td_or_mc_errors\"][k],\n",
        "                             \"description\": r'$\\delta_F$'\n",
        "                             },\n",
        "                \"f_exp_error\": {\"data\": stats_td_lr[\"f_exp_errors\"][k],\n",
        "                             \"description\": r'F bias'\n",
        "                             },\n",
        "                \"f_var_error\": {\"data\": stats_td_lr[\"f_var_errors\"][k],\n",
        "                             \"description\": r'F variance'\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                             \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=25,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(0.17, 0.88),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=3, rows=3,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC4T2m37bDAt"
      },
      "source": [
        "#@title X(0)-ETD - lr sweep\n",
        "\n",
        "agents = [\n",
        "          \"X(0)-ETD\"\n",
        "          ]\n",
        "custom_hyperparams = {}\n",
        "hyperparams = {\n",
        "               \"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [0.001],\n",
        "               \"alpha_f\": [0.1, 0.01, 0.001],\n",
        "               \"alpha_z\": [1e-2],\n",
        "               \"nonlinear_et\": [False],\n",
        "              \"clipped\": [False],\n",
        "              \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 5\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats_td_lr = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "stats_lr[agents[0]] = stats_td_lr\n",
        "stats_td_lr = stats_lr[agents[0]]\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\"td_error\": {\"data\": stats_td_lr[\"td_error\"][k],\n",
        "                             \"description\": r'$\\delta$'\n",
        "                             },\n",
        "                \"value_error\": {\"data\": stats_td_lr[\"value_errors\"][k],\n",
        "                             \"description\": r'VE($d_\\mu$)'\n",
        "                             },\n",
        "                \"value\": {\"data\": stats_td_lr[\"values\"][k],\n",
        "                             \"description\": r'$v_w / q_w$'\n",
        "                             },\n",
        "                \"f_td_or_mc_error\": {\"data\": stats_td_lr[\"f_td_or_mc_errors\"][k],\n",
        "                             \"description\": r'$\\delta_F$'\n",
        "                             },\n",
        "                \"f_exp_error\": {\"data\": stats_td_lr[\"f_exp_errors\"][k],\n",
        "                             \"description\": r'F bias'\n",
        "                             },\n",
        "                \"f_var_error\": {\"data\": stats_td_lr[\"f_var_errors\"][k],\n",
        "                             \"description\": r'F variance'\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                             \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=25,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(0.17, 0.88),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=3, rows=3,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "jyccIJ5zooHb"
      },
      "source": [
        "#@title OffTD/ETD/X(1)-ETD/X(0)-ETD\n",
        "agents = [\n",
        "          \"OffTD\",\n",
        "          \"ETD\",\n",
        "          \"X(1)-ETD\",\n",
        "          \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [0.01],\n",
        "              \"alpha_f\": [0.1],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "              \"clipped\": [False],\n",
        "              \"eta\": [None],\n",
        "               \"positive_followon\": [True],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    \"OffTD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "    \"ETD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "    \"X(1)-ETD\": {\"alpha_v\": [0.01],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "    \"X(0)-ETD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 5\n",
        "smoothing = 5\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "# stats = run(number_of_steps=number_of_steps,\n",
        "#                                       log_every_steps=1,\n",
        "#                                       seeds=seeds,\n",
        "#                                       envs=envs,\n",
        "#                                       custom_hyperparams=custom_hyperparams,\n",
        "#                                       hyperparams=hyperparams,\n",
        "#                                       # verbose=True,\n",
        "#                                       agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats[\"value_errors\"][k],\n",
        "                             \"description\": r'VE($d_\\mu$)'\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                \"f_exp_error\": {\"data\": stats[\"f_exp_errors\"][k],\n",
        "                             \"description\": r'F bias'\n",
        "                             },\n",
        "                \"f_var_error\": {\"data\": stats[\"f_var_errors\"][k],\n",
        "                             \"description\": r'F variance'\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=25,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(0.15, 0.45),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=3, rows=3,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Styz1hJrxZON"
      },
      "source": [
        "#@title OffTD/ETD/X(1)-ETD/X(0)-ETD\n",
        "agents = [\n",
        "          \"OffTD\",\n",
        "          \"ETD\",\n",
        "          \"X(1)-ETD\",\n",
        "          \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [0.01],\n",
        "              \"alpha_f\": [0.1],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "              \"clipped\": [False],\n",
        "              \"eta\": [None],\n",
        "               \"positive_followon\": [True],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    \"OffTD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "    \"ETD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "    \"X(1)-ETD\": {\"alpha_v\": [0.01],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "    \"X(0)-ETD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 5\n",
        "smoothing = 5\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats2 = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats2[\"value_errors\"][k],\n",
        "                             \"description\": r'VE($d_\\mu$)'\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                             \"description\": r'F bias'\n",
        "                             },\n",
        "                \"f_var_error\": {\"data\": stats2[\"f_var_errors\"][k],\n",
        "                             \"description\": r'F variance'\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=25,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(0.15, 0.45),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=3, rows=3,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF_ZRm4eNMia"
      },
      "source": [
        "#@title OffTD/ETD/X(1)-ETD/X(0)-ETD\n",
        "agents = [\n",
        "        #   \"OffTD\",\n",
        "        #   \"ETD\",\n",
        "          \"X(1)-ETD\",\n",
        "        #   \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [0.01],\n",
        "              \"alpha_f\": [0.1],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "              \"clipped\": [False],\n",
        "              \"eta\": [None],\n",
        "               \"positive_followon\": [True],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    # \"OffTD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    \"X(1)-ETD\": {\"alpha_v\": [0.001, 0.01],\n",
        "              \"alpha_f\": [0.1, 0.01],\n",
        "    },\n",
        "    # \"X(0)-ETD\": {\"alpha_v\": [0.001, 0.01],\n",
        "    #           \"alpha_f\": [0.1, 0.01],\n",
        "    # },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 5\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats2 = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats2[\"value_errors\"][k],\n",
        "                             \"description\": r'VE($d_\\mu$)'\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                             \"description\": r'F bias'\n",
        "                             },\n",
        "                \"f_var_error\": {\"data\": stats2[\"f_var_errors\"][k],\n",
        "                             \"description\": r'F variance'\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=25,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(0.15, 0.45),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=3, rows=3,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hnyn8AvHIbS"
      },
      "source": [
        "#@title OffTD/ETD/X(1)-ETD/X(0)-ETD\n",
        "agents = [\n",
        "        #   \"OffTD\",\n",
        "        #   \"ETD\",\n",
        "          \"X(0)-ETD\",\n",
        "        #   \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [0.01],\n",
        "              \"alpha_f\": [0.1],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "              \"clipped\": [False],\n",
        "              \"eta\": [None],\n",
        "               \"positive_followon\": [True],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    # \"OffTD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    \"X(0)-ETD\": {\"alpha_v\": [0.001, 0.01],\n",
        "              \"alpha_f\": [0.1, 0.01],\n",
        "    },\n",
        "    # \"X(0)-ETD\": {\"alpha_v\": [0.001, 0.01],\n",
        "    #           \"alpha_f\": [0.1, 0.01],\n",
        "    # },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 5\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats2 = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats2[\"value_errors\"][k],\n",
        "                             \"description\": r'VE($d_\\mu$)'\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                             \"description\": r'F bias'\n",
        "                             },\n",
        "                \"f_var_error\": {\"data\": stats2[\"f_var_errors\"][k],\n",
        "                             \"description\": r'F variance'\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=25,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(0.15, 0.45),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=3, rows=3,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAID5O06U7Dm"
      },
      "source": [
        "#@title OffTD/ETD/X(1)-ETD/X(0)-ETD\n",
        "agents = [\n",
        "          \"OffTD\",\n",
        "          \"ETD\",\n",
        "          \"X(1)-ETD\",\n",
        "          \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [0.01],\n",
        "              \"alpha_f\": [0.1],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "              \"clipped\": [False],\n",
        "              \"eta\": [None],\n",
        "               \"positive_followon\": [True],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    \"OffTD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "    \"ETD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "    \"X(1)-ETD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "    \"X(0)-ETD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.01],\n",
        "    },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 5\n",
        "smoothing = 5\n",
        "\n",
        "number_of_steps = int(2e4)\n",
        "stats2 = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats2[\"value_errors\"][k],\n",
        "                             \"description\": r'VE($d_\\mu$)'\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                # \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                #              \"description\": r'F bias'\n",
        "                #              },\n",
        "                \"f_var_error\": {\"data\": stats2[\"f_var_errors\"][k],\n",
        "                             \"description\": r'F variance'\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=25,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(0.1, 0.45),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=3, rows=3,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "SUI0mPxxWAzk"
      },
      "source": [
        "#@title OffTD/ETD/X(1)-ETD/X(0)-ETD\n",
        "agents = [\n",
        "          \"OffTD\",\n",
        "          \"ETD\",\n",
        "          \"X(1)-ETD\",\n",
        "          \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [0.01],\n",
        "               \"alpha_f\": [0.1],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "               \"clipped\": [False],\n",
        "               \"eta\": [None],\n",
        "               \"positive_followon\": [True],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    \"OffTD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "    \"ETD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "    \"X(1)-ETD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.1],\n",
        "    },\n",
        "    \"X(0)-ETD\": {\"alpha_v\": [0.001],\n",
        "              \"alpha_f\": [0.01],\n",
        "    },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 20\n",
        "smoothing = 10\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "# stats2 = run(number_of_steps=number_of_steps,\n",
        "#                                       log_every_steps=1,\n",
        "#                                       seeds=seeds,\n",
        "#                                       envs=envs,\n",
        "#                                       custom_hyperparams=custom_hyperparams,\n",
        "#                                       hyperparams=hyperparams,\n",
        "#                                       # verbose=True,\n",
        "#                                       agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats2[\"value_errors\"][k],\n",
        "                             \"y\": r'VE($d_\\mu$)',\n",
        "                             'description': \"Value error\"\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                # \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                #              \"description\": r'F bias'\n",
        "                #              },\n",
        "                \"f_var_error\": {\"data\": stats2[\"f_var_errors\"][k],\n",
        "                             \"y\": r'F variance',\n",
        "                             \"description\": \"Follow-on variance\"\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=28,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(.05, 1.),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=2, rows=1,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO_G3Op_PB-J"
      },
      "source": [
        "#@title OffTD\n",
        "agents = [\n",
        "          \"OffTD\",\n",
        "        #   \"ETD\",\n",
        "        #   \"X(1)-ETD\",\n",
        "        #   \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [None],\n",
        "               \"d\": [0.4, 0.5, 0.8, 0.9],\n",
        "               \"df\": [0.4],#, 0.8, 0.9],\n",
        "               \"dz\": [0.4],# 0.5, 0.8, 0.9],\n",
        "               \"alpha_f\": [0.1],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "               \"clipped\": [False],\n",
        "               \"eta\": [None],\n",
        "               \"positive_followon\": [True],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    # \"OffTD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(1)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(0)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.01],\n",
        "    # },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 10\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "# stats2 = run(number_of_steps=number_of_steps,\n",
        "#                                       log_every_steps=1,\n",
        "#                                       seeds=seeds,\n",
        "#                                       envs=envs,\n",
        "#                                       custom_hyperparams=custom_hyperparams,\n",
        "#                                       hyperparams=hyperparams,\n",
        "#                                       # verbose=True,\n",
        "#                                       agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats2[\"value_errors\"][k],\n",
        "                             \"y\": r'VE($d_\\mu$)',\n",
        "                             'description': \"Value error\"\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                # \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                #              \"description\": r'F bias'\n",
        "                #              },\n",
        "                \"f_var_error\": {\"data\": stats2[\"f_var_errors\"][k],\n",
        "                             \"y\": r'F variance',\n",
        "                             \"description\": \"Follow-on variance\"\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=28,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(.05, 1.),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=2, rows=1,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yILf6zJguvFF"
      },
      "source": [
        "#@title ETD\n",
        "agents = [\n",
        "        #   \"OffTD\",\n",
        "          \"ETD\",\n",
        "        #   \"X(1)-ETD\",\n",
        "        #   \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [None],\n",
        "               \"d\": [0.5, 0.8, 0.9],\n",
        "               \"df\": [0.4],#, 0.5, 0.8, 0.9],\n",
        "               \"dz\": [0.4],# 0.5, 0.8, 0.9],\n",
        "               \"alpha_f\": [0.1],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "               \"clipped\": [False],\n",
        "               \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    # \"OffTD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(1)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(0)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.01],\n",
        "    # },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 10\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "# stats3 = run(number_of_steps=number_of_steps,\n",
        "#                                       log_every_steps=1,\n",
        "#                                       seeds=seeds,\n",
        "#                                       envs=envs,\n",
        "#                                       custom_hyperparams=custom_hyperparams,\n",
        "#                                       hyperparams=hyperparams,\n",
        "#                                       # verbose=True,\n",
        "#                                       agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats3[\"value_errors\"][k],\n",
        "                             \"y\": r'VE($d_\\mu$)',\n",
        "                             'description': \"Value error\"\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                # \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                #              \"description\": r'F bias'\n",
        "                #              },\n",
        "                \"f_var_error\": {\"data\": stats3[\"f_var_errors\"][k],\n",
        "                             \"y\": r'F variance',\n",
        "                             \"description\": \"Follow-on variance\"\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=28,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(.05, 1.),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=2, rows=1,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI8HldZzwyDk"
      },
      "source": [
        "#@title X(1)-ETD\n",
        "agents = [\n",
        "        #   \"OffTD\",\n",
        "        #   \"ETD\",\n",
        "          \"X(1)-ETD\",\n",
        "        #   \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [None],\n",
        "               \"d\": [0.9],\n",
        "               \"df\": [0.4, 0.5, 0.8, 0.9],\n",
        "               \"dz\": [0.4],# 0.5, 0.8, 0.9],\n",
        "               \"alpha_f\": [None],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "               \"clipped\": [False],\n",
        "               \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    # \"OffTD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(1)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(0)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.01],\n",
        "    # },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 10\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats4 = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats4[\"value_errors\"][k],\n",
        "                             \"y\": r'VE($d_\\mu$)',\n",
        "                             'description': \"Value error\"\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                # \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                #              \"description\": r'F bias'\n",
        "                #              },\n",
        "                \"f_var_error\": {\"data\": stats4[\"f_var_errors\"][k],\n",
        "                             \"y\": r'F variance',\n",
        "                             \"description\": \"Follow-on variance\"\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=28,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(.05, 1.),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=2, rows=1,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OZJluTO5_jz"
      },
      "source": [
        "#@title X(1)-ETD\n",
        "agents = [\n",
        "        #   \"OffTD\",\n",
        "        #   \"ETD\",\n",
        "          \"X(1)-ETD\",\n",
        "        #   \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [None],\n",
        "               \"d\": [0.8],\n",
        "               \"df\": [0.4, 0.5, 0.8, 0.9],\n",
        "               \"dz\": [0.4],# 0.5, 0.8, 0.9],\n",
        "               \"alpha_f\": [None],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "               \"clipped\": [False],\n",
        "               \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    # \"OffTD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(1)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(0)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.01],\n",
        "    # },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 10\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats4 = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats4[\"value_errors\"][k],\n",
        "                             \"y\": r'VE($d_\\mu$)',\n",
        "                             'description': \"Value error\"\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                # \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                #              \"description\": r'F bias'\n",
        "                #              },\n",
        "                \"f_var_error\": {\"data\": stats4[\"f_var_errors\"][k],\n",
        "                             \"y\": r'F variance',\n",
        "                             \"description\": \"Follow-on variance\"\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=28,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(.05, 1.),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=2, rows=1,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZUuxqBw6oHK"
      },
      "source": [
        "#@title X(1)-ETD\n",
        "agents = [\n",
        "        #   \"OffTD\",\n",
        "        #   \"ETD\",\n",
        "          \"X(1)-ETD\",\n",
        "        #   \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [None],\n",
        "               \"d\": [0.5],\n",
        "               \"df\": [0.9],\n",
        "               \"dz\": [0.4],# 0.5, 0.8, 0.9],\n",
        "               \"alpha_f\": [None],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "               \"clipped\": [False],\n",
        "               \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    # \"OffTD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(1)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(0)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.01],\n",
        "    # },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 10\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats4 = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats4[\"value_errors\"][k],\n",
        "                             \"y\": r'VE($d_\\mu$)',\n",
        "                             'description': \"Value error\"\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                # \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                #              \"description\": r'F bias'\n",
        "                #              },\n",
        "                \"f_var_error\": {\"data\": stats4[\"f_var_errors\"][k],\n",
        "                             \"y\": r'F variance',\n",
        "                             \"description\": \"Follow-on variance\"\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=28,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(.05, 1.),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=2, rows=1,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRUcIHii42Sg"
      },
      "source": [
        "[np.any(np.array(i) > 1000) for i in stats4[\"value_errors\"][0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Th7K7TuxD4B"
      },
      "source": [
        "#@title X(0)-ETD\n",
        "agents = [\n",
        "        #   \"OffTD\",\n",
        "        #   \"ETD\",\n",
        "        #   \"X(1)-ETD\",\n",
        "          \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [None],\n",
        "               \"d\": [0.9],\n",
        "               \"df\": [0.4, 0.5, 0.8, 0.9],\n",
        "               \"dz\": [0.4],# 0.5, 0.8, 0.9],\n",
        "               \"alpha_f\": [None],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "               \"clipped\": [False],\n",
        "               \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    # \"OffTD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(1)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(0)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.01],\n",
        "    # },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 10\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats5 = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats5[\"value_errors\"][k],\n",
        "                             \"y\": r'VE($d_\\mu$)',\n",
        "                             'description': \"Value error\"\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                # \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                #              \"description\": r'F bias'\n",
        "                #              },\n",
        "                \"f_var_error\": {\"data\": stats5[\"f_var_errors\"][k],\n",
        "                             \"y\": r'F variance',\n",
        "                             \"description\": \"Follow-on variance\"\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=28,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(.05, 1.),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=2, rows=1,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCliBKZwB35l"
      },
      "source": [
        "#@title X(0)-ETD\n",
        "agents = [\n",
        "        #   \"OffTD\",\n",
        "        #   \"ETD\",\n",
        "        #   \"X(1)-ETD\",\n",
        "          \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [None],\n",
        "               \"d\": [0.8],\n",
        "               \"df\": [0.4, 0.5, 0.8, 0.9],\n",
        "               \"dz\": [0.4],# 0.5, 0.8, 0.9],\n",
        "               \"alpha_f\": [None],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "               \"clipped\": [False],\n",
        "               \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    # \"OffTD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(1)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.1],\n",
        "    # },\n",
        "    # \"X(0)-ETD\": {\"alpha_v\": [0.001],\n",
        "    #           \"alpha_f\": [0.01],\n",
        "    # },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 1\n",
        "smoothing = 10\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats5 = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats5[\"value_errors\"][k],\n",
        "                             \"y\": r'VE($d_\\mu$)',\n",
        "                             'description': \"Value error\"\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                # \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                #              \"description\": r'F bias'\n",
        "                #              },\n",
        "                \"f_var_error\": {\"data\": stats5[\"f_var_errors\"][k],\n",
        "                             \"y\": r'F variance',\n",
        "                             \"description\": \"Follow-on variance\"\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=28,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(.05, 1.),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=2, rows=1,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mvi-UGn5k3S"
      },
      "source": [
        "[np.any(np.array(i) > 1) for i in stats5[\"value_errors\"][0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xfr_vfDxI0E"
      },
      "source": [
        "#@title OffTD/ETD/X(1)-ETD/X(0)-ETD\n",
        "agents = [\n",
        "          \"OffTD\",\n",
        "          \"ETD\",\n",
        "          \"X(1)-ETD\",\n",
        "          \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [None],\n",
        "               \"d\": [0.4, 0.5, 0.8, 0.9],\n",
        "               \"df\": [0.4],#, 0.5, 0.8, 0.9],\n",
        "               \"dz\": [0.4],# 0.5, 0.8, 0.9],\n",
        "               \"alpha_f\": [None],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "               \"clipped\": [False],\n",
        "               \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    \"OffTD\": {\"d\": [0.5],\n",
        "    },\n",
        "    \"ETD\": {\"d\": [0.9],\n",
        "    },\n",
        "    \"X(1)-ETD\": {\"d\": [0.9],\n",
        "              \"df\": [0.5],\n",
        "    },\n",
        "    \"X(0)-ETD\": {\"d\": [0.9],\n",
        "              \"df\": [0.5],\n",
        "    },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 20\n",
        "smoothing = 10\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "stats5 = run(number_of_steps=number_of_steps,\n",
        "                                      log_every_steps=1,\n",
        "                                      seeds=seeds,\n",
        "                                      envs=envs,\n",
        "                                      custom_hyperparams=custom_hyperparams,\n",
        "                                      hyperparams=hyperparams,\n",
        "                                      # verbose=True,\n",
        "                                      agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats5[\"value_errors\"][k],\n",
        "                             \"y\": r'VE($d_\\mu$)',\n",
        "                             'description': \"Value error\"\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                # \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                #              \"description\": r'F bias'\n",
        "                #              },\n",
        "                \"f_var_error\": {\"data\": stats5[\"f_var_errors\"][k],\n",
        "                             \"y\": r'F variance',\n",
        "                             \"description\": \"Follow-on variance\"\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=28,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(.05, 1.),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=2, rows=1,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_a88Ze9DQfA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "6c946713-c0c7-49f4-9bb8-a1e7f618a539"
      },
      "source": [
        "#@title OffTD/ETD/X(1)-ETD/X(0)-ETD\n",
        "agents = [\n",
        "          \"OffTD\",\n",
        "          \"ETD\",\n",
        "          \"X(1)-ETD\",\n",
        "          \"X(0)-ETD\",\n",
        "          ]\n",
        "hyperparams = {\"discount\": [1.],\n",
        "               \"lambda\": [0.],\n",
        "               \"alpha_v\": [None],\n",
        "               \"d\": [0.4, 0.5, 0.8, 0.9],\n",
        "               \"df\": [0.4],#, 0.5, 0.8, 0.9],\n",
        "               \"dz\": [0.4],# 0.5, 0.8, 0.9],\n",
        "               \"alpha_f\": [None],\n",
        "               \"alpha_z\": [0.1],\n",
        "               \"nonlinear_et\": [False],\n",
        "               \"clipped\": [False],\n",
        "               \"eta\": [None],\n",
        "               \"positive_followon\": [False],\n",
        "               \"beta\": [np.inf],\n",
        "              }\n",
        "custom_hyperparams = {\n",
        "    \"OffTD\": {\"d\": [0.5],\n",
        "    },\n",
        "    \"ETD\": {\"d\": [0.9],\n",
        "    },\n",
        "    \"X(1)-ETD\": {\"d\": [0.9],\n",
        "              \"df\": [0.5],\n",
        "    },\n",
        "    \"X(0)-ETD\": {\"d\": [0.9],\n",
        "              \"df\": [0.5],\n",
        "    },\n",
        "}\n",
        "envs = [\n",
        "        \"FiveStateMDP\",\n",
        "        # \"TabularFiveStateMDP\"\n",
        "        ]\n",
        "seeds = 20\n",
        "smoothing = 10\n",
        "\n",
        "number_of_steps = int(1e4)\n",
        "# stats5 = run(number_of_steps=number_of_steps,\n",
        "#                                       log_every_steps=1,\n",
        "#                                       seeds=seeds,\n",
        "#                                       envs=envs,\n",
        "#                                       custom_hyperparams=custom_hyperparams,\n",
        "#                                       hyperparams=hyperparams,\n",
        "#                                       # verbose=True,\n",
        "#                                       agents=agents)\n",
        "\n",
        "for k, env_id in enumerate(envs):\n",
        "  if env_id == \"FiveStateMDP\":\n",
        "    n_params = 3\n",
        "  elif env_id == \"TabularFiveStateMDP\":\n",
        "    n_params = 5\n",
        "  else:\n",
        "    n_params = 6\n",
        "#   import pdb;pdb.set_trace()\n",
        "  statistics = {\n",
        "    #   \"td_error\": {\"data\": stats[\"td_error\"][k],\n",
        "    #                          \"description\": r'$\\delta$'\n",
        "    #                          },\n",
        "                \"value_error\": {\"data\": stats5[\"value_errors\"][k],\n",
        "                             \"y\": r'VE($d_\\mu$)',\n",
        "                             'description': \"Value error\"\n",
        "                             },\n",
        "                # \"value\": {\"data\": stats[\"values\"][k],\n",
        "                #              \"description\": r'$v_w / q_w$'\n",
        "                #              },\n",
        "                # \"f_td_or_mc_error\": {\"data\": stats[\"f_td_or_mc_errors\"][k],\n",
        "                #              \"description\": r'$\\delta_F$'\n",
        "                #              },\n",
        "                # \"f_exp_error\": {\"data\": stats2[\"f_exp_errors\"][k],\n",
        "                #              \"description\": r'F bias'\n",
        "                #              },\n",
        "                \"f_var_error\": {\"data\": stats5[\"f_var_errors\"][k],\n",
        "                             \"y\": r'F variance',\n",
        "                             \"description\": \"Follow-on variance\"\n",
        "                             },\n",
        "                #   \"rewards\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #                   \"description\": \"Episode rewards\"},\n",
        "                # #  \"ep_timesteps\": {\"data\": stats_td_lr[\"ep_timesteps\"][k],\n",
        "                # #                   \"description\": \"Episode timesteps\"},\n",
        "                # \"return\": {\"data\": stats_td_lr[\"rewards\"][k],\n",
        "                #              \"description\": \"Episode returns\"},\n",
        "                # \"zloss\": {\"data\": stats_td_lr[\"zloss\"][k],\n",
        "                #              \"description\": r\"$\\delta_z$\"}\n",
        "                }\n",
        "\n",
        "  plot_statistics(env_id=env_id, agents=agents,\n",
        "                  statistics=statistics,\n",
        "                  custom_hyperparams=custom_hyperparams,\n",
        "                  hyperparams=hyperparams,\n",
        "                  smoothing=smoothing, fontsize=21,\n",
        "                  legend_loc='lower left',\n",
        "                  legend_bbox_to_anchor=(.1, 1.),\n",
        "                  legend_ncol=4,\n",
        "                  num_ticks=2,\n",
        "                  cols=2, rows=1,\n",
        "                  seeds=seeds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OffTD_0_#dfc27d\n",
            "ETD_1_#01665e\n",
            "X(1)-ETD_2_#80cdc1\n",
            "X(0)-ETD_3_#8c510a\n",
            "OffTD_0_#dfc27d\n",
            "ETD_1_#01665e\n",
            "X(1)-ETD_2_#80cdc1\n",
            "X(0)-ETD_3_#8c510a\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0fb50e4d-5e16-4846-b609-385e3c7e5e40\", \"stats.png\", 148261)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArsAAAFsCAYAAADMsHGIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZhcVZn48e9b1V3V+5KkO4QkEBKQVTYVBAQCOAwuuCCjI6Bk1B8jouOoKDougKOOy+CooOPCOLjhwqKOigqCkS3IvglJ2Dp7el+qu6u6tvf3xznVVCpV1Uu6u7oq7+d57nO7zrnn3lPVt269dercc0RVMcYYY4wxphIFSl0BY4wxxhhjZosFu8YYY4wxpmJZsGuMMcYYYyqWBbvGGGOMMaZiWbBrjDHGGGMqlgW7xhhjjDGmYlmwa4wxxhhjKpYFu8YYY4wxpmJZsGuMMcYYYyqWBbvGGGOMMaZiWbBrjDHGGGMqlgW7xhhjjDGmYlmwa4wxxhhjKpYFu8YYY4wxpmJZsGuMMcYYYyqWBbvGGGOMMaZiWbBrjDHGGGMqlgW7xhhjjDGmYlmwa4wxxhhjKpYFu8YYY4wxpmJZsGuMMcYYYyqWBbvGGGOMMaZiWbBrjDHGGGMqlgW7xhhjjDGmYlmwa4wxxhhjKpYFu8YYY4wxpmJZsGuMMcYYYyqWBbvGGGOMMaZiWbBrjDHGGGMqlgW7xhhjjDGmYlmwa4wxxhhjKpYFu8YYY4wxpmJZsGuMMcYYYyqWBbvGGGOMMaZiWbBrjDHGGGMqlgW7xhhjjDGmYlmwa4wxxhhjKpYFu2ZGicgCEblCRB4UkX4RiYrICyLyAxE5oUi5g0Tk1yLSKyJpEVEROdrnVYnI50TkeRFJ+LwBv57KssLvryMnPSkifSKyUURuEJH3ikjj3Lxi5WeSr/Wv/LZrp/F/Wl2gbNr/35/358qHRaStpC/GPCUi5/nX7CkRCRXY5nARiYvIiIgckJO3v3/vXp2TXi8i7xCRq0XkfhEZ88e5okhdlopITES+Nc3nsmaS582bRGTFNM63Dn+cfGXjItItIo+JyPdF5I0iEpzO86h0s3XOZeUfLyK/EZEeERkVkUdF5BIRkTzbvsLX5WPTfC5XTPLcOVpEVk/jnFvrj5OvbExEOkXkARH5loicPp3nYHZVVeoKmMohImcANwCtQC9wFzAKHAq8E3iniHwd+LCqprPKBYAbgSOBdcCzQBro85v8K/BJYBtwExADTgF+lVOFo4GjgOeAu/NUcTjn8R+Bnf7vRmA58EbgXOCLIvJ+Vf3x5F+Bvc5N7P6aZjzs138AOnLyDgROAjp9fq6dOY/vwZ0TAPXAEuDvgDcAXxCRTwJfVVWdSuUrmapeLyLvAM7CvXcuz87377lrgWrg46r6Qs4u/iNnnXEQ8MMp1mWbiPwPcJGIfE1VN06lfJZC50vGZtz5+IM8eWcBi9n1XMroybN9Zh8BoBl4CbAG+Cdgo4icr6oPTrrme4FZPOcQkTfiPiOCwJ24/9kZwDXAicD5OXV5QERuAT4hIteqah/TU+izJKMP93mU75w7F3e9yv6cyVif83gE9/zAPccW4AjgYuBiEfkrcIGq5p67ZrJU1RZb9ngBXgGM4YLUTwPVOfmvArYAClyVk7fKp99ZYN93+fyVE9ThCr/ddRNs1+G3W50nr9nvJ+m3eVepX9v5tvjXRYEV0yy/xpdfO8F2a/12a/Lk1QIfwH1IKPDZUr8u820B9gci/n15WE7ev/jX7X4gmJN3pH8ffzvPPlfhApZ/Bo4FrvT7uWKCuuwHpICfz9b5Mt1zKWubFZlzu0D+KuDnfpsIcGSp/8fzbZmlc64V6Pdlz8lKXww849MvyFPuJJ/3pWk8j0l9lkywj4KfM1nbrPbbdBTIPwq43W+zHVha6v9xuS7WjcHsMf8z0g+AEHClqv67qiayt1HVu4Ezcd+CPyQir8zKXurXzxc4xFK/j0L5M0ZVB1X1CtwHLMA1Yj+VzzuqGlXVq4HX4YKoT4nIS0tcrXlFVTcBn8K9L6/1LWuIyH7A53Ff6N6jqqmcopcAmfd07j6fU9X3qOp3VPVhIJG7TYG6bAb+ArxZRBZP9zmVkn/ubwP+B2jwa5NlNs454N24ls5fq+rNWcfqBDLdFD6apy734D5T3lWoW8V8p6qP4T43b8X9ovX10taofFmwa2bCa3BdFbYDXyi0kao+DXwTd1H7cKaPHO5DEODCrH5L14nvswkcALv2FZ3VZ+Pq+mPcz1e1wEWzfTwzPaq6Fvgp7pz6l9LWZl66GteSdgIuoAD4b1yw9hVVfTx7YxFpAM4DnlfVdTNcl5/gfsJeM8P7nWsfwf2i8HIROanUlZmHZvqce71f35gn73e4BpQjRWT/PPnXA4uAN0/1ScwX/ovB+3Gtu28WkeUlrlJZsmDXzITX+fUNuS26efzEr8/E9ef9Aa5PE7j+UT/wy924/nk/wH2wkJWX79v/bPiZX582R8cz02P/pwLU9Y1/D64F9gsichnwWmAj8Nk8RU7FBSVrZ6E6f/br1xXdap5T1UHg9/6hnXM5ZuGcO9qvH87NUNU48KR/eFSespVyzj0DPISL2U4tcXXKkt2gNgc67vpMWd44s+Lkz+52l2sBmYvMZG7YeAKI4/rGNqrqGnF33/89cLeqrskt4PPr8+XNskf9+tDJFgj884Vl+b9Of+cHk/1fz0eZ/9MqEamexBeucVc+fOcu/6/Ljz0l7+tw5cN3XgR8Jyvpe5cfe0reFv8rH77zIVx/1oyXX37sKQ/l2e5l7PqeefjyY0952WTrPlmq+oSIfBl309AXcS1EF6lqLM/mJ/v1/bNQj+dFpAc4TkRqChy/XDyKuwFp0teGjKvOqd/lnPvIzSN5z7mrzqnf7Zz7yM0jec+5q86p3+2c+8jNI7udc1edU7/bOfeRm0fm7TknIk24zwqArQUOtxV4Oa6/cK4HcX2BKyFAfBT3PKd8zhlr2TUzY6Ffd0+0oaomcTcbgPt5aT7L3KW9oKS1mL9eKDK0zpo5rEf23fT2v8rv67i+zQA3qupfCmx3pF/n3i0+UzYAYab3gX1qseGcZrieE7Frw8Rm4pxryPp7tED5zC9/uw0XqapDwA5gPxFpLV7dvC4scs51TGN/e8LOuT1gLbvGFJZpcSnL1to5UGzosbkcIie7Zcz+V/ldjhvSCOA0EVmoqr15tmv36+kO1TSRzH6nc9PnREOPzSW7NkxsPp1zS3HnXP8E2+YqNvRYviHrZpOdc3vAgl0zEzIXsAk/wESkCjeUDMz9xWKqMi3Ps3URLneXqmpHqSvBrr8QTPXDrOKJm8zlYtz79E/A24CryH+jWOYn48gsVWfIr1uy6vef7P4rz92qem1O2voSdGUqxK4NRczgOZf9ZbqOF8+fbPVFykP+c+66PNv9SlVzx27P27WuROyc2wMW7M6BKfR9LVeP4cY0fDkw0SQMR+CGpRkEcgcVn2+O8eunJlugzPu+lqvM/+mZqfTXhcJ9dPNs913gu5PcdlJ9IH0/3lk9X/yQS9fiuqx9CPgNbmzPC0Xkh6p6R06RAb9umqUqZQKbgay0c8nf3zI32J1PpnxtyCjURzfPdpM+5ybb79b34y2bc05Vh0RkEHfeLCP/673MrzcVqFK+c+7CPNt1sPtERfPJtM85Y312zcy4xa/PFZHqCbY9z69v1axZ1Oapt/l17sXZzC/2fyrsE8BhuPfbj1R1APigz/uOiNTkbN/l17PVLzDzq854/35VXaGqkrOsmaXj7zERacbdUAt2zuUz0+fcY359bG6G/7w5Ime7XPnOudzzTfz46vOSiByEC3bTvDhUp5kCC3bNTPg97uaCpcDHC20kIgfz4niBX52bqk2Pn/byJNxNEd8rcXVMAX6kjn/EnVPfKG1t5hcRORT4N9w5/N5Muqr+HPcF9UDcbIfZMgHDIbNUrUNws2s9PUv7nwtX4X46/6uq3lfqyswns3TO/davz82T93qgBnjCT2iRW58mYF9gs6qWZRcnEQnipkUW3PCe20pcpbJkwa7ZY76F9p24IcWuFJF/831zx4nIicBtuEkavjZfPyREpFlELgf+1yddXOCmClNCIlIjIu/HDSofxE1Xaz/veX5Ww2txXYY+o6q5XYbeh7uL/aMickRWeqbV6LhZqNMq3Mgt95fjsGMislJEfo6b0SuCG0vWeLN4zl2L64LwRhE5J+t47cCX/cOvFCj7ClyQWJatoSJyJG72tDNxkzZ9qLQ1Kl/WZ9fMCFV9QEReB/wCNy3kh0TkXiCK+8aeGYv3auDS0tRyNx/PGiKrAdf36xjcxXoAeJ+q/rREdSsH/ykihUZj6FHVmfo/v8e34IK7SWUf4GX+7xjwYeBrM3SsSvE+4ETcQPy7vTaquklEPoNrpfyuiLzKf2m9C3dDz+pCOxaRX+KmLoUXp/p+j4iclbX/V+5W8MUJGH43tacy7pACNxZl5LvBaFqyjhPA9SV9Ce46JrhW6QtU9cn8pfdas3LOqWq/v07fBNwoImtxN769GnfT2c8ofK/Inp5zr5rgnLtWVQuN1jAVi7KOE8T1Mz4cWOnT1uHOuR0zcKy9k6raYsuMLbiWmytxF7xBXDCyCfghcEKBMqtxP0NfVyC/w52qEx77imL7yd1f1pLC3cW/EbgBNz1wQ6lfy/m65Lx2hZaOIuXX+G3WTnCctTn7TPtz6nng17hWjoWlfj3m24L70jYEJIFjimwXxM3KpMAlWenf9GknFiiX+/7ZbSlQ7g7crz+Lp/h81kx0PL9cMYlzaU2RbVbk2WccN2rMY8D/AG8AgqX+H8+3ZbbPOb/N8bguDX24RpTHcN3iAkXKPIfrqxua4vO5YpLnXLHzKfM+WV1km9V59jmG68d8P/CtYuVtmfwi/gU3xhhj8D8xPw58V1XfO9H2k9znfrjRV25U1bdNtL3Zu8zSOfcqXKvxl1X1spnYpylfFuwaY4zZhYj8GHgLsEpVt8/A/r6J+8XkCFXdsKf7M5VnFs653+G6VaxSVRubdi9nN6gZY4zJ9Um//sSe7khEluJu6vqeBbqmiJk8514OvBb4Dwt0DVjLrjHGGGOMqWDWsmuMMcYYYyqWBbvGGGOMMaZiWbBrjDHGGGMqlgW7xhhjjDGmYlmwa4wxxhhjKpYFu8YYY4wxpmJZsGuMMcYYYyqWBbvGGGOMMaZiWbBrjDHGGGMqlgW7puKIyE9EREXks5PYdpXfdlhEGqZxrDW+/BXTqqwxpiT8+7bY8ugM7L8jJ22FT1+7J/s2cy/f/9OUj6pSV8CYWfAj4DzgfOAzE2x7gV//UlWHZ7VWxpj56CYg33t/81xXxBgzOyzYNZXoNmAnsFJETlTVe4tsmwl2fzT71TLGzEOXqmpHqSth5r1DgUSpK2Gmx7oxmIqjqingev/wgkLbicgrgQOBHcDtc1A1Y4wxZUhV16vqc6Wuh5keC3ZNpfqhX79VRKoLbPMOv75eVVMiUisi7xaRX4rIcyISFZFBEVknIv9PRGSyBxeRtb6P14oC+QX7f4nI8SJyg4jsEJG4iGwVkWtFZL/JHj9rX3Ui8gkRecT3Sx4WkftE5MJi9RKRkIh8RkTWi8iYiPwq93mJyHl+XxERGcg55qdE5Mms1/AuETm/wDE7/D5FRD4gIo+JyOie9pk0ZiaJyHIR+baIbPLviS5/rTh+Bo9xgX+vDPr3zhMi8kkRqc3Z7lP+PfOenPRDsvocn5uT90qffuMU6zSt97P/+10i8qgv1yMiPxKRfSd53HYRSYhIp4gEC2xzmn9Od2SlLRWRj4nIn0Vki/9fdYvIb0XktAL7mcx1LV8f7ICIvF1ErheRDVnX2Id9HUJ5jjV+n4c/p37kz6WYiDwuIu8s8posF5FviMhG/5r2iciDInK5iDTlbCu+bneISL/f/9P+uHUFX/hKpaq22FKRC/A4oMAb8uRVAz0+/0ifdoR/vAP4M/BTXIvvqE+/Ns9+1vi8K3LS1/r0FQXqpkBHnvT3ASm//BX4BfCY374LOHQKz789q+wO4HfALcCAT7u6QL02++2GfZlfAP+d87y+4+t4p3+d7vb5jcCDfptu4Aa/r5hP+2aeY3Zk7TOO64byM+DmUp9DtlTu4s+5gu/RnG1f6s9nBdb7c/4e/zgJ/GOB/XfkpK3w6WvzbP8dnxf175kbso75V6A+a9tX+fQf5+zj4qzndU1O3id8+vun8Brtyfv5S/79/CfgRmBr1utXM8nj3+LLnFUg/1qf/66stPf7tI3AH/y15D4g7Zd35tlP0etakf9ng0/vBe7yx/oj0O/TbwUCOWXW+Lz/BTqBF3y5tf7YCvxTnjqenLXfDtx1+TfAMz7t6KxtA7hfNxWI4D7PbsZd2zPnU22p34NzuZS8ArbYMlsLcKl/Y/8iT94bfN5jWWltwKvzXJwWAw/57V+Vk5e5cF2Rk565eK4oULd8F85X4j44twOvyMl7ty9z3xSe/+98mauzP1z883kg34cIL35QPgMszbPPzPOKAqfmyb/a598BNGalH+Iv7Aq8KadMBy9+mB5e6vPGlr1jyTrXV0ywnfDiF+cvAZKV9xYfoAznvl8KvMdXkCfY9ftR/94/KCu9GRdEKfC1rPQQMAJszdnPz4ExXKD3t5y8P/r9HDGF12hP3s9d2cfCBYb3+bw1kzz+eX77H+XJC+OCvyjQlJV+VL7nCLwc90V/gKwvDj6v6HWtyP8zBLwJqM5Jb+LF6+8FOXlrss69q4FgVt65BY6zwL+eClzG7p9RJwDtWY8/6rf9C7Akp76ZLwhfLPV7cC6XklfAFltmawH2xQWPu1wMfd4N/g1/6ST39Xd++6ty0jMXrity0jMXzxUF9pfvgvYrCrRE+/xf+/xjJlHfo/22D+ZeGH3+MT7/13nqpcC5BfabeV7X5Mmrx7WCp4BD8uRf4sv+OSe9Yyr/C1tsmYkl61wvtKzw253mH2/KDWp8fuZacnme/XfkpK0gf7D7F59+UZ79H4FrkRwB6rLS/+TLZAfHO/2+MkFqu0+vwgXkXWQF6xO8Pnv6fn5vnjKZYO5/J1mHOlzLZCT7ufu8c/y+bpjC//zzvszZOekFr2vF/p8THOsgX+amnPQ1mX0B4TzlnvT5+2elfYwCDTd5ylfhGg5GyAp0s/Jrcb/09ZHns6FSFxuNwVQsVd0uIrcDZ+Iust8HEJFm4GzcRfz63HIicgKwGliOuzAI7uc8cBewGSciAeAM3IfL7wtsdheuRfo44JEJdnmmX/9SVdO5mar6iIgM+33tlo37eayY/8uT9jLc6/Wgqq7Pk/9D4BrgBBGpUtXkJPZpzGwrNPRYJu1kv/6Fqua7G/+HuOvLyXnyJiTunoJX+oc/yc1X1SdF5BHgWL/c7bPW4q4ZpwHPiMihuF9tvg08gfs5fzXu5+5X4ILXP6iPeCZhT9/P+a5jG/x6Uv12VXVURH6Ju7/iTex6vc70Gf5xbjnfV/bvcde3dlwrMLx4/S50HZ/WNUhEXuqPtwL3Ootfih3rz6o6lid9A3A47jXa5NNe7dfXTaI6xwKLgD+p6o7cTFWNishDwOt83TbkblOJLNg1le5HuMDvAnywC/wD7uJ3q6puz2zoO/jfiGvFLaSxSN6eWIT7mQ8gLsXvhVs0if2t8OvPicjnimxXkyetq8BFOFu+MUgzH2Ad+QqoakREeoGFfumcxD6NmW0TDT1W9LzG9bkEWDrN4y/E/bzco6ojRY5xbM4x1vr1auC7fp1Jz7QOrsYFu6tzyiAirwJ2ucHNu1RVe9jz9/OWPMUifh3Ok1fIj3HB7vn4YNc3WLwO1zp5S/bGInI4LmhdWWSfha7jU7oG+S8q36fIqD9FjpXv9YH8r9Fyv944iWqt8OtXZ24ULGIRFuwaUxFuBv4bOFVElqnqVl4chSF3bN0v4QLdu4DLca0jA6qaFJGX4C4Kkx6RoRDfipsrkzaMa2kq5m+TOExmf3cDUx0uJzZD20yJqs74Po2pYPfjfgla7R+vxr0v16nqmIg8iWv1hTzBLm7YxQvz7PcK3M27eyTfL0rTdDvuZ/czRaRNVbtxLelh4Lrs1nZxrQQ34ALd7+Gu/c8Bw6qaFpGLcDehFbqOT/Ua9GFcoPs3XF/aB4E+VU341uWxIseaqdcnV+ba/yzuJspiemepDvOOBbumovmfwW4G3gmcJyI/x/3cOAL8Mmfzc3BdG85W1cGcvAOneOi4X+ebgnh5nrQe3IU2jbsTd7I/NRay1a9/papX7eG+JivTSr4iX6aINOJagMbYiy6ypuwVPa+z0rdNc/+9uOvFIhGpL9C6u9sxVDUuIuuAM0TkEOBUfKDrN1kLfEBElgEn4fpx/i2r/HUU/1l8Xryf1Q0L+TPgQ8DbcF0nCnVhOAQ3+cNDqnpRnt1N9To+kXP8+h9V9clZPNYW3HM7CBfEFpO59q9X1TUzWIeyZuPsmr1BZszdC3AXScENa5X7odIKRPIEugBvn+IxM32lDs6Td2Zugu/vthZ3F+8ZUzxWPrf59ZtnYF+T9RDuZsBj/YdvrsxPfevy9O8zZr66y68Ljdn9jpztpsS3TN7nH+42dq3/Wf5YXCvuwznZa/36Ylx/3bVZeX/264/i+pHeOcUv0fPp/ZwJas8XkaW4wL6D3VsuW/16ty4CvqX1nNz0PVTweEz9M6OYP/l1vpb4XA8Ag7hfMxfMYB3KmgW7Zm/wZ9y33ZfiWgfgxQA42wagRUTOy04UkUyQPBVr/fpSEanP2tfLgH8vUObzuJbd/803+LmINPhB2mt3L7orVf0rLuA9SUS+mTvguN/fUSJy1sRPZXL8l4fv464r3xSR8VZt3w3kM/7h12fqmMbMgbW4Lk37Af8uWR3qReTNuJ/UR3FDOk3X1X59uYiMtwj61tNv4r6gf09VR/PUDSDTivnnrLzxER5ytp2U+fR+VtWHgadxN/J9ytfp+jzB+7O4a+jp2QG6/5LyNWDVDFct09/1fdmJIvJq4CMzeJxrcb/+vU1EPpLbFU7chCHtAL5l/8u4vsK/FJHdnrO4iTfekZte0Uo9HIQttszFAnyRF4cU2kr+4bj+MWube3A3QzzCi+Nr5hsyaA35hx6rAZ7KOt5Nfp+JrH115KnDe3HDpSnuJpObeXFQ9MxA7i2TfM7tuJYgxY1HuRZ3t/dveXFw8a/llCk6vA4TD6mWPQh9J+7mmN/hWoiUIoPQl/ocsWXvWrLe6ysmsW32pBJP+2vD3f5xEnh7gf135KStyHcd8XnZk0r81r93MmOr7jKpRFaZzHi7igu4Qzn5mUlllCmMr5tVfkbfz8We/yTq8m9Zz0UpMMEObjQK9dfLW3BjD2/2r1NmSLYrcsoUva4V+X++CndNV3+t/Slwr3/8xQJl1uSrQ1b+dT5/dU76amDI573g/xf/R+FJJX7o0+P+/PkZ7nPoSdwXgkdL/R6cy8Vads3eIvtmtOs1/3BcPwPOwgWlh+Pu9o0Ab8Td6DBp6m62Oh13wQn7fTUC71PVy4qU+zZu8PMf4Pr7vg43pE0DLlB9Pe4nqsnUoQs4EfgXXOB9NK4V6kjgedzPm/85lec1iWNGgFOAT+NaIt7gHz+EG1z9kpk8njFzQVWfwHUl+A6uS8C5uC5Kv8ZNNPPTGTjGP+O6RDyE+5n+DbgA+9PAaZqnL6+qxoF1/uG9/nG2TEvvLv11p1Cn+fR+/gkueAN4WFWfLrDdJcAHcSMXrMbdpPcAbhiyh2ayQqp6N+4aexuu5f9s3Oyc71LVj8/wsdbiJsz4tk96I64v9iCulf25rG3TqvpOv82tuC8Z5+CC8xjwFeBdM1m/+U78twBjjDHGGGMqjrXsGmOMMcaYimXBrjHGGGOMqVgW7BpjjDHGmIplwW4ZExGdxHSAxhgz79j1yxgzV2wGtcpgHxjG7F32eNrqecSuX8bsXeb8+mUtu8YYY4wxpmJZsGuMMcYYYypWWQS7IvIJEfm1iDwrIkMiMiYiHSJynZ83vFC580RknYhERGRARG4Xkb+f4FgHi8hPRaRTRGIisl5EPu3n1S5UJuy3We/LdPp9HDTBsc7ydRrwdVwnIjM5n7YxxhhjzF6tLCaVEJEYbnq7x4HtPvkI4CDcVHhvVtVbcsp8BbgUN63hrbjpW8/A9VO+2M9UlXuc44A7cDPk3I+b9vAUYB/cPONn5s5QIyJh4E+4mUl2AHfhZis5DhjGTfm326wtInIJcA1uqsk/AWPAmUAt8EVV/cQkXhc3h2EZ/A+NMTOq7Pvs2vXLmL3WnF+/yiXYPRm4X1XHstIEeD/wDWAnsFxVkz5vNW6axF7gBFV9xqefgJsDW4BDVPX5rP1V4eY8PxD4sKr+l09vwAXLJwCfVtXP5dTtCuBy3JSNZ6rqsE//MHAVsAE4XFVTWWUOwk3fmsJNA7nOp78EN6/2QuAUVb1rgtfFPiyM2TtZsGuMKVd2g1o+qnpXdqDr01RVr8bNB70PcFhW9qV+/blMoOvLrMPNK12Nmzs725twge5jmUDXlxnGBdUAH/JBMQAikr2fSzKBri/3VVxL9MG4+cSzfRDXwvztTKDry2wEPp/zHIwxxhhjzDSVRbA7gYRfxwFEpAZ4tU+7Mc/2mbTcAPT1hcqo6sPA88AC4KSsrJOAFuA5VX1kJo6VlXam7yJhjDHGGGOmqayDXRF5B67l9Bm/ABwChIFuVd2ap9jDfr1CRJqy0o/OyS9U7qg9KSMiLcD+/uFuAbKqbgF6cH2MDy6wX2OMMcYYMwllNamEiHwaWIW7gexQ4HDcDWtvz+oTu59f5wt0UdURERnAtcjuDzwxmXJZ6ftnpe1JmX5VHSlSbpEv93iBbYwxxhhjzATKKtgFXgccn/V4E/DOnNEOGvx6tMh+RnDBbuMUymUC09kuU6jcOBG5CLgo87ijo4O2tjYGBgZIJBIsWbKEHTt2UF9fTzAYZGhoiPb2djq2beOFrk4WLFrE6OAgC1paAEjExli2dF+G+vqoDYVpa2ujq6uLpqYmUqkUIyMj4/usrq6mpaWF7u5uWlpaGBsbIxqNjueHQiEaGxvp7e2ltbWVaDRKLBYbz6+pqaG2tpb+/i7CeVMAACAASURBVH4WLlxIJBIhHo+P59fW1hIOhxkYGJjUc+rt7SWdTrN48WJ27txJY6N7ySKRCPvssw+dnZ0EAgEWLlxoz8meU8U8pxUrVhS5fBhj5rt4MknvyDCRWJR9m1tpqKkpdZUqWlmMxpBLRFqBI4ErgVOBT6nq533eecBPgHtU9VUFym8FlgInqeq9Pi2Ou3HtIFV9Nk+ZzwGfBL6nqhf5tO8C/w/4vKp+Kk+ZA3HdKxKqGvJpJwL3ANtUdVmB+t2N6w98vqpeX+R1mNLdzDsHB1j3/LMsrG8gkUqR1jSqkFYdvzcygNBYU0NdKExjTQ314TChYBWhqipCVUGqg+X2/ciYimSjMRhTAqpKMp2a1mdhKp0mEovyxNatjCbixJMJEuk01YEgB7Yv5pB9lhBLJNjc10tNdTXVwSB1oRAtdfWz8EwmL5lKkUynCFdVIyKk02kUSKSSDMfG6B6OsHJRG+Hq6snucs6vX2UZuahqP/AXP0HE/cC/i8itqvoAbmxbgLoiu8icOZGstGGgtUi5QmWKHWs6ZQqVmxG11SHqw4Xve1NVxpJJBkZH6IoMkkpnfRCJC4brw2HqQmFa6+porq1zAXFVWZ5KxhhjKkwy5Xo1VgWDe7yvdDpNPJWkJzJMQ02Y57q72Dk0yP4LFlEfDrPfgoUEA4Vvf1JVnu/uoqO3h7Qq0USC+lCI1rq68XKZbeLJJD3DEXqGh6mprialLhA++aCXlCTgjSeTPLltK93DEZLpFPsvWMTA6CiJVIrqqgCD0SiqSjSeoLWujn2aW+a8jpNV1hGKqo6JyM9xrbxnAw8Am312oVbTelwXBnDdIDI244LdZeTvJ5vZX26ZgseaoEyriNQX6Lebr9ycEBFqqquhwDe0tKZJpFIMxUbpjgy5VmGgLhRmWWsrixoaaaypwQ2DbIwxxswuVWVkbIxwdRU7Bwd5prOTRDrFwvp6Dtt3KXWhMIPRUWKJBMOxGIubmmmoqSGVThNLJHZpAMoEtyHfcvv0ju1s6uthODZGTXU1iVSKZQta2drfRywRpzsyxAGL2mhrfPF+92QqxWg8zlA0St/oMJt6e2ipq6MqEGRB/e5Bq4iwqKGB7YP9hIJVHNjePv68ook4D23q4GX7r6C2OjSV1tO80uk0gSLB+VgiQTAQYCga5ZEtmxiJx2lvbEAQnu3qJCBCQ02YeDJNe2MjgtAzPFxwf/NFWQe7Xrdft/n1etxsZG0islRVt+Vsf6xfd6jqUFb6Y7hRE44FbmF3x2ZtR87fx5LfbmVUdUBENuNuVDsGuDu7gIgsx92cFsNNSDGvBCRAuCpAuKqahqwG4rFkgme7O9nYuZPqYJBlrQtY2mL9kIwxphJFYlF2Dg6iwKq29qKtm7NJVbnn2WcYikUB91nkfvqvozMyRGJLisP2Xcq9zz6DAoPRUfZtaWFRfSM7hwZJptOsXNRGXShER18P0Xic0bhrfU2m0yRSSdobm1jc1EwqnSYggojQ1tiIqtIVibB9YIDlrQsIBAIEAwF6IhHGkgkUpToYpL2piapA8VbmqmCQ9samXdJEhLpQmFQ6yn3PP0dAhJVt7ey/cOEu3ShiiTjBQIBkKk2oqopkKkU0EacqEHT1GXY/EkdiUXqGh1nV1k4ynaaxpoZ4MsnChgaqg1UMRaP89YXnxvcbqgqytOXF1trlCxbs6b+rZCoh2D3Vr58DUNWYiNwOvBb4B+BrOduf69e/yUn/LfBOn587S9oxwEqgD9ffNuNuYABYJSJHq+qjUzjW+3z+3Tl5mTK35U6kMZ+Fq6oJV7lvnMlUis19PewcGuSUgw62Vl5jjCljmWAqGk/QMxyhMzLIcGyMoWiUQEAIBYOsWNS2SxlVnfDaPxyLsWNwgEQ6xfLWBeMtioV+Dh+KRtnW30ddOMyy1gX0Dg/TNzLMYHSUhQ31BAMBAvJi0L24sYkt/f0MRqMEA0Ga62pY3NTEwOgom/p6aa6tAYRHNm+iqirIwrp6aqqqaQzXkEynCFVV7bK/3IBeRFjc1EQqnWZ4LEbSrxc1NNBcVzvFV7mwxppaIEowEODpHdvpGY7QWldPIpmkKxIhkU4RDAhjySQBBAWS6TSoUhNyrdGxeIJQVRXBgPiAVqgKBEimU7TU1rNvSwtbB/oIVQVdeipNQ7hyGqvm/Q1qInIGoMCfNauyIhLCBYxX4VpBD86MqysipwF3kH+64D/jxhfOnS64Gjdd8Cp2nS64HrgNN13wZ1T133PqdyXwGdw0v2dmuiVkTRe8ETddcDKrTPZ0watV9b6s9HXM0nTBOwcHeHTLZtoa8w7yMOO6hoZ4xQErWdQwN8czZi9S9t8gK/kGtXgyyVgyQWNNLUPRKNXBILWh0Hi+qhKJxagPh0vWIjpZo/Ex7nv+OcYSCdIoAR/AhquqaK6tI5lK0T0c4dAlS1lQV89ofIyNnZ2kNMUrVqzkhe5u2hub2Le1dXyfQ9EoGzt30DsyQiKVJJVOEwwECQiMJZPst2AhvcPDLKxvoCoYpKm2llAwyOPbtpJKp4gnk7Q1NjEQHQWF1rq6XV7fXMl0asKW1bSmdwls57PhWIye4WHqw2EafBcMEaE6GEQEBNf6nEynGEskqQ+Hd/nykfk787pEYlFG4/Hxm9OnqjsS4ejl+02lz+6cX7/KIdj9V+C/gE7cJA39uC4LL8VNExwDLlDVm3LKfQU35e4oLlgNAX+Ha82+WFW/nedYx+GC4Trgr7g+sycDS4A7gb9T1XhOmTBwO270hB3AXbjxcY/HDSF2as7QaJly7weuBpK+fnHgTKAW+KKqfmISr828DnZH42MECHDigQdZ664xM6vs31CVFOxu6+8jkUoRicVorqtjY+cOxhJJDmhrY0tfH6l0iqbaWhrDtbTU1dEzHGHbwAA1VVW0NzYxEh/jiKXLaK6tI550wV+x4G2upNNpHtm8iW2D/ezb3EI8lRz/BS/byNgYkbGYG93H/zwOEE0kSKVTBAIBWmvrOXzpUsJVVTzQ8QLxZIKGcM34TWSZ82A0Hqd/dIR9mpuJxV1XgNExt26pq/P9ZpMMRqPWkDJPWLA7A0TkYOBduKDzAFyr5xjQgQsyr1bV5wqUPR/4AHAErhX1IeBLqvrHCY53JXA60IQLeH8MfLlQtwIf8F4GnI8LdIdwLcufUdWNRY71GuBjwMtwrc1PAt8oNtxYTvl5HewCdA4NcfTy/di3pXXijY0xk2XB7jygqmzt7+OxrZsJBasIiJBIp6gLhQhXVTEYjVJbHSJUFSSWSJBIpRjzwWxbYyNBcXe0pzVNWpXm2joisRjJVIolzS0sbW2lvbFplxuK0uk0yXS66Ag46XSa/tFR6sMhaqpd0JxIJSc9XNbA6AhdQ0N0RgYZisXYp6l5Wq9PpuUwnkzSFRkar0sqnWZxU9MEpU25sGDXzKpyCHYTqSR9I6MctWw5S1vLt3O7MfOMBbslMhofQxW6IkNs7uthYHSURQ0N44HcdMUSCYbHYjTV1FIdDBKJxRhNxKmrDlFTXU08lWRxUwsDoyP0j4ywrHUBK9vax0cScCMDRNg20E99KExHbzd1oTArF7VTXRVk/c7tBCXIge3tNNfW0VSbv09pJBblrmc2Akq4qpqWumKjZE5NNO76/lYFA2XTZcBMzIJdM6vKIdgFd8Na78gIRy5dxrIFC+f02MZUKAt258jA6AgdvT3UVFWzY3CQ0cQYqVSapKapD4VorKnJ+9P+TIkl4gyPjVEXChFLJFCFptoaf9NVgIMXL2FzXy9D0SiJVIpQVRAhwMKGesaSCXqHR0imUzTU1CC4bgIBCbCqvZ1wVTWLG5sYHouxsXMnLXV19A4P++GlKufmJDO7yiHYrYTRGMw8VxUMsrChnse3bUVErIXXGDNvjcbH6BseYUt/H9FEnNH4GPFUClWlraGRxX54qLm6D6Gm+sWuCNk3Dy1qaGR4LMbftm8jpWkW1NXv1rWhpjrE0tZdW5wX1Lubsbb09pFIJ3mmcweptCLi0quCgWndpGTMfGbBrpkTVYEgC+vreWzrZoKBwLyeacUYs3dJpJIMRWMMxaK80NPF8NgY1cEg9aEwS+bxtaohXDOt4aECEmBRY8Ms1MiY+cmCXTNnqoJu9phHNm/iuAOqWNhgF1tjzNzoGxl2d/qPjLCosZFFDQ0MjI6ytb+fnYMDJNOuVbO2upqldkOtMRXFgl0zp6qDVTTX1fLgphc4YeWBBW+SMMaYmdIzHOG+559FVakKBtnc10t1MEg0EaemupoFDfUTjsNqjClfFuyaOReuqiZZneaJrVs4YdWBRefpNsaYqVBVeoYj9I2MUFtdzUg8TkdvD001teMjF4Ab/aC1vs5GBTBmL2DBrimJ+nCYrsgQO4cGbQxeY8weyYwru7mvd3zs27pQiEQ6RSqltDU2jE9ekFFTPXsjKBhj5hcLdk3JtNTW8fSO7bQ1Nk56sHNjjMlIplKICI9u2URXZIiqQIC0KosaG2Z1ODBjTHmxCMOUTKiqiqFYlM29vaxqX1zq6hhjysRwLMaW/j46erqpD4eJxGLs0zy9Wb6MMZXPgl1TUq119TzT1cmSlhYb29EYU5SqsmHnDp7p6qQqGGBBQz3DsdicT5RjjCkvFuyakgoGAlQHA2zs3MnRy/cvdXWMMfNUKp3mnmc3+lbcpvEby1rq6ktcM2PMfGe3oZqSa66tY/vAAAOjI6WuijFmnkql04zG4+zT3GwjKBhjpsSuGKbkRIT6cIind25HVUtdHWOMMcZUEAt2zbzQEK6hf2SErqGhUlfFGGOMMRXEgl0zbzTX1rK+cwepdLrUVTHGGGNMhbBg18wbNdUhRsfG2DHQX+qqGGOMMaZCWLBr5pXW+jrWd+4kkUqWuirGGGOMqQAW7Jp5pTpYRSqVpqO3p9RVMcYYY0wFsGDXzDut9XU8191FNB4vdVWMMcYYU+Ys2DXzTjAQICDClv7eUlfFGGOMMWXOgl0zL7XU1vFCTzexhLXuGmOMMWb6LNg185Jr3Q3wfHdXqatijDHGmDJmwa6Zt1rr6tjU18tQNFrqqhhjjDGmTFmwa+YtEaG2upoNnTaNsDHGGGOmx4JdM6811tTSHRmmd2S41FUxxhhjTBmyYNfMe001NTy1fTtpm0bYGGOMMVNkwa6Z92pDIUbGYnRFhkpdFWOMMcaUGQt2TVloqq1l/c7tpKx11xhjjDFTYMGuKQs11dXEEkm2D/SXuirGGGOMKSMW7Jqy0VJXy4bOnSRSyVJXxRhjjDFlwoJdUzaqg1Wk0ik299o0wsYYY4yZHAt2TVlpravn2e5Om0bYGGOMMZNiwa4pK8FAABGhw1p3jTHGGDMJFuyastNaV8cLPV2MxsdKXRVjjDHGzHMW7JqyE5AA1YEgz3d3lboqxhhjjJnnLNg1Zamlro4t/f2MJRKlrooxFUVEwiLytIioiBQc+kREzhKR20VkQEQiIrJORN4+l3U1xpjJsGDXlCURAYX+0ZFSV8WYSvMp4OBiG4jIJcDvgVOAdcDtwFHA9SLyH7NeQ2OMmQILdk3ZqgtXs80mmTB7kd7eXr7+9a8jIj8RkT+KyMcyeSJyuIi8QUTqprt/ETkCuAz4XpFtDgK+BowBp6jqa1T1TcDRQC/wcRE5ebp1MMaYmWbBrilb9aEw3ZGITTJh9go33HADK1eu5MMf/jDA24FXA4dkbbIU+CVwznT2LyIB4FqgDxfwFvJBoAr4tqquyySq6kbg8/7hpdOpgzHGzAYLdk3ZEhEQ6B8ZLXVVjJlV69at47zzzqOqqoqrrroK4DhAcja7HRhkmsEu8AHgeOBfVXWgyHav9+sb8+Rl0s4UkfA062GMMTPKgl1T1mqqqtg+WOxz2Zjy94UvfIFAIMBtt93Gv/7rv6KqD+Zuo6op4GHgiKnuX0T2Az4H/EFVf1ZkuxZgf//wkTx12AL0ADVM0O/XGGPmigW7pqzVh8N0DQ2STKVKXRVjZs29997LCSecwLHHHjvRpjuBJdM4xLeBIPC+Cbbbz6/7VbXQ3aFb/Xr/AvnGGDOnqkpdAWP2REACpDXNYDTKwoaGUlfHmFkxOjpKW1vbZDZdMNV9i8j5wGuAT6jqCxNsnnmTFes7lAmCGwsc7yLgoszjjo4O2traGBgYIJFIsGTJEnbs2EF9fT3BYJChoSHa29vZ0dlJ5/btNO2/gt7ubuoa6l1FhkdY2NZGX08PEhBaWlvp6+mlvrGBdCpFdDTKovY2erq6qaquorGpif7ePhqbmojHxxiLjY3nV4eqqauvZ7B/gKbmJmKxMeJjL+aHwmFqasIMDQ7R3NrC6MgIiXhiPD9cEyYUChMZGqJ14QIiQ0MkE8nx/Nq6WgLBICORYRYsWshAfz+aVhYsWmTPyZ5T2T6nzm3bGGxsRmJjRKPR8fdwKBSisbGR3t5eWltbiUajxGIxVqxYMcFlZuaJqs75Qc3MEBEFmOz/cOfgAI9u2UxbY97PoLI1MDrKkuZmDtt3WamrYsysOPDAAwmFQjz11FOZJBGRNHCdqr7LJwSADmBAVY+czH5FZBHwNK5F+FhVTWTlKZBS1aqstBOBe4Btqpr3DScidwMnAeer6vVFjj2l61c8meSO9U9V3PXLmHLXHYlw9PL92Ke5ZbJFcu83mHXWjcGUvYaaMNsHB0in06WuijGz4qyzzmLDhg1cf33B2BHgPcAy4HdT2PV/AQuBi7ID3SKG/brY8Gb1fh2ZQj2MMWbWWLBryl5VIEgylSYyFit1VYyZFR//+Mdpbm7mwgsv5KMf/SgicoLPqheRY0Tks8A3gG5cADtZZwNR4D9EZG324vODWWlHA5t9equI1OfbIS7gBtg0hXoYY8yssT67piIEAkLv8DDNtdMeT9+YeWvZsmX87ne/4y1veUtm6LG7AQXO9YsAXcAbVbVriruvA04tkp/Ja1HVARHZjLtR7Rhfj3EishxYBMSADVOshzHGzApr2TUVoSEcZrvNpmYq2AknnMCGDRv46le/CvAHYD2wEbgD+DhwsKr+dSr7VNUWVZV8i98klZW21qf91q/PzbPLTNptqjo2lboYY8xssRvUypjdoLar7kiEU19yCLWhUKmrYsxsm/UbPPLdoObTDwKeAlLAalW9Lyt9Ha4P8Cmqetck9m83qBlT5uwGtRkgInUi8iYR+R8R2SAiMREZEZHHROQzIlJwvCkROUtEbheRARGJiMg6EXn7BMdbIiLfE5Gt/ljPi8h/ikhTkTIBEfmAiDwqIqMi0iMi/ycix01wrONF5Dd++1Ff/hIRmfMToVL0jxYa+tMYMxNU9RngQ0AYuEtEbhGRXwGP4QLdL04U6BpjzFya98EucB5uvvd34VoS/g+4CzgAuBJ4QETacwuJyCXA74FTcK0NtwNHAdeLyH/kO5CIrAQexd3V3A/8Gtcv7iPAfX72oNwyAvwUd3PI/sAtwJO4KTXvEZHXFTjWG3H93V7nt7/Fl78G+PEEr4nJozZUzQ6bTc1UoDvuuINzzjmHu+4qHEOKyCkicrOInDLb9VHVa4DX4q5hrwJeDTyOG27sE7N9fGOMmYpyCHYTwHeBw1T1MFV9q6qehZuK8hHgEOBr2QX8z2lfA8ZwP6e9RlXfBBwN9AIfF5GT8xzr+0A78A1Vfamqvs0f55fAocB/5ilzIfBW4BngEFU9V1VXA/+AuwHwhyLSnFO/VuA6n3+uqq5W1XP9c3kWOE9ELpjKi2SgPhSmZ3jYZlMzFec73/kOt912G0cffXSxzR4FzgTeOxPH9P10C97ErKq/V9XTVLVJVRtU9ZXFxtU1xphSmffBrqr+QFX/WVWfzknfAVziH54jItkdNT+ICyS/rarrsspsBD7vH16avT8ReTnuruMu4GNZZZLAxbige42I5E5jlNnPx1S1M6vcTbhW6AW4Vuls7wZagF+r6s1ZZTqzjv1RzJSICIoyGI2WuirGzKj777+fY445hsYi/VVVdQh4GDh+zipmjDFlYN4HuxN4zK/DuL5iGa/36xvzlMmknSki4TxlfpN7F7EPQu/CzR3/2ky6iKwADseNU5lvIPfMsd6Qk16sfr/DDdtzpIjY3PJTVB0I0h0ZKnU1jJlRO3fuZPny5ZPZdAuwZJarY4wxZaXcg92Vfp0A+gB8v9pMkPhIbgFV3QL0ADW4LgoZmd8HHy5wrEz6UXnKPFlg9qF8ZYoeS1XjuD68+cqZCbghyAYmfYe3MeWgvr6ezs7OiTeExbgvy8YYY7xyD3Y/6Nd/yGqN3c+v+1W10K35W/06u+V0v5y8mSzTKiKNAH5Uh+ac/Mkcy0xCVTBIPJVg2GZTMxXkmGOO4Z577mHTpsKTkvlfml7Fi794GWOMoYxnUBOR1+L6viaAT2dlZYYiGy1SPBMEZ3eAm6jcnpTJlItklZnqscaJyEXARZnHHR0dtLW1MTAwQCKRYMmSJezYsYP6+nqCwSBDQ0O0t7ezbetWOrdvp2n/FfR2d1PX4Gb7HB0eYWFbG309PUhAaGltpa+nl/rGBtKpFNHRKIva2+jp6qaquorGpib6e/tobGoiHh9jLDY2nl8dqqauvp7B/gGampuIxcaIj72YHwqHqakJMzQ4RHNrC6MjIyTiifH8cE2YUChMZGiI1oULiAwNkUwkx/Nr62oJBIOMRIZZsGghA/39aFpZsGjR+HOKjAzz+NNP87JDD6Ozs5NAIMDChQvp6uqiqamJVCrFyMjI+OtUXV1NS0sL3d3dtLS0MDY2RjQaHc8PhUI0NjbS29tLa2sr0WiUWCw2nl9TU0NtbS39/f0sXLiQSCRCPB4fz6+trSUcDjMwMDCp/1Nvby/pdJrFixezc+fO8X6akUiEffbZx57TXviczj77bG6//XbOOussrrnmGs4444zca8IhwC+AatyNtsYYY7yynFTCX9jvBVqBD6rqN7LyTgTuAbap6rIC5e8GTsINk3O9T9sIHAT8nar+KU+Z9wDfw80MdKZP+zfcDW8/UdXdRk8QkSpcMA6wVFW3i8i+wDafVu1vgMst92PgfOCTqvqFIq+DTSqRRywRJyABTlh1UKmrYsyMeetb38qNN95IIBAglUr9FTd7Grjr1itwv9T9UlXfUrJKToFNKmFMZajoSSVEJCQiR4nIq0XkXL8+KmdUhBknIktxU2W2Al/ODnS9Yb+uK7Kber+OTKHcnpTJLjeclTaVY5lJqqkOMRAdZSyRrxu1MeXpZz/7GZ/97GdpamoCOA64wC/HA0PA5bhhEI0xxmSZUjcGP+zWGtxECMfhRkHINSYi9+PmT/+BqnbvaSWzjr8AuBXXl/VaVb0sz2ab/bpVROoL9NvNtPhmd4DbDByTlTfZMtl5hcr0q2oE3PBAIjKI67e7DDft5mSOZaZAEAajUdqrq0tdFWNmRCAQ4FOf+hSXXXYZoVDoJCAzPMMW4CF/c6sxxpgck2rZFZEDReSnuIvql3Czkg3juhL8FrgeN2TWvbj+pqcAXwa2iMj1InLgnlbUTwv8e+Aw3JBdeQdOV9UBXgxCj8mzn+XAItwdyxuysjI3dRxboArH5myX/fcRIpIvqspXpuix/H6OKFDOTFJNdRXbbTY1U4Gqq6tR1XWq+gu/rLNA1xhjCpsw2BWRa4C/4WYEuwc3le4qVW1X1ZNV9Y2q+g5VfYN/3AYciLuB6l7cz2p/E5Grp1tJPx7ur3GtyX/E9bUtNk3Wb/363Dx5mbTbcsbTzZQ5O2f8XURkMXAybrriWzLpqvoCrmW2FtfaXehYv5lC/V6PGxbtCVW1lt1pqg+H6Y4MkkqnS10VY4wxxpTQZFp23427MesAVT1DVb/vg7yCVPV5Vb1WVU8HDgCu9fuZMhEJAj8FTsdN7HDOJFoxvgYkgfeKyCuz9nUQ8En/8Cs5dX4AuBM3XfCXsspUAd/C3eWcr1tGZgrhL4tIe1a5c3CTSfQB/5NT5lpgAHij3y5Tph3XIr5b/czUBCRAKq0M2WxqpkLE43F++MMf8u53vxsR+b2I3FFgub3UdTXGmPlkMn12V6nq9ukewE/icImIfH7CjfN7P/Bm/3cP8C2RvDfyfVFV1/tjPiMiHwKuBu4SkduAOG7e+Fq/7V159vFPwDrggyJyOq7V9hW4ySvWAx/JU+Y64DW4lu/1/oNmEW7q4SRwoaoOZhdQ1X4RWQPcBNwoImuBXuDVuGmEfwb8uOirYiZUFQjQMxKhtb5+4o2Nmcd27NjBGWecwYYNGzKjF/x9kc3Lb4gdY/ZCY8kEghCqKttRYMvGhK/wngS6M7Sf1qy/31xwKxd0rs863jUi8hzwMdxA6wHgceAbmeHG8tTxeRE5BrgSNy3wm4EdwFeBK/3c87llVET+Edfq/B5cN4QorrvDZ1X1/gLH+rWInIQbI/hEXBC+0T/+lpbjmHDzTENNmG0D/RzUvk+pq2LMHrnssstYv349xx9/PJdeeinnnnvukdhoLcbMqdH4GM90ddIQrmHlojYKNLztZmt/H+t37iASi7Fh5w6e7+nm8a2bSfmP+QPb2jn/+BM5eJ99+Mbtt9E5NEh7UxNNNbW85diXc+x+KyZ9rJkWSyQYGB0hpcq+zS2kNI0g7BgcYCQ+xmNbttA5NMgLPd2cfshhHLzP/JytvCzH2TWOjbM7se7IECcfdAj14XwDhxhTHtra2qitrWX9+vXU1dVBCcapnGk2zm75iyUShKqCBKR0k7EOj8W4Y/3TBET46wvP8Ye/PUFQhAX1Daxqb+f8405ARPjp/ffRFRliaUsrrz/yaFrr6lm/cweLm5o49SWHkEyn2NLXR9/IMA3hGla1t7N+xw6+fecddA0N8UJvz27Hbq2rY/8Fi/jCm8+lrbEJcOdzZ2SITb093Pf8c9zyxGP0jRaazHVyXnXgQXzwjL9neesCgoHZfa1VlbFkkj/87XG+c+ef6RkenriQd/nr38TlZxdrnEF0MQAAIABJREFUkxw359evGWs7F5Ef4VpOn8DdXLUtK28VEFbVfMNsGTOLhIHREQt2TVkbGRnhtNNOywS6poyoasla5WZCMpXihd5uYokEz3Z18eO/3svmvt7x/PbGJi5ZfQavfelRU9pvLBHnzo0b6OjtYWVbOyesPJAdgwO01NWxqGH3LzRpTfNcdxcDo6MctmQpwUCAXz36EFfd9ofdtk2p0j0coXs4wn3PP7dL3jNdnazduH63MtPRPzpK/+hmXnv1V2dkf4Xc/ewz3P3sMwAcss8SLj71dA7fdymPbd1C/8gIQ7EoPcPD7L9wIQ2hMFsH+hmMRlm5qI3+0RGiiQR/evpJNvf1je/z4MX7kEynOXrZfhy1fD8isRj//ZfbGR4bK1SNCc3n7hgz1rIrIr8EjgRW+KQBfOCL68N6cqEZzcz0WMvuxEbGxqitDvGKA1aWuirGTNsxxxxDW1sbt956ayapfKMnrxJaduPJJH986gke2tRBPJlkIDpKdyRCJBajd2TXFrFXHrCKfZqb+dWjDwPQ1tDI8gULqK0OsaS5hbe9/DiWL1hIPJmkNjSrczNN2k0PP8BVt/2BRKrY4EfOgrp6BmNRUuk0C+rqx1szX7HiAJY0t3D6wYdy/MpV3PrUk9z88IM8tnVL0f0dvu9S6kNh0ppmQ+dO4skkY8ndJhw188iX3/I2Lj3ztZPZdM6vXzPejcGPh/tSXOB7AnA2bgKF21W12E0VZoos2J2YqtI7MsLphxxKdXD+fus0ppjvf//7XHzxxTz66KMceuihYMHunEmkkoyMxWmqreGFnh5iiTjdkQgfvenns3bMulCIRQ0NHLPfCupDYZa1trJvcws11SE2dO5AVTl6+X4ctmQpIuKvc8M8tKmDnUODdEcixBJxjtlvf0496BDufe4Zbl//FKcfchhnHnZE0ZbmZ7s6uenhB7nx4Qdm7fntrfZtbmHFokX8f/bePM6Ossr/f5+qunvvnT0hCwlJgBD2XRZxAUcUEBHZRGQGHRVnHMdRfzP4dR2/jhsy6tdxdERkUxlwARQXEFzYl7AlIQRC1k4v6eV2373q/P6ourfvvX07vaSTdKef9+t106mn6nnqVN17637q1HnOOWP5SlbNW4DreXT2J/nhX//Ec9u27m/zxs0R8xcwr6mZD5x+FucdNVypggqmvtgdsgM/ndavgX9X1f/dqzubZhixOzo6kn0cv3gprXV1+9sUg2HcfPKTn+TGG2/k85//PNdcc83CINPNlGUyit2X23fypw3r+fmap9jec+AWpVk2cxavX3EoxyxcjKL810MPsKh1Bg+9tJ6edGp/mzduHMti6cxZLGhuYXZDI7c+9vCEjFsfjTIjUcdJBy/jhCUHs2refJ7a/Bpf/e2v6eivPU90Vn09C5pbmNvYxHlHHsPRCxcNO77reaxr205vOs3h8+bTGPPDlbKFPP/3N/dw97PPTMhxjJV5jU1ce9abeP2KQ/nZk4/xWlcXS2bMYE5jE4fPnV/6Te1IJjnqoIXMaWwa7dAHntgFEJErgf+jquZZ8gRixO7o6EmlmN/UzMq58/a3KQbDuLBtGxiM//S83VZLUVWd9I8x9qXY3dHbw3PbtvJqZwcz6uo4csFC6qJRntq8ie09PWzq7OC+F58f87jTkUQkwkA2yzmHH8Hi1hl896EH9qs9BzW3cPFxJ/Ku404Y4rHuHhjg9+teIBoKcdqyFTQFMe/JTJq6SBQR4bFXX+F3a5/nzYet4thFi0lmMkScEDt6e0hEIsyoq9vtBLzixLa+dJpHX93IguYWXrdsOQ2x2IQdY2d/kte6utjQ3sYdTz7Oa2Ux06Ml4jhDwkAS4TADucGyBUfMX8AFRx+LICyfPYfls0eXyWhaiV0ROQF/YtqQLP4iciFwo6pOL5W1lzFid3QUXJeBbI7Xrzx0Sk8UMUxfFi+uTD20adOmTbvbXlWX7G2b9pS9KXZ7UgP0pNOEbZsv3vsrHtv0yp4ZOwo+9qZzSGYy5NwCTbE42UKhVMEx77q0JBK82tnBq52dOLbF8YuWkHNd7nvhObZ07xph9P3LJ85+KxccfWzNTAA9qQF+v/ZFOpJ9bOnexZIZM5nf1Mwjr27krxs30DtMYZ/Pn/cO3nToKmzLwlOPXQMDbOvp5g9rX6Q5kWDF7DnkXZeXdrbR1d9Pa10db1t9FA2xGA+sX0vUCXHGipU4lr23D3/SkcplSWYytCbqcOzhj19VUXTEbBmu56Gqux1rd0w3sesBHvAKflaGNfiT0wrA54B7VfXfJmRnBsCI3bHQkUxy6rJDqI9O3N22wbAfmfJ3bRMldlWVR1/dyMOvvMxDG9aztbt74o3dDR9/81t413En7tEYuUKBF3dsI++6HHXQQjqSSdbu2M6TmzexYedOeoPQAle9ihn1w3FQcwsz6up4tbNz3GEJ85qaeNOhq7jqlNP2OJuNqvLMls08s3UzcxoaOf2QFSZDzgHEdBO7C4Ej8SemrQ7+vwy/mEMBeAJfAK8B1qjqxATTTGNG+2Pxgz8/yOfv+QWOZeGqEg+HidgO0VCIaChEJBQiHgrTFI8PvmJxmuMJmuJxmuNxoqHJMTt4vHT2Jzl0zjwWts7Y36YYDBPBtBW78XCYP760lhe2b+PRVzeOSvyNh2UzZ3Hu6qM4ddlyfvXs00Rsh/eectqkSa/0l40beOq1TTy3bQsLmlu44qRTWdTaWuHF89RjR28vjdEYiUiEF3ds44H16+jsT9KRTLKjt4dkJlMSxKcdspzFrTO49ISTa6b/MhhqMa3Ebs3BRaLAKipF8GqgSVWn37OHCWa0PxZfue9ePnHnns0cjjgOzfEEzfE4TcHfGfX1HDxjJstmzmZR6wyiodAe7WNvks7lsC2Lk5cesr9NMRgmgmkldncN9PPH9ev42u9+zcOvvDyhdpy0ZCkHz5zJ4taZLGxp4fB586f8zb3BsC+ZCmJ3xFtUEbkAeEpVXxvr4KqawffoPlE1psm3uw/JFvITMEaBtr5e2vp6a663RFjQ3MKymbM4fN58jph/EIfPmz9pvCCxcJj2ZJJcoTBpbDIYxsMLL7zAqlWrzgfqGeZHQ1Vv2rdW7T3uePJx3vW9b425XyT4ns9tbOKogxby3lNOY36TX31+10A/7ck+Vsyea+L4DYZpwGh+9f8XUBHpBp4OXk/hC+CXxrNTVZ26CeWmIJn8novdkfBU2byri827urh//VrAT1vyube/gyMPWrjX9z8aRKA3nSqVdTQYphIPPPAAf//3f8+GDRvAvy7XQgAFDhixu2LO6GaEn7D4YOqjUVoTdZx9+BGsXnDQsNu2JOpoSZhUhAbDdGHEMAYRuQE4Fj8UoVirsthpAD8G96my14uqOnK5FcMeM9rHgH3pNLsG+tnSvYvntm6hLhohky+QLeTJ5PNkCnkGsll6Uin/lU7RnRqgJ5WiN52iO5UaVQWdWtRFInz/PVezdOascfWfSPrSaWbWN7BqvnmwYJhaPP3005xyyil4nsdFF13ELbfcsga/eM//BQ4B3ohfvOdGYLOqfnb/WTs6Rnv9yhUK1F17DQWv8ho0q76eukiUg1pauOjYEzhxydK9Z6zBYBiWqRDGMOqYXRGxgMPwhe9pwFVUGlwcKAs8jy98n1TV/54waw0V7KtsDKrKQM4Xw92pAb8eeJAm5uWOnWzsaN9tAvbGWIx/euM5vGXV6v36yND1PPoyac5acRhWjRQ6BsNk5eKLL+aOO+7gnnvu4ZxzzkFEbgTeU5z7ICKtwA+AE4HjVHXbfjR3VIzl+nXMF67D9TxaE3Wcdshy3rJqtamIaDBMEg4osVvqIDIHeBAIA98CXgbqgOOBdwLz8IWv4Cc3NxPR9hKTKfVYKpfllY4OXtyxnbuffZq1bTuGbHP0QQv5l7PfyrJZsyd8/6OlI5nk5KXLShVqDIapwPz585k9ezZPPfUUwBCxG7QlgFeBX6nq1fvF0DEwluuXqpJ33f1SLthgMOyeqSB2x+Peuh5oAU5U1a+p6i9U9RZV/UdgEfBx/FRjDwMmr+40IR6OsGr+At513An86KpruPCY44Zs8/SWzVz+g+/yjd/fR382sx+sBMsSdg0M7Jd9GwzjpbOzk+XLl5c35QFEpHTXpqoDwEPA2fvWur2PmURmMBj2hPGI3TcDf1LV9uoVquqq6teAK4CT8L2+hmmGiPCJs9/KB884i3BVRRZXlVsfe5iLv/cdnnxt0z63LRGOsL1n3yadNxj2lNbWVlKpiuIAxXqhi6o2dfCdEQaDwWAIGI/YtRicqFYTVf0p/sS1vx+PUYapj4hw1amnc/vffZBTli4bsr492ccHb/0Rdz71RI3ee49oKEQykyGTz428scEwSViyZAmvvVaR/fEp/EeB7y42iMgs4Exg0760zWAwGCY74xG7jwBniMjweV18XsLP4GCYxhzU0sr177qMr1x4MXMaGivWeap86Td388s1T+1Tm1QZtl67wTAZedOb3sQLL7zApk2bik33AO3Av4nIT0Tka8Bj+Ll396yCjMFgMBxgjGc663/ghzL8XETOVdUhM5HED7BazQgeYMP0QEQ4c8WhnHTwUr770APc8mhlpegv3PNLwo7DOYev3if2xMIOO/t6mV0lvg2Gycrll1/OwMAAbW1tLF68GFVNici7gZ8BF5Vteh/wpf1jpcFgMExOxlUuWEQ+BXwRSALfBm5X1WeDdfOALwDvBZ5R1WMmzFpDBZMpG8NYePCldXzyzp9S8LxSmy3CF89/J2849PC9vn/X8+hNp3nDSpOCzDBlEShNUDsdaAbWq+q+fUyyB4z1+pUrFEw2BoNhEnKgZmNAVb8EXII/I/iTwNMikhWRPmALvtD1gE9PkJ2GA4gzlq/kSxdchF02w9pV5V9/8b88+NK6vb5/27JwPY/kfsoIYTBMFKqaUtXfqOptU0noGgwGw75k3G4tVf0JsBj4Z+CPQD+QADqB3wCnqurde26i4UDkzBWH8vnzLsQqF7yex6fu+hl/3bhhr+/fsoRuk4LMYDAYDIYDnj0qQaOq/cDXgxciIjqeuAjDtORNh60i77l85pd3lcrv5V2Xf/nfn/D1iy7lhCUH77V9J8JhdvT2sHjGzL22D4NhvNx0000AXHDBBdTX15eWi1x55ZXv2V1/Vb1pd+sNBoNhOjGumF3D5GCqxuxW8/NnnuSL9/6qoi0aCnHDxZdz9MLqNKITR0cyyVkrDyPsmLKjhsmFZVmICGvXrmX58uWl5SKeVxbwXsmUqVxpYnYNhgODqRCzO+KvvIgcrapP7+mOROQYE1NmqMX5Rx1LruDyld/eW2rL5PP8409v4VuXXMER80fKcjc+FKUvk2ZGnfnxNEwuPv3pTyMizJgxo2K5yGc+85nP7S/bDAaDYaoxomdXRDzg58CXVPXxMe9A5ATg/wPeNhW8DVOJA8WzW+TWxx7mG7+/r6KtLhLhO5deyaFz5034/npSKeY2NnLYvAUTPrbBsJeZ8vVzjWfXYDgwmAqe3dFMUPsUcBbwiIi8KCL/KiKniki01sYiEhOR14nIdSKyFngYOCMYx2AYlktPOJkPnvmGirb+bJYP33YTG9rbJnx/dZEIbb19o/6xNRj2FzfccAPf//7397cZBoPBMCUZUeyq6peBpcD1wBzg88BDQJ+IbBSRx0XkfhF5QkReAXqBB4HPAjOBrwLLVPU/9tZBGA4crjrlNP72dWdUtPVlMlx7281s7d41oftybJucWyCVM6WDDZObj33sY/zqV78aeUODwWAwDGFUqcdUtUtVPwbMA64C7gS6gCXAsfj12I/BT0XWjl+u8nJgvqp+QlW7JtxywwHLNaedyXtOPrWirWugn2tv/zGd/ckJ319vOjXhYxoME8mcOXOIRms+TDMYDAbDCIwpz66qZlT1R6p6karOBWYDRwCvA1YBs1R1gapeqqq3qmp2L9hsOMARET585hu5+LgTK9q3dnfzkdtvJplJT9i+YuEQO3t7J2w8g2FvcPbZZ/PnP/+ZnHkKYTAYDGNmj2qlqmqHqr6gqn9V1RdVtXOiDDNMb0SEf3rT2Zxz+BEV7Rvad/JPP72NTH5ifvTj4TAd/UncYTM5GQz7ny9+8YvYts1ll13Gjh079rc5BoPBMKUwCUYNkxZLLP7PuefTl0nz140vl9qf2bqZT911B1+58GIce88SfFhi4alHfzZDYyy+pyYbDHuFT33qUxx55JHceeed3HPPPaTT6T8Dm4FaNa9VVa/exyYaDAbDpGU0qcfuBO5X1W/VWPce4GVV/WuNdV8B3qGqSyfKWEMlB1rqseHI5HN8+LYfs2brlor2t6xazWfedj6W7NEDCroG+lk+a46ppmaYtFhW5Wd8hEqVpqiEwWDYZ0yF1GOj8eyeD/QMs+7G4DVE7AIz8CesGQx7RDQU5usXXcr7b/4hL3e0l9p//fyzzG5o4ENnvnGPxo+HwrT19Rqxa5i0PPDAAxXLZ5555uv3kykGg8Ew5TBhDIYpQUMsxn9ecgVX3/QDtvcM3nvd9PBfOPuwI1g2a/a4x46GQnT295N3C4Rs85UwTD7OOKMyHZ+qPrifTDEYDIYpx549/zUY9iEz6ur59iXvoSWRKLV5qlz/h/v2qDBEsQxrMlMr/NFgMBgMBsNUxohdw5RiQXMLnzrn3Iq2R199hb9s3LBH49qWsGugf4/GMBgMBoPBMPkwYtcw5Thj+UqOW7Skou0bv7+PvFsY95iJSIQ2k2/XMIlJp9P8+7//O8cffzwi0iMi7jCv8X8RDAaD4QDEiF3DlKOYg9eSwQmdm3d18bMnHx/3mBEnRDKbIZvPT4SJBsOEkkwmOeWUU7juuutYs2YN+PMtBGgLNpHgtRnYUnsUg8FgmJ6MVuzWicjC6tcI6+r2ks0GA4fMmsN5Rx5T0fb9Pz+4x6V/k1kTt2uYfHz5y19mzZo1XH311fT19QHcgZ9ibD5QD/wd0AE8DBy8/yw1GAyGycdoxe6FwKs1Xrqbde+YaGMNhnI+cMbrSUQipeVkJsOPH6mVBW90hG2HzmRyIkwzGCaUu+66izlz5vCtb32LaDQK/rUXAFVNqeoPgLOBi4B/2E9mGgwGw6RktGJXxvkyGPYaLYk6rjrltIq22x9/hM7+8QnWukiEtr6ePcrsYDDsDTZt2sSxxx5LOBwuNnkAIlLKlaeqzwAPAVftewsNBoNh8jKi2FVVaw9ek76Kj2Fqc/FxJ9CaGIyYyRYK/PAvfxrXWI5tk8nnSeVyE2WewTAhhEIhEmUp94Bi6pBZVZu2A6ZqpcFgMJQxotgVkfi+MMRgGA/RUJirX3d6RdudTz/Bjt7hiv6NhElBZph8zJ8/n61bt5Y3FXPtnVS16VHAqNOKiEhcRM4XkR+IyHoRyYjIgIisEZFPi8iwcy9E5BwR+UOQGSIpIg+LyCWjPiiDwWDYR4wmjKFNRG4UkTeKiAlNMEw6zj/qGOaV1eQueB7//ac/jmuspniM9W07yBVM9ibD5OHkk0/mueeeIzNY+ORe/Ljd60XkLSJyhIh8B1iOP0lttFwK3AW8D3CBXwJ/ApYAnwUeF5Fq7zEi8iHg18Dpwf7+ABwJ3CoiXxrHIRoMBsNeYzRitw54D3AfsEVEviwiq/auWQbD6AnZDn932pkVbfc8t4ZNnR3jGstTeGUcfQ2GvcX5559POBzmvvvuA0BVXwG+DiwA7gaeAT6AH97wyTEMnQe+Bxymqoep6rtU9RxgBfA0sBK4vryDiBwStGWB01X1Lap6Pr5XuQv4pIhUBtMbDAbDfmQ0YncZ/h3+RmAe8M/AGhF5SkQ+KiJz9qaBBsNoeMuq1SxpnVFa9lT5r4ceGNdYzYkYr3a0k8ykJ8o8g2GPOPfcc+no6OC8884rtanqvwCXAD8Dfg98CzhWVV8e7biq+iNVfb+qrq1q3wF8KFh8h4iEy1b/A36e3++q6sNlfV4Cvhgs/vOoD85gMBj2MqOZoPaKqn5WVZcDJwPfBXbh38V/FdgsIveKyCUiEtu75hoMtbEtiw+ccVZF2+/Xvcj6th1jHssSi0jI4aW2tpE3Nhj2I6r6E1V9t6qeraofGYvQHQVrgr8RoLWsvViv+44afYptbxaRSI31BoPBsM8ZUwU1VX1UVT8EzAXOA+7Ej/M6B7gZ2CkiPxSRs3YzjMGwV3j9ikNZOWduRdv/e/D+cY3VGIuzM9lrJqsZJgV//vOf98dui8Up8vgODkSkCVgUtD9d3UFVtwCdQBQ/FMJgMBj2O+MqF6yqBVX9lapeBMwGrgH+DCSAK4HficjmiZioICLHisgnReROEdkmIioiIyZCFZETReRXItIpIikReUZEPrS7SXYi0igiXxWRV4JZyVtF5HsjhWqIyKXBTORkMDP5DyJy9gh9VojIbSKyM9jXOhG5rupxoWEMiAh/X+Xd/cvGDTyz5bVxjVcfjfLi9m14njcR5hkM4+b0009n6dKlXHfddaxdu3bkDhNDsTjFb1Q1G/y/WDmzW1UHhulXTBuxaJj1BoPBsE8Zl9gtR1X7VPX7qnoG/gzef8WfpLAA+Jc9HR+4DvgScAF+zPCIiMh5+OL7rcDz+DOXF+HHtN08TJ8W4FHgY/iznH8B9OCX4XxaRGpeuEXkK8At+DOR/wA8gj9D+Tci8oFh+pwAPAm8G9gU7KsR+BzwWyN4x8/JBy/j6IMWVrR9549/GFehiHg4QjKbYXtP90SZZzCMi9NOO41NmzbxxS9+kVWrViEiT4jIP+6tORMi8jfA1fhe3evKVhVTke2uLndRBNfvBdMMBoNhzDgjbzI6RGQe8C7gYirju/aUh/Fjxx4PXtuAYYtViEgzcCP+sV2oqncG7bPxBfClIvJrVa0WvV/Hf+x2J3CxqhaCfjcA1wI/AN5Yta8z8SdidAEnq+qGoP1k4I/ADSLy22DmdLGPgy+OE8A/qeo3gvY64LfAGfg3CV8Y7QkyDOJ7d9/ANTf/sNT29JbNPPLqRk4+eNmYx2uOx1nXtoNZDY2EnQn7uhgMY+LBBx9ky5Yt3Hrrrdxyyy0899xzxwBHA18Rkfvxb+LvUtU9jrsRkZXBeAL8s6quGaHLWMe/Bv9pIOBXh5s5cyY9PT3k83nmzp3Ljh07SCQS2LZNX18fs2bNYsfOnezcvp2GRYvp6uggXucX2Uj1D9A6cya7OjsRS2hqbmZXZxeJ+jo81yWdSjNj1kw62ztwQg71DQ10d+2ivqGBXC5LNpMtrQ+FQ8QTCXq7e2hobCCTyZLLDq4PRyJEoxH6evtobG4iNTBAPpcvrY9EI4TDEZJ9fTS3tpDs66OQL5TWx+IxLNtmINlPy4xWerq7UU9pmTHDHJM5pil7TDu3baO3vhHJZEmn06XvcDgcpr6+nq6uLpqbm0mn02QyGRYvXjyRl5RRIXtSGjUQaO8ELscXaRb+BXIrvqD7saq+OAF2lu+zANiqWjMcQUT+GfgK8IsgHU75ugvwxeyzqnpkWftsYDtQABaq6s6ydRFgCzATOEZVny5bdze+9/ijqlqdnuebwEeAG1T1H8ra34k/e3qNqh5V1ecYfI/vLmB2UXDv5lwoMGqvZVtvD89s2czM+gPf4fKR22/m4VcG5+ocOmcuP7rqGsaTKrqrv59FrTNYURUPbDDsL0TkCPzr7rvxQwsUSAO/Am5W1XvGOe584C/4T8L+Q1U/UbV+Nb7zoVtVW4YZ42n8CcxvV9Vf7WZfY7p+5QoF7l/34rS4fhkMU4mOZJKjDlrInLJ89yOwz2s2jDmMQURsETlXRG4HduJ7PM/Cv9D+GN/7uUhVPzXRQneU7G6m8D1ABlhdFZbwFvxz8adyoQsQxKoVL9hvL7aLSJRBT+/uZiW/vap9WPtU9SngFaAFOLXGmIZRUh27u7ZtBw+sH1+sY3MizqudHaRNGWHDJEFVn1fVT6rqYuBM4Pv417aL8cOixkwQyvVbfKH7/WqhG7A5+NssIoka68EPYQMYX7C8wWAwTDCjFrsicpKIfAvYgX8xfRcQBn4HXIHviXyvqt6ve+Iu3nOK3tKnqleoag4/hhf8GNsR+1S1l/dZiZ+Sp0NVtw7tUuqzWEQa9nBfhjFy6Nx5vGHlYRVt333wftxxTDazxMK2LF7r6pwo8wyGieRP+DfPvwuWx+w1CZ7S/Ro4LBir5nwDVe1hUPAeXWOcg4AZ+MJ7/VjtMBgMhr3BiGJXRD4jIhvwH219EP9C9jzwcfxH/ueo6i2qut8z8AeisjFYrCVAy9vLPbsLq9btcZ9gpnLPBO3LMA7ef/rrscrCFl7t6uQ3Lzw7rrGa4jE2dXUa765h0hBkqvkG/jyG3+B7dfvw5yyMZZwIvgPjBPxKmZepqrubLncHf99ZY12x7XdlGRwMBoNhvzKaGTefDv62AbcCN6nq+BTD3qeu7P/DzRauNVN4pBnG4+lT7Nc0AfuqYLwTPLZt3TqtJnjMmzmTMw9exv0bN5TO3Xf/eD/Hz55HIZsb8zF1tu3gWcdhUVMLmUymdJ6j0SixWIzu7m5aW1tJJpPkcrnS+lgsRiQSoaenZ1TvU1dXF57nMXv2bNra2qgPYhSTySRz5sxh586dWJZFa2sr7e3tNDQ04LouAwMDpTFDoRBNTU10dHTQ1NRENju6iQPmmCb3Ma1fv57bb7+db3zjG+uAQ/C9uHl8AXoz8MuxiEwRsYHb8EPR/gS8I3gCtjuuD64/HxCR21X1kWCsQ/Cz8YA/b8JgMBgmBSNOUBORm/FjcX+nqvs94ejuJqgFGSG2BYuhWhO8guO5DPhXVf33oO23wJuAv1PV79fo80b8R4QbgkpyiMil+JPw/qKqrxvG1q3AfOBUVf1r0JYDQsAhtaodicgX8H8w/ltVr6leX7WtmaA2Att6unnnd/+TQln4wifOfivvPPb4MY/lqUdX/wCvW7acumh0Is00GHaI9WMsAAAgAElEQVTLt7/9bW655RYeffRRVJUgVOxhfIH7E1XdNZ5xReQf8MUrwF34nuFa/F9VXVfW78PAf+JP6v0dkAPeDMSCbT81in2bCWoGwwHAVJigNqJnV1Uv3xeGTBDlaXfi1L5wFydVJGv0iw8z7nj67K5f8xj3ZRgn85uaueDoY/nZk4+X2n7wlwc5d/WRRENjS2dsiUXItnils53VCxaO3MFgmCCuvfZaAJYvX85ll13Gpz/96aWq+uoEDN1c9v8LdrPdjUBJ7Krqt0RkI36axNfhh8Q9i5995tYJsMtgMBgmjD0uKjGZUNU+oDdYXDDMZrVmCm+uWrfHfYKZysXbnD3dl2EPeN+ppxMpy5Hb2d9fIX7HQmMszraebpKZ/R6ibphGXHvttTz66KOsW7eO6667jgkSuqjqZ1RVRvH6Y42+v1bV16tqg6rWqepJe1Poep5LausLJLeupZAxZbwNBsPoOaDEbkAxAfox1StEJASsqtput32q2sv7rAOywMwgN+VwfTYFInxP9mXYA2bU1XPxcSdWtP3o4T/Tn8mMeSwRIeI4bGjfOfLGBsME8c1vfpPjjx976M2BhHouhVQPhVQfyS1rx1UV0WAwTE8ORLG7u5nC5wJR4DlVLfec/hrwgNNEZFZ5h2Cm8tuCxVKCdFXN4JcHBrioxr6K+69Oqj6sfSJyNHAwflGJv9QY0zBOrjjpVBKRSGm5N53mlsceHtdYjbE4bb299KQGRt7YYDBMGCIWTqwOr5CmkBouvNhgMBgqORDF7vfxU36dJyLvKDYGIvY/gsWKmcKq2oY/0SMMfCco6VvkP/Crp90fFH0o56vB338LZiIX93Uy8H78WdLXV/X5ObAROFJEPlrWJwF8O1i8fqTqaYax0RSPc/mJp1S03frYw+MWrIlwmPVtbca7ZDDsB0RsE8pgMBhGzaQXuyLyVhF5pPgC7KD9kbLX3xa3V9Vu4L2AC9whIveLyM/wE5wvA27HF7bVfBR4CbgQWCcit4vIc/glf3cC76vuoKoP4AveVuAZEfm5iNwLPIRfcOIjqvpKVZ88cCl+6rGvB/b/BNgAnBz0/fK4TpZht1xy/Ek0xQbnBaZyOW58+M/jGqsuGqVroJ/OfjOP0GDY11hOmHyqd+QNDQaDgSkgdvG9qieWvYqUt1VM9lLVX+CX270Xv2LZufgTw67FT5g+xB0XpO45Afg6fpaKC/DL9n4fOLoq7KG838fxa9Q/h18++FT8fJXnqOp3h+nzGH5s7k/wwxbOw8++8GngzaPIc2kYB4lIhPeeUpkl7mdPPMbOvvH9aDbGory4Y/u4qrIZDIbxY4Wj5Pt3Ge+uwWAYFSPm2TVMXkye3bGTyee58Ls30J4c9Mi+85jj+cQ5bx3XeO3JPo6Yt4AFLa0TZaLBMBr2eZ7KiWas1690JsXdv/4xM2f684HzqT60kMeOJojPWowdjmGFoog1FXw4BsOBw1TIs2uuCoZpRTQU4urXnVHR9ss1T9GRHN9kl+Z4nHVtO8gVTIi1wbAvCcUbCDe0Akpy61p6Nj7FrvV/pXvDo/RtepZUx2vkU724+Syea76fBsN0xohdw7TjbauPYk5DY2k557r8+JG/jmuskO3gKbzS2TFR5hkMhjFgh2OE65oJ1zcTSjRhh6KoVyCzazt9r62h5+XH6X7pYXa99CiFtImxNximI0bsGqYdIdvhypMrY3fvfPoJuvrHF//XnIixqbNjXHl7DYZaHHPMMXz2s5+tuW7z5s2ISMs+NmlKICKI7WCFIr7nt67VF8J1LQgePa8+TWbXdpNFxWCYZhixa5iWvP3Io5lVFrucLRS45bHxeXf9MsI2L7W3TZR5hmnOM888w2uv1S6iuGTJEqhKn2gYGSfWQCjWwEDby/RvX4/n5ve3SQaDYR9hxK5hWhJ2HK446dSKtjuefHzceXeb4n6hie4BU2jCsHcJvJJTfoLa/sByQoTqWsj1ddKz8QlSHa8ZL6/BMA0wYtcwbTn/qGNpSSRKy+l8ntsee2Tc49VFIqzdsc38eBoMkxgRIVzXjB2Ok+rYxK71D9O3+QVSnVvwCsbbazAciBixa5i2REOhIVXVfvLkY/Sl0+MaLxGJ0JNOjztvr8Fg2HdYtkOkfgahWD1ePk2qbSPpLiN4DYYDESN2DdOaC485jsZYrLQ8kM3ykyceHfd4TfEYa02hCYNhyiCW5Wd0qG8l07WN7g2PMND+KvmBXgrZlP/KDOAV8uapjcEwRXH2twEGw/4kHo5w2Qkn850H7y+13f74I1x83Ik0lIng0RJxQvSmMmzv6eYgU2jCsAf09/ezefPm4VbXicjC4Vaq6rAdDbURyyJc34KqR2bXdjJd22pthR2NE22ag9ghLDuEFfYLWVh2aJ/bbDAYRoepoDaFMRXUJob+bIa3f/t6kmWpw46Yv4D/fPcVJCKRMY9XcF2SmQynL19J2DH3k4axY1kWIsPPQfO83T46UFWd9B+8sV6/UukB/vfem2iZMRdHLBwRLH+cUfX3VFEFV11ssbCrKq3565VsoYDruaj6bQCCEA05iAhuLoO4WRQoFArkXRdXFRCcRBN2tB71CljRehJNM8kXPJTiMSqWWFgiuJ6CKI5lYYlFLBwiZE/Ot63gubieh+dp6amV4p9PRUlEIjiWPa6xXc/DUw/Hskf9XlaTymXJFVwcyyJTyFP6SAmELIuw45DJ5/33GFAFq2xXIdsmbDso6r/nCpGQM+T9UFUGcllcz8MW/zsasm1CdqXtqkrBcxEExf9MFVz/OAXBVf8cWiIIgmUJVjBWwfXIBkWKRPzPXvGzUf2Z3VfUeo9UFTc4nu29PZy0ZOmkrqA2Ob9ZBsM+pC4S5ZLjT+J7f/pjqe25bVv56E9v4ZsXX04sHB7TeI5t43rKll1dLJ01e4KtNUwXRhCBu/uxOCAzNeRzGXofvwt39mLiy47HTjSjKBGxQZVCIMbAFysaCIWi8rHFQlHi4TDpfJ6c55adKMXCF8AN8TjxkF8sxrFtwrZNNp+nsz+JKjiRGNm878WNxh1mxeI0RKO+DZl+PLeAZdtkMp3kOnqps4SICBIK4amFU9eCROMkIjFEhIG8S8EOsSs1QG86HbzvMvguBoulv4Mmo2hJUEn5yvK+lPXHF3aO5R+rZUkgYHxhbwVCJpsvkHMDIe8pEcchGgphiUV9PFYaM2zbeKps6+4evDEYPOUV+/XN0VJz8V/HtnBsm0wuXbJbPfVzJheFFZQNWoniV7JsTdRR8JR4OERjLO4LR8+jI9nHQDbHnMYmQpZNIhLB9TxyhQKWWHjq0ZfJkMplcQIxaVk2Hcle/4akbE8iFk2xOA2xKLmCi+u5DORy9KXTlHKkBF1i4TCqHpZl0RCJEQ+HCQXOj+INTraQR1HyrovnKb3pNA3RCM3BxGnX8/BQOpNJelIpPPUGz54MPSWWCLZl4VgWnvrjhh072F4ouB6F4Eau+G4UPz+WSKkdBFVFLL8tbNs4tk1XdgAU/7Mj/mdHUeY2NI35d3JfYzy7Uxjj2Z04Mvk8H7z1Rzy3bWtF+3GLFvONd11KNDS2L7LreXSnBjhj+cox9zUYRsGUF7RjvX51tW/mxg8c6vcNxWh+4zUkFh1J1nOJhyNEHP8HGSBkOTi25QtAUWzLX2f7rjIcLGwRbAnyZAfrLfwf/6JHTURKAnCsqCpeIYdYNmLZeK4f85tLJykK8pJiESEUTeCEYkTqmgjF6rDsMOI4WFYIDTbLBWWPBz2AeVzPK3kYI06IkG3jqYdtWYGoc8m5BWyxyLkFugcGyBQK5Ap58q5LOp8DwMLCw79hqI9GaYrHiYXC1EdjNMfjWLvxKhZcl2yhgKpiWb630vU8MoU8tliBR1UpuC4iQiwUJh4OI4E4A8i7BVzPwxKLgWy2JKhEBE/947ADcQ6+OA87dinP+Xi9wsORD8R+8SmAJTLsOXA9j4LrlpZtyyp9FicKDZ48ZAp5kpkM2XyekOOUPp+eKqlslpxbIFdwsSwhHgqTCt7fgusRC4UQSwhZNo2xOJ56hGybdD6P63qEHJuI45Q+O2HHCTzXvkhP5/yxoiH/Zm8Pzvk+v34ZsTuFMWJ3YunPZPjQbTfx4o7tFe0nLjmYr110CRFnbDF5XQP9HNTUwqHz5k+kmQYDTEexu30jN354dWnZidbxuo98j0j92GLjVRVPwVUvcML5IqLKN1ptK45Y2AIiFo4EoidwwBYPoeh89f1xYGOh+PsqPja3gnnhxW0sLCz1UNcFddF8FlDs4BG34GeOiMYbiTXMwAlHsENhoolmZD891jYY9hAjdg2jx4jdiacvneZDt93EurYdFe2nLF3GVy5895hicD316Ozv5/RDVo4r9tdg2A3TTuzufPU5bv7YSRVty998NUtOe9fEG1dFUSAX41SLMjlYS/XbUR2BUHxUXGyjql0ZjCWlQnb7IhzPxSvkcdwcov61xXbCxOqasUMRnEicUCRO3s1TyKRQPESVUDhOoq6RkONPprOdECE7FHhMwUJG5Z3z4zNLtwZDbguKnvDqczBaz1/xMzCR3llVnXBvr2HCMGLXMHqM2N079KRSfPDWH7GhfWdF+xsPPZwvnn8hlozem9KTGmBmfQOrFww7cd5gGA9T/ld8rNev3s7t/PTz55Pcvp45h5/GguP+hubFR1QIms6Xn2TD735IpL6FxIwFJGYuZMGx5+ydA9jHeKqlSXYi4LkuhXwGz3NRt4Cq53uBLSeIkBA8t1CacKV+RAdONIblhLDDcZxoPeFIDNtxEMvGsmwsy/LFfRAeUSjkyRfyqJeHYgy0gOd64Ll+mEYogmXb2KEISBDviWA5DoIfhiBi+V5xy/K938H77uEfi6rnLyk4dgjHcbAC17mFf5OgxfMQ2Kaeh+u5frypWGjZ5CnFj2F1ykIlipMQy9dXI4H9xZhUS/BvdNSjfFaohR/iYouFZfnLHuq3IxQ8D8uqjKf2PK24TaoIxbYCLz9QwAMPLMsf08GPr0Z9++yy8JriJEEYvJEqri9+VooUv2oiVMQji1AWs1tJcdKeBufVEsELbiS07G/Edkoxz6PATFAzGPY3TfE4377kPXzglht5pbOj1P77tS8wq76Bj77x7FGP1RiLs627m4UtrTTFEyN3MBgMNYnVt7D8vI9SX9dAONFYcxs3l6Vv+wYAOtY/Sv2cpQeM2LWq44cti3Bo7OnOvEIOz/PQdC/5ZCeZssQeg75bX7z5f/20bNWzznxTfKGDCBIIIhGpmlA2KNBVQZxQ2ejgea4vmkWCfVuU/Mcivnguxop4impxYmFgR1E3WRaWFfKFm+2AemA7iB1GbAdV1+/jFdAg9lmCWFTLDgeqUBHLDo7LQ0JRxHKCVR6oop4fmyuhiL+tZYFY/v/F99crIJ4v4Cu81qq+aM7n8LxCoFQ1sEMQ2x9DCzl/kp4lCDaEQkgQEiOBjWLZ/vieF9ikaPBeimUjth3ErFfOZCsJVM/17Q7OsYjl33AUPfiBbX5/z18nln9uURAb1D8X2XyOg2cuoDE+eR1pRuwaDDVoTiT4zqVX8v6bf8hru7pK7bc+9jCzGxq49ISTRzWOiBAPh1nXtoMTlyw1j9UMhj3ADkWGFboAVlVcfbRx5rDbdm9+gUh9K/HmORNm31TAcsJB1HB0v+xfPXcw4wT+NbJW7LGWRLiWeSgHt60OU1Atij31hSmO35bPoLkyn6xYg2MUJ2/lMhXCrojnuoPLpewQgSj3yoRssB4t89wGnnQVCeK6BxV/9TEXhWXxvIglgccUykVs2dCDfavOW0nbBudmyE2Iv8OKsTRwMZeSSRTPa/ldSvVxlRkykOwhG68DI3YNhqlHa10dN7z7ct73ox/QNdBfar/+9/cxu76BNxx6+KjGqYtG2dnXR2d/kpn1DXvLXINh2jNasauey/N3fo1U1zacaB1zj3w9h5374X1h4rRHLHtUz7DLxWCt7asdByKBZ9Swz8nmJ3+JbSN2DYbdMK+pmW9efBnX3PxDUkHaFQU+/cs7aUnUcfTCRaMapzEW5cUd2zktUbfbFD4Gg6E2nippsYiqEqZ2vGXj/OWceM31pHbtIN3dRsP8Q2qO1b7uEVJBhbRCpp9CJlVzu3y6n4GOzYhlE4rXE0404UTiE3ZMBoNh32DErsEwAivmzOXL73gX//jTW0vVg3Kuy0d/div/79IrOXTuvBHHiIbCtCf72NHbw/zmlr1tssFwwJFxC/w13gI5P6ozinJGWIiXiV4nEqfpoEPJzV+J60GfwICrNAs0lpXM2vSXOyrGjrXMrbnPnq1reeqmfyst181azKnX/lfNbTtffpJ8qo9wohGxHOKt84k2mJLhBsNkwIhdg2EUnHTwMv71b97G5+7+RaltIJvl2tt/zPcuv4qDZ84acYymWJx1bTuY1dAwacuCGgyTFbcsbtADMgwfdbrNVV4pC3M83BYagwcqnlugaeHh5FN9DHT6RWRebJzHc1kPC/ibsBAuCuiqWMl0vJFH8x420GoJS+xBAb3lsbtpX/vX0rKzaDUNV34ZgMMcIRGMmc8M8PxdX8N2ImgoTH/rQupPvgALCCMsd2o/5M+p4gH+9K6JTdNlMBzomF9cg2GUvG310XQmk3znwftLbb1BXt7/vuJ9LBjBYxt2HPoyaTZ3mTLCBsNYKRe7APVSO5QBKtMtAZRHclq2w4qz/5YVZ/8thVyGezvbKcT9SW9u1bbVadEy8UZ6A/3roRVit5CtDIXoP+pseoJtlykkgk0zPe20v/iXweOasZC2Ey4AIIFWiN0Nf/gR3ZueJ1LfQn/9DNpXnIo3fyUARzmw1K59/L8PJmRZwev0UO1KcP2q7PIC8YxvY5M1dDtV5enC4GQsEVhhC7EaY6ZU2eQWC9FCXGDRMHZudZW+QMRbCPOs2vv3VNnqDaYfE4Yfs8NTdgYpvkIILRbMqjEmwKuukgsmZlnAQTZEahxTRpUOr5gbGcICM4cZs89TssH/FWgQiNYY01NlR3HuW/CaO8wxpVVJ6eD7GRMGb8iqSAXns/jRTQzzPSmokmFwTAdwhhkzWXZM4H/3ap2nyYwRuwbDGHjvKafRn81y0yODP1ad/f188NYf8d9XvI/ZDcPPFAdojid4uaOdeU3Nk76WuMEw2Yh6Lq5lkwcax/BbO4yzFEIR8q0LKprKI+qdaILGBSvwCgXSqT5yDTNK66qnQrm59OBCJEFh5amlxXLJnOnrrOinZRXgQlV29u/cRPemZwdta15QErvlm3pugSdu/CS5/h4KuTTZ1oPIXPbvpfXl2/ZsWUemZyfhuiY6oo08n2iFiJ8WcYkFxwQiTj2PQnaAfDpJbqCXbZk8uYWrSuMcbPmiCyDb30OmZydOJE6vE2GtFYOoP2ZrldjNp/v9tF4ibC4oO0KJUtqvuAhNpfOZId3bjohFAXhCw2hw/kMMHdNz/TzAHR6st6PghAFlKYNiV1Xx8lnUcxHb4SXPob/s7MyyhEiNz0pS4bHC4LvYKnBmuPaH6kVX2Vb2QOBER1hQY95cAXikbEwLuGAYsbvNhTXu4LZLbThqmA/1gzml/Lbr7LBQV2O7XQp/yg+OOceCU6s/gAFrXGXnKI5pMmPErsEwBkSED7/+jQzksvzvU0+U2nf09vKhW2/ie1dcRUui1qXFx7b8pOovt+/kiAUH7QuTDYYDgqZwhFPT3TQ2zyTL7rPSzxRBbMVV31tbP8zGWfwfwUKwXB0e0LL4CE56/w0AvFzQCsFR7QFuXrwaJ1qHei49Cw6HUO2qiZnejorlCrFbtW2FgIaS2CvaWjqO/l10b3qutCzRwRRQUnVMO9b8gc2P/nJwn2dcQf60S0vbFsln+nngSxeVlsORBLmPV8Y6F+l86TGev+trg9uecD65N79/yJgAj/zXP5Dq2jrY8LGfQqx+yDH1bnuJx//n46Xl6EGrSF/5FWBouq0Xf/WftD33x9Kyc97HKRxx1pAxMz07eejrV5aWNRSFT9xVWi63ddtTv+WVh25HLBvPdggd/nryJ7+z5jFtfOAWsskuxLJJewpnXFkS++W29m7bwIbf/Q+geJ4SnrOM3BuuHmInwEu//QFdrzwDQNZysE+9GHfZCUO2zSZ38cztn8cr5PHcAmI58L5vDn28AbQ9/ye2P/M73HyWHIKz4hQKx54L+IUzynnuzq+SG+j19+Epcu5H0brmIWP2bFnLru0vc8jKE4esm0wYsWswjBER4V/O/hvSuRz3Pj/odXltVxcfvu3HfPey99IQiw3bvzEWY2v3Lha2ttIYMzO7DYaxICIjZoidbwvzR5HgKiHCeREpVdRyd7PtHBtiIrj4McPlAlpEWHH235aWd7hKrmI/g/+fsewYVl/0STy3QDrTz0DTfGK2P26iymQ3l6lYthtmEGSSHSJ4Kjcc/GmvPgtuPluxrPHBp1EVNSvsKuntVZ6d8nEL2YHKbXf7iLtSVUk2hdYQu0MkbdmYlZHUNZDaacvscNV1ucrO8siEXKq3lLEDQBYdWXNMgLbnH6K/fdPg+pMuQqNDiwjl0310bXxqcH9lI1WL3VTXdvq2vTQ4Zrp/mG2Vns0vDi4GVexqkeraRsf6RwfHmbmkbJRKdr36LJmesiqihRy1yKeTZKtu4CYjRuwaRsRPnu2WgqX8ijJTK15norHE4rpzzyOdz/PA+rWl9g3tO/nHn97Cty65gni4tmdHRIiFQ6zbsYMTlhw87c+lwbC/kSDx/+6SAtaJUDfKR7fDxV4CxJrnEBtlIYvDzvtHcv27yPR2kuntYNGsuThha0gscbavUuw22janhKQkjMupFrutdU04lr9dU9m1yKrKWSvqcpRTrI5GxeP+6tRtLSI0Bd3j1de3KtsPLqSI2H5Z3AYp36xyu4gIMy1qv09aKX8X2ELCFvIoM8r2b4crb5MssTjEDmKBtdKzrm6luK+3baLBeaoOoan2wDd7eSwZjO8tUn2tj6C0BGMOEWNV2yZCYb8AHP5ExtIxOJXhcBKKUJLZUi3MK89pyAlh49/kDROCXKJJBrepOCbLLlWVm8wYsTuNcPMZvzxkYSCoYuOB5/llC91CqWyjugW/zSv4FWQGq3eDKk6ikfr5K4d8yaYbjmXzhfMu5GN33MYjr2wstT+3bSsf+9ntXH/xpUSc2uU866MxU2jCYDDslvrZi2H24iHt1aKpcf4hHHfVlwnHG3GiCSzbJjKMemlaeBheIUduoJfcQA+rmmfQFBoq88VycKIJnEi8lF94uAlx4UQjDfOWUcikcPNZZscTLHNq3zo40QROtA6/Mpqy2M3S5BSnaA1iO2HirQuC7TyaGmewuoadxTHDiaZAICsLwmFm1xjTcsKB4BU8t4BjWawexk7PK1Qszw+FOGSY/ReqPPDH2x514VrbVr1vKMcPM2b1e3xkNMLMGmNW/w5HwzHOiIwul/shkQhLR7ntySEhVmP/ItaQCm+TEam+ezJMHUQkKEE+uvfw1c0v8dhf76alOUiTVVUXu/yvv67YVvmly6eSWI5D/UGHD30sNA3J5HN85PabeXrL5or20w5Zzn+842KcYar6ZPI5XA9et+wQU2jCMFam/OOAsV6/ctkMjz12L00tI6f5MxhGg3pezVLFALlUH/mBXrzAARSuayJaFjNdzvZn/kAhmyp5OOceeRbh+FAnRi7V54cmBL+roVg9DfNqFz4Z6NpGPp307XQLJGYurDmmqtKz+QUsJ+xXp7Ns/yap1pidWxno2IwVxJPHmueQaJ1fc9uuV57BK3sK0LLkyCGe8eIxdbe9yhEnvZ1ZM0c9D2WfX7+M2J3CjPXH4rXNL/PoE38gVCPIfMjYCGVVvoMkMj6K4mYHACU2dyVOrA5bLBzbwrHs0t/p9Hi+P5Phg7f+iLVtOyra33zYKj739ndgD3NBbU/2cdSChcxtGvk9MRjKmPJfLiN2DYYDg95dbRyy8sRJLXZNGMM0YkZ9HccuWkw8uDst/4kpPv4pxi4pGoRW+X/9CRyD8tfzlFymn2y6DcdqQupa8SIxciqkcjn68hk8tLQTEYg4DtFQ6IAsqFAXjXLDu6/g/Tf/kFc6B4P1f/vi88TCYf71LW+rKf4bojHWt7cxu6HReHcNBoPBYNgLHHiqw7BbLJGJE1WxGNo0g0I2Tb6/DSsdomnOUuJzDiIUTZB3C2TzBbKFApl8jl2pAbr6k3SnUv4kA7GIh8NEQ6EDwgvcFI/z7Uvfw9/9+H/Y2t1dav/FM08RD4X56BvPHnKc0VCIvmSa9mQfcxqbqoc0GAwGg8Gwhxixa9gjRIRQNE4oGsct5Ni1/SV2bVtPJNFE05wlJBpmUBf143zmBxXGsvk8A7ksPakU7ck+ugYGUBQLIRoKEQuHsGRqejln1NXznUuv5G9v+h/ak32l9tsef4R4OMwHzjhrSJ+GaIz1O9uYVd9gvLsGw25Qr0A+3Y8dCk/7CbIGg2H0mJjdKcxYY94Guttof/VZ4o0z96pdAPlMilymn1A0QfO8ZSQaZw07EaDguvRnM/Sl07Qnk+wa6MdTRQTi4TCxUHjKeX5f6+rkmh//kF2pyvyTHznrTVxx0qlDtm/v6+PohYuMd9cwWqbWF6IGY71+FQoFntu4BreQI5/sxC3kAUUUsKzKlFZa+qe4s2AyroVl24jtIE4ES6SUa6bcCikNIoMDBteg6hOvQxYULc1yGByjuF3ZiKX9VrRV7UDK/icMzqcon0dR7KNauVzqVZaCargSyyNRfJ+q7S7+3Z/X6HLbqim3rXq74SyuPqbhPqN785hVFREp7Xt//waW2+GpVnxnervbWLHypEkds2vE7hRmMovdIoVchmyqj3CsjpYFK4jVt474pfU8j/5slp7UAO3JJF39SRQIOzaJSATHmhp1Cje0t/GBm2+kL1OZluYTZ7+Vdx57fEWbycxgGCPTTuwCpCROAlIAACAASURBVAt5f16B5+EWcoCSL+TB88vPalH8gp9esZj/Uz28Qh5Vj3xmgHxmgEyq1y8bVRK8iqeKZTtYdgjLsv30jMFPuqr4olosNMiwYuGHYxEIk+K7Iqp+YQMJxGZxPZXitkj5GfDUKzVo8CrOf3DxUB0qbotzLkAqBJJXNufCCwb1ggIaQz5A1Yq/yr7diWQN7Ku+YaiU/ZUSs9Y5kKrloeZpIPbLhHbxnA8zbvEcSLBSym4TRvrklT6bAlI1spaNW33zMZz0Ltpefkzl573iHEh5n/J9BcesxU/t8Oemct9lK6Tsxqiir5b2WX4sUnb8WvZZLm6V7eti+coTaJ1RWXp7Nxixaxg9U0HsFink0mRTfcQbZ9E092AisYZhPb3VuJ5HTyrFjt4e2vp6KLgeliUkwmGiocn9KPOF7Vv54K03kcpVVp/57Nsu4G+OOLKirb2vj2MWLmZ2YyMGwwhMS7E70XhuAfU8PNcvtZrPpijkMuSzA3iFvO8JDkSrW8jheS5uPoubzw7aXWW+WIJlObhufqjbtmLDQHkMcZVWelCLKSHFsrAsx08JCYhtY1n2YMpIBgV+cGIDe+zKFJNl5miQ67bUVukM9/8ivtAtTlIu5lRVrySyRYJCF6Xxi0rKGiKgym0rjeO5Ja+4p1r6bSjPCISWfehL/QfXFz33xX0pvigTsUr7lOCce8ExlESbFHPylr1hQZtUpd8sib3yscsoCv/hnDoCQaGmQRsGRXVgR/W64ntXfA+C7fx+HhLc0BSltFc8X1bxuAY9/CU7Sp5ayx9PKNUMLn1kpfg0oXSSK85bkVRvB7OWrCYxymIpYMSuYQxMJbFbJJvqw81nEcsiVj+DWONMQpEYTjiGE46O2uu7a6Cf7T099GXSiEBdJDJphe+Tr23iH35yM9nCYJJyS4QvXXARZ608rNSWDgTxqcuW7/dHVoZJz5T/gEwGsTsRlHu6qtvVc0tCtchgoR4AQT3Xz+UaFPrx3ALqFkrCUlXxCnncQh43l/Y9v/gOBF90eyUPtmWHsJ2wvz+xAMXN50pj+2J4iIuwynBqul0t2xfWVpBNx7JDiGUhWHheocIOCZ6+qVsonQu/3fIrk4n4fcVCLBvbCQV53f2bC/9GwasQnMEApZsP3wgLS/x9eepBUPXMU5eiaHTdfFk+XX+Ctlj+MfjvjwS2F28yBgskuHn/6UGFO734PhbywXtZPF+Bu7RWnAqV/7dsezCPffGcwKAAtuyqz0yh9FkC/AJQwfhWkFu3oo9qaazqsYv/t4Jz4HmF0rGLNej31qrPRcnD7NX+vs5ednQp09MoMGLXMHqmotgtop5HPpemkE0PPgISCEXihKJ1hCIJnEgMxwkhtoPthPxHi3aoooxlOpejqz/Jpq5OkpkM8UiYusjQxNf7m79s3MA//+w2CmWVZhzL4qsXXcKpSweTiu/s6+X4xQebqmqGkTBi1zAuigLa93D6BRNKwqjM21cUTpblYNnOqJ/ETTeKXlpVLfPKq+91B4pivXhTNFHncXcFMfYmRc9+eUyxf+MypkuSEbuG0TOVxW4tVNV/nFgolB4rlu5GRSo8DrYTxg5FsJ3Ak+GESeYKvNbTTTKTIxKOUB+L+8LYskseBLGsktdhX3P/uhf51F0/wyt7vyKOwzcvvpxjFy0GjHfXMGqm/IfDiF2DYdpixK5h9Iz1xyLZtY2dLz9FpK4Z9VxsJ4QzTLnfrq3rcfOZ4M7fZdbBR2JPklQ/xceDg4//vNIjNM9z6U9naEv20J1KYYlQF4lgieU/hhENHsk5WKGIPyM7FPFrpociviC2HcRygr/2kMeQe8Ldzz7DZ+/+eUVbPBzmO5e+h8Pn+cH97ck+jl24hFkNxrtrGBYjdg0Gw1TFiF3D6Bnrj8Ufb/wUT/7yhtLyEW+6iiPffHXNbe/43Hlkkl2l5Xf8212T1iM8HOlcjo7+Pnb09uB6imP5RSz8yRZeSTCr66JaNnO7VsCa2H6sVzFOzQ4Fwjj0/7d35mGWFeXB/71nuVvv3dOzMUszwwzINsMeQAQFBQOioMGVqIkhMQtGvnyfn0ZwyfNooolRPzVxe2ISiSIQRQ2u4AiiyL4IzAyzwSw90zM9vXffvb4/Tt3b994+t7uZ6e47ffv9PU89556qt+rUqbr3Pe+t81ZV8IrP9ceN4+II8rjB7JTsGnf7ow/xqZ/cXXaF1niCr/3hH7G6YxHJTJqhVIoNx63UbYSVaqixqyjKfGXO9ZduKrGAcCpe3xcmD4TKuuWy+aIhWM5Q7162/OoO2lecRMfKk2hetPKY8e2KRyKsal/Eca3tDKeS9A4PcXB4yBq+QiISm/ZodeCPZf2y8nny2RQUfN+MnVmbLyzuE7aIjoPjR3AjcV67vJ2B887hy799uCjRPzbKjd/+Jl9/5x+zqLEJ13F47MUXWDU8xIlLlxPx9KeqKIqiKEeCPkEXEI7rl51XM2CB4kzNAtUM4/3bHmXzr24vnh9/5uVc+Nabj6KWM4/rOLTEE7TEE3R1dDKcStE7PMSB4UFy+TwR1yXuR3Gd6n82g6Vm3MCEPQKX34LrRT6bIpca4doVbfT3dXHb1l1FmX0D/fzVf36Nz15xGU2NzbRG4uzpfpEDh/azYfVaOppbJ/wJURRFURRlctTYXUA4no/jRXBcF8fxJh3VLG4AYddydDw/VK5nx5Nl523L1lYt8/De52nuXIkXqd1qCY7j0ByP0xyPs6pjEUPJJIeGhzg0PETe5PGnYfgeCSKCuB64HtimvOHcs+nPwU+27yrKbesb4OZ7NvF3F56Jh8EFUtks9+54nBWtrSxrbScSS+B6UTw/ihuJ40WidiF86zJRshSNU+pWoRPeFEVRlAWI+uzOY2q9GoMxhu9+4o2M9vcU4y7708+z9IQzJ8jmc1lu/+hVZNNjtC1fx6JVJ3PuNTeFlpvPZccXQp8jcvl8heFrcESIR3wi7uz9J8zm83z4Fw/w0L79ZfGv6lrJh15+XnHXorwx9I+O0RD1Wd3aRmPEDybmlazRCYwv+l1cXnx84XvH8+w6nMESbq7r2z9AwYoWjusFri6OUzSSJxrOx4aLiqI+u4qizFvUZ1eZRxjD2Ve/j949mzm8ZwuH926l/bj1oaK9ezaTSQ4DcHjPZlw3fKQY4IFvfZzdv7s/WGfXj3H+mz/EsnVnT5BLjw3z5E++hheJ4voxYg2trL/gmtAyxwZ7SY8N4UZieH4UP5rA9aPFdNdxaE0kaE0kWLOok9FMmv7RUXoGB+lLjSA4xCMe0Soj3EeK5zh85BXnc9PPNrGlt68Yf++u3bwwMMi1J63jVV2riHou7Q0JRtNpnj1wgKjvs6K1jY7GRqLTNMZLV67IpsfI5EfGF5o3hZ2RCouiF/YjtZntDkriSLDkmx8tji57kRiuPz66XNxu1X5WFEVRlFqiTyLliBHHYdVpF7PqtIuB6jsJAXRvfaTsPNFafXQ5PTpEPpchPZohzWD51pKlcmODbHngjuJ5Q9vSqsbu5gfu4Jl7/7N4vuGKP+G0S98ZKnvvV99PLpcJ1vL1Ipz9B3/LSN5wYHCQvtFRAGKeD0MHGNjxWOAa4vlEW5fRtPLk0DKzY0PB6GgkVrZlJ0Dc9/jkqy7ixh/fy56h4WL89r4BPv2bR/jyY09x5QlreP2Ja1nckCARiZDOZdlx6CA7Dx1icXMTnY3NwRJrk4y8BqO2R+fzWzCW87ks6cwQqZH+YHS5sCuUlBjJdnemwprIXiSOF43jR+J4fnR8RNmL4M7wnwhFURRFKaDGrjJjTOZ24EWiNLYvZ/jwPoBJXSnSyeGy82o+vtl0slzOr+4LnKuQdb1oFUk4+MIz5DLj8hdFIzRF4ixtaSWZyTCUHKNncJC9e7bQc/+tRbm2Ey+oauzu/NEXGNz1BCA4kRhrX3cTzatPL6a3xqL8w6Wv4Ka7f8wpfc+QcnxS4jEsUTazjG89s5nbnt3Cy1cexyWrV3BKZwedDQnyxtA7PMz+gQF812VxcwvtiQYaolHcWXA5KGwPOt0R2+LEvHyO9NgQqeG+8c1CSgxjcQQvmiAaa8KPN+JH48URZM+PqfuEoiiKcsSosavMCSdf/FZOvvitjA4eYrDnReJN7VVls+mxsnO3ihGbzaTK5SLVDdhK2WoGtDGGXLZctnQVi5jvE/N9Opua8Xa30FMil0EYGB0jHp3o55tLjxauQD49hoS4cSxrauBTF2yg5/bvFON63EY2R5cBgd/ufS/u4b4X9wDwxvRmzhx+HseL4EeiHHf+H3Bg7Xns6+/DQWhNJOhobKQhEuWJ7/0TjuviesGI6hmv/dNQg3X4cDd93dvtaGyERHMnTYuOC22r6VCYmOe4HvjV+8fk8+RzGZIj/YwOHiSXy5b9efIiMSKxRiKJZiKxBmsIBy4paggriqIok6HGrjKnJJoXkWheNKnMVf/rP8ll02TTY+TSSWJNHeFltXRy9tU3kk0nyWaSxKvIAcQaW2nuXEU2kySXSePHEqFy+Wy6zG2ickOIMiqWY+tsaWdFWxs9Q0P0pQLjNup5xHyfXGq0TNaNhu9c1+5RZkBnnUnWAU6NEMmlIJfCpIb44oMPc/DFLGtaW+hqbeG4pgaWNSRojnjseqR8E4vTrriBsJK7tz7Eb+/8dPF87TlXcv51Hwy9/M+//D76urcXfXYvevvHaFt+wgS55HAf2x++Gz+awIvGiTd1sGz9OWUy4ji4TrTMj7qUXDZDJjlKcrhv3BC2yxn70QR+rJFoognfGsKeH9RJV6BQFEVR1NitISISBf4P8HagCxgA7gVuMcY8X8Oq1RQRCSY++VFoqC6XaF7ESRddN60yN15xAxuvuGHqa7seV9z4VXKZFPlshlwuU1W2bfkJvOwVbyaXSZPLpliyZiMr2jtY0d4R7IKWTNI7PEz/6CjG8RAvirGjxm4k3NgeHwEOOGHxEm464yy+u+V5dvYPlqVFTbmxPWaELb19ZRPdAJo9oXTlYyMuX37wIZY2JljV1s6qlmbikShRzyObSZflrWZ8AiSH+0mN9JMaKZYcKjfSf4DH7/6X4nnb8nVcuf7fQmWf/MnX2fXEz4gmmokkmll//jWsOPlCXC9YRcJnvN2GevfixxpBHNJjQySHesnnsnYyHYEhHGsgGmvCiURxXR8vErO727llK05gt4R2Znh7aEVRFKX2qLFbI6yh+3Pg5UA3cBeBwfsW4CoRucQY82jtargwcRyXRStfNi3ZxcdvYPHxG0LTYn6EmB+hs6mZXD7PKTd+lYGxMQ4NDjA4MsCwGyOdTJKIRMp8ayNNHSw5+2rymSS59Bix9uVctX4NV647nicPHOShffv5Xc8htvT2EakwdrOEG2jpdLlbRhLhE78e373NdxzaYlE64jHOHXyWU0tkt/YN0vf8NjrjCTobEyxqaCDuBy4Yle4e1QzjTMWoth8NN/QhWB5v6NAehuz5qtMuCZUz+Tx3/cNbglF4ESLxJt50y/fLRuGNMeRzGbq3PcrBXU/jR+M4rk/TohU0L15J2YoTdjLd2EAviOB6gWHsxxtxXA/XtetTF9aqdtwJy7WJOMXl2UQcqDhXA1pRFKU2qLFbOz5IYOj+BniNMWYYQERuAv4JuFVETjHGVN/mTJkXuI5DUyxOUyzOirZ2MrksI6kU/aOjHBoZIp3NIUDE84i1LWfFK94+oQwRYePSxWxcuhiAdC7H1oMX8lz3PrYe7GFHby/70uGv7LPiclvT2Xgmh2fyE8ZfM/k8PaNj9IyO4aVyOJFlVjbH47sP8+B3f1gmH3VdWqIR/rzvcNnA+8fue5Bo8zaao1Gao1EaIj5x38fdt60s/xgu23oPE/d9Yp5H3PeIeR6OCKmx8tHrSLwp9J7SyeFxdxM7Ca7S3UREcL0Ivbuf5Ykf/Wsx/tRL3xm6FjTAjz9/A6MD444kb/jgd4g3dZDPZchlUsFSbSbPgR1P8OgP/h+OE/gjL1p9Chte88fjk+6gOLq8/eG7Gex5ITCavQjHn3U5rcvWFg1lcTw8P0b7cevUIFYURZkF1NitASLiA++zp39RMHQBjDGfEZF3AqcDVwPfrUEVlVnEdz1aEx6tiQZWdywimckwnBp3eciTRxB818VzXXzXLW4uUSDiupy6dCmnLl0KBKOYh8eS7OgfYEffADv7B9jRP8CegSGSOXgk1jWtuj0dXcHT0RWTyqRyOXpGx/hk66vxyeGbIBzatoe87JsgvyQ7wDnxdURNlojJ0t2TYdPX/2OCXNR1+dPDW1lZEveBTQ/S+9heIq6D57hEXAffdWlOD3BhidwwPh/62S/wXQffCWR8N5BPbN9W5p/8zKHDbP3dszgieI6D5zjFz8mKVTueOjRALCk44uA5gYzjOAwOjzByuLsoF2ldwpjfiOsIjgiuSGBsi9Cz8ym6tzxYlF26/hzal6/D5HJksxmMMQz37qN16fG4k/loH2OoG9axxfQ255jJDTymWda0xGauXuaYq1eVeQNVo1/aPINJ73fS6h/pvVXPJxL8eT8W0R3UaoCIXAL8AthujJkwo0dEbgY+DnzDGPPuScqZ1g5E+WySfDZJd283u7t3Ek00A9Ao0FxlW9zevCFvixWgzQE3ZLJPxhhGSi7vAw1VyhzNG0o9YBMCfkiZeWMYLilTgKYqZaaMIV0iGxGIVpEdyZerhYQwwYgEyBpDskTQFYhXmeiUNIacGVdQUQEvRNYYw2jFPSVC6pnL5xlKpxlKpxlNp0lmM6RTacTky/I6TmCAZR0Hx5HgFbpAFHBKlKUxhsPJFHuHRtk3lqR7ZJRDo0kOjYyyb2CIQ2NJRjPl7hDRSATPHR9hTKYz5HLhLxga4uOrWhgDo8lkqJzveUT8cSWYyeZIZyb6QyfyKRb5kDAp4rk0u6Od9GYmfseXZAf4o4FfkzBpYibDPr+df1l8Bcl0ekKZrx96nJcntxfPf9pyBvfG14fe08cP3UXcjNfrk8ddx+F0foLc6ak9XD84bsA+E1/Fra0XkMlmJ8j+Sf99rM+MjxbfuvgyNruLgn4UwXWCb4/v+Tzytx9jVce0djis6cy7EDes+wkM3nOBYWBKN6zp6q9saoA9D3/26Cs9nYf7HBtmM1uWotSW1q7LaF35iumI6g5qC4SN9vhYlfRCfLhD6EtksPsh+nf9nKf91TwWWQfJ4OF9anoXZ2W2heb5SfxChp3xFQOuHX2AJjM2QW6f087P4uOvhJflenlN8vHQMu+PnsYL3pLi+cXJp+jK9UyQS+JzW8PFxfOoSfOW0ftCy3za7+KxyPj/hVPTOzkrsz1U9q4J9/QrmsxE42yv287PY9O7p1/Owj09X7gnu2LEqZHq93TnVPcksCoOnY3tHIqdyWpgdcU9DaXzHBjLsX80y4HRHAMrzsZtHx/dffTB+9i8axd9qRwDqTxZ+3yORSP8zR+Ou1yMJVN86t+/GVrP8049mUvPG1+B4VePP8k9Dz0yQW7UifKG666jrXncfeFz/3Ub/UPlay8f8Fq4bcN7uP7KKxjOZWnOpHjTwX6+efePJ5S5M9LJupXH0R51kWyai06/jD27Rnhu564JsiNujGi0EcllIJvhPW+8lk99644Jcq4pN4DXr1nDK7o2ht6TS7nsNZe/mn9+4LkJ90QqTS5T7t98DDO3bljqzaUoylGgxm5tWGWPe6qkF+JXz+xlp/9nauJ4Q/gIhNGVneY9TRGHpojDCS3BxLNNUZ8XStJv2thK12nLgWAUbihj6E/l6M95lP4FiHvCh85sYyiTZySTZyxrSOaCsKi5fF3hlojD0oRLMmsYyxlSuaMY4XK9INAfmvxUdAUnnvMqGtYcPx65655Q2c8tfR0feNf14xHJVKjcs5Fl/PyCG7ng1JdBLouJJuCFg6Gyv4yvp+3lb6DB9yCXwbQtA54Lv5V54LOrbliKosw31NitDY32WG0Yp7CYU+jsHBG5ASiuo7Vr1y46Ozvp7+8nk8mwbNkyuru7aWhowHVdBvuCpagqzQl5Ca/Q1KZVIJj01RwRmiMOSyg3diOu8M6Tm0PzPe03lr3GeOu6Rv6xa3z0OG8M6Vxg+P60waV0vP0rF3fiZBrJ5I0NkMkbRuLNlE5nW9vi8aEz24py2Tyk7eeOpnJVd96SKOtMgryBrIFc3rqjVGxb7DqwoSNCzkDWuvZkjSGX93DbFpNf3FWUje45RJMf/Kpyecjb+9oaW87Iaa8h0hw+2a6UgcOH2TWaK/6GI5EITU1N9Pb20tbWxtjYGMlkkq6urinLmkUuBFoJ3LDCXnncgRq7dcAca/0ZXRN7vj6xjvRP/2zcb/Uyw7tKEDm67ehnEzV25yHGmK8AXyn4vBUefA0N43PjSx+GXnIpA8kWmkVYlh8Mfk4CzS64TkvoNdpJEbOvag3gRxpxmbi0VIQ4zWaMwg+jQQxuNLzMhEPZK/aIH8P1Jsp6uDSWyEXJVS0zKh6NZnz0LeZ6uBJucCXIYkpkPb8RN2RrBV/iNJTIxQXcSHiZUUdImHE/Ud+L4boTZT1c4iVyEXJVy/Qdv1w29J4CpRgjR7bEx9TzG3CZuDubLzFiJXJRATcSbnxFHCmT9b0orjtR1sUtk4uQrVqm73jlsq6HK+OyLtbfG2iUPJTIntLZSiMTlyvrlmZ+USK3tNHjVRuWh17/fjfK7hLZPz55EateNlH9pXC5s0Su2c9z19XrQst8xungqRLZG05u40snhW8X/X1PGDGZ4qPsnmtOIJ5PkTOBAZ03hjxwYlcXkVjwXS/9DTc1BW3V0hL+O5hj5tQNy400s/rCW2aiKKZlFEzLbphbw0w3R1GUo0MnqNUAEfkM8H7gn40xN4WkbwCeAA4bY6puCzbdCR6KotQdNbN+VH8pinKUzLn+OvYdxOqTF+2x2hpPhfgXqqQriqLUiqNyw1IURZlr1I2hNjxpj+Er24/HP1klXVEUZV7ykuccDA6yePFient7yefzLFmyhP379xddO4aGhli6dCkHDhzAcRw6Ojro6emhubmZXC7HyMhIsUzf92ltbeXgwYO0traSSqUYGxub0ke6kB6LxYjH4/T19dHR0cHQ0BDpdLqYHo/HiUaj9Pf36z3pPek9HUNzDtSNoQbY2cw9BJM8zjDGPFGR/iTBBI83GmP+e5Jy9DWgoixM1I1BUZT5iroxLASMMRng8/b0iyJSnFlm16k8HdgKfL8G1VMURZkMdcNSFGVeoW4MteMTwKUEy/g8LyL3E6yrex6Bz9vbjDETt2NSFEWpLeqGpSjKvEJHdmuECdbAuhT4CDAEvB5YA9wGnDnVVpuKoig14lcEO3isFZGNIelvsscfzF2VFEVRqqM+u/OYgs+boigLD2Nqt3+hiHwMuAX4NcF2wSM2vrBd8FbglMneTqn+UpSFy1zrLzV25zH6sFCUhUuNjd0ocA+BG1Y3UOmGdfFUb6dUfynKwkWNXWVWEZFHjDFn17oeytGjfVk/zMe+tAbvB4C3Exi6g8C9wC3GmK2zdM15105KONqX9cWx3p86QU1RFEV5ydh5Bx+3QVEU5ZhFJ6gpiqIoiqIodYsauwuPr9S6AsqMoX1ZP2hfTg9tp/pB+7K+OKb7U312FUVRFEVRlLpFR3YVRVEURVGUukWNXUVRFEVRFKVuUWO3zhGRqIjcLCKbRSQpIgdE5Fsisq7Wdat3RGSTiJhJwluq5LtCRO4RkX4RGRKR34jIW6e41jIR+aqI7LH9vENE/lFEmifJ44jIX4nIEyIyKiKHROT7InLu0d77fEREzhKR/ysi/y0iewv9NI1854nID2z7jdr2/AsRqbqOpIi02P7ZYftrj4h8RUSWTnGtt9nvw5D9ftwjIpdPkedE+5s/YK+12eqEyFT3diygOqw2qP6af6gOmwRjjIY6DUCUYLF3A+wj2Ir4t/Z8CDir1nWs5wBssm19B/CNkHBeSJ6/sHkywI+A7wGjNu6TVa6zBjhgZZ62/bzdnj8LtIbkEStngD5bx01A3l77ylq3Xw3663u2PcrCFHleb9srb9vvDtueBri1Sp52YLOV2W774Xf2vBtYXSXfp63MqK3rj+21DfBnVfKcCwxbmd/aa3Xb801ApNbtPkX7qg6rXdur/ppnQXXYJPdZ687RMHsB+Kj9QvwaaCyJv8nGbwbcWtezXkPJw6JrmvLr7A8/CZxfEr8eOGTLumiS63yuJM4D/tvGfy0kz7ts2lZgSUn8G218L9BS6zac4/76APAx4CpgCZCd7EEBtJU8FK4tiV8CPG/j3xGS7xs27U7AK4n/vI3/eUieS2zaIWBdSfz5QApIA2sq8ngl9Xh/SXyj1QkG+HCt232KPlEdVru2V/01z4LqsEnaptado2F2AuCXfInPCEl/0qZdU+u61ms4gofFF6z8Z0PS3m/T7qqIP9vGHwCiFWlLrALJAp0VaYV/4W8IudZdlcplIYZpPCj+xrbT90LSrrFpT4b0Sc4q9yUVaVGgJ+w3C/zQxv91yLU+R4WxYOPfZOOfCMlzZolR4FW7xxq3v+qw2ra/6q95HlSHjQf12a1fLgRage3GmMdD0u+wx6vnrkrKFFxlj3eEpBXiXiPBNq2VeX5ggh2tihhjDhC8AnaB3y/Ei0gXcAowBvzPJNfS78bkTNZf/0MwwnW6iKwuiX8twVyJ+23/FLH99wN7Wmx7EYkBl01yrWr9VbV+xpjHgB0EryMvDCnzWEB12PxC9df8Y8HoMDV265eN9vhYlfRC/IY5qMtC549E5Esi8gUReb+InFApICKtQEGhTHiwG2N2E7z+iQEnliQdST8X8vzOGJOZZh5lIlXb3hiTJhh9gvC2fyn9dRLBiMlBY8yeSfJ0VUzome86YL7Xv15Q/VW/LBgdpsZu/bLKHsO+WKXxq6ukKzPHzcB7CSZvfAbYIiKfExG3RKbQX33GmJEq5YT12ZH083Tz2Fz5FwAACc5JREFUtIlIUxWZBY1VyC32dDbaftp57Pelf4audSwx3+tfL6j+qkMWmg5TY7d+abTH0SrpBYWkymD2uA+4HlgLJAhGNP6WwNfpRuAfSmSn6i8I77Mj6efp5qnMp4zTWPJ5Ntr+peSZyWsdS8z3+s93VH/VNwtKh6mxqyizhDHmFmPMN40xO4wxY8aYrcaYTwBvsCLvE5EVtayjoihKGKq/lHpCjd36ZdgeE1XSG+xxaA7qopRgjPkp8AjBsioFp/2p+gvC++xI+nm6eSrzKeMMl3yejbZ/KXlm8lrHEvO9/nWJ6q+6YUHpMDV265cX7bHaP+9C/AtzUBdlIs/b4zJ7LPRXm4g0hMhDeJ8dST9PN0+fMUYfFiEYYwaBAXs6G20/7Tz2+9I6Q9c6lpjv9a9nVH/NcxaaDlNjt3550h7PrJJ+ZoWcMre02eMIgDGmn/Ef9hmVwiKyElhEsBTMlpKkI+nnwudTRcSfZh5lIlXb3rbrqRVyk+apiC/Ns5nAT7JTRI6bJM8u+wA7mmsdS8z3+tczqr/qgwWjw9TYrV9+RTC7ca2IbAxJf5M9/iAkTZlFRKQTuMiePlqS9EN7fBMTKcT9rGI9ykKe11WsX4mILLHXyQF3F+KNMTsJtuGMA1dOci39bkzOZP11FcEyS08bY0pHHX5EsC3nRSKyuDSD7b/X2dNi2xtjksA99vQPQq5Vrb+q1k9EziDYpvUw8EBImccCqsOOQVR/1RULR4fVeocPDbMXCLYNNPaL0FASX9hqcwvH6O5J8z0AFxBM5HAr4rsIHuKGYI1AKUkr3W7z9yriJ9tu85dU7FxE4E93p43/ekiedzO+3ebikvhrWcDbbVa00ZFutbmY8S0urw/J9+827Q7Kt9os7CJ0T0ieV1J9q80k4Vtt+sA2Jm612cD4Vps317qdp+gD1WG1aXfVX3UQVIeVlFXrztAwe4FgEeeCYtoH3AY8aM+HgbNqXcd6DYzv3d5NsBPNrbYvxmz8C8AJIfn+0qZnCEYzvkew7IoBPlnlWmsItts0wFPAt4Ht9vw5oDUkjwDfsTKHgduBXxD8Y88AV9W6DWvQZ1fa30chGBtK495Tkef19oGSB+617Vh4eHyLEmOgJE87gZFmrCL/NvC0Pd8PrK5Sv09bmRH7vbjb9pUB/qxKnnOtfOE+brO6wBAYGZFat/sUfaI6rDbtrvprHgbVYZO0Ta07R8PsBvuwuMV+MZME+1Z/G1hf67rVcwBeBnyJYNbyAYJ/rQPAw8CHwxR4Sd7XWsU9aB/oDwJvm+J6y4GvAnsJfKN2Af8ENE+SxwH+isDfacw+NH4InFvr9qtRn72r5OFQLXw0JN95tt0O23Z8kuCh70xyrRbbP7tsf+21/bdsijq+3X4fhu336V7g8inynGh/8z2M+0zeDERr3ebT7BfVYXPf5qq/5mFQHVY9iC1IURRFURRFUeoOnaCmKIqiKIqi1C1q7CqKoiiKoih1ixq7iqIoiqIoSt2ixq6iKIqiKIpSt6ixqyiKoiiKotQtauwqiqIoiqIodYsau4qiKIqiKErdosauoswwIvJKEblTRPaKSFpE+kRki4jcLiJ/KSItta6joihKGKq/lHpEN5VQlBlERG4BPmZPnwM2E2yHeCJwGsEfzPONMQ9a+U3AxcDxxphdc11fRVGUAqq/lHrFq3UFFKVeEJGzgI8SPByuM8Z8ryJ9KfAOoH/ua6coilId1V9KPaPGrqLMHNcCAnyn8kEBYIzZD/zjnNdKURRlalR/KXWL+uwqyszRaY89UwmKSJeIGIJXgAA7RcQUQoWsiMhbReRe6z+XFJHnROSjIpIIKXuTLadLRN4hIo+KyKiIHBSR/xCRFSF5RETeIiK/FJH9IpISkT32/MNH0BaKoswvVH8pdYsau4oyc+y2xzeKSOekkjAM/DtwwJ7fac8LAQARcYBbgf8CzgGeAO4GGoCPAL8QkXiVa/wN8B/2WncBQ8D1wG9FZFWF7N8D3wJ+D/idrc9m4ASCV5uKotQ3qr+U+sUYo0GDhhkIwBpgFDDAAPAN4D3AGYBbJc8mK99VJf1/2/RfAstK4iPA12za31cpMwP8fkm8Z+tkgB+WxMeAJDAIrK0oywEuqXXbatCgYXaD6i8N9Rx0NQZFmUFE5FLg34CVFUn9BCMPf2eM6S6R30SV2cwi4gHdQAI4oTSfTY8DO4AosMgYk68o87+MMW+vyNMGvEgwsrLWGLPTjuL0AE8YY8444ptXFGVeo/pLqVfUjUFRZhBjzD0Er86uBf4VeAzIAq3Ae4EnROTEaRZ3JrAI+HXlg8Jeawx4FGgD1oXk/3ZInj7gxwQTUV5u4w4SPEA2isgnROT4adZPUZQ6QvWXUq+osasoM4wxJm2M+a4x5r3GmLMIJn68F+gDFgNfmGZRXfZ4Wenkj4qJIFdamUUh+V+oUu4ue1xeEvdOAv+7DwI7RGS3iNwqItdavztFURYAqr+UekSXHlOUWcYY0w/8q4jsI5ho8UoRSRhjRqfIWlDS24AHppDtPco6bhKRdcDvA5cTvEZ8mw2/FJFXG2MyR3MNRVHmH6q/lHpAjV1FmTvutUeX4LXgVA+LPfa42RjzriO43mrgqSrxAPtKI40xQ8BtNiAipxO8SrwYeBfw1SOog6Io9YHqL2XeosP7ijJDiIhMIXKCPaaBQyWfIfyP58MEs6IvFpH2I6jSdSF1bAWusKeTjrYYY54i8NsDOPUIrq8oyjxB9ZdSz6ixqygzx9+JyKdFZG1lgogcB3zZnn7fGFN4SBRGJyZM+jDGpIBPAU3Ad6uVKyLXV6nPm0Xk8hJZD/iMLe9HxpgdNn6ViLxbRBoqynaB19jT3SiKUs+o/lLqFl16TFFmCBH5LPA+e7oVeJZg/ccVwHmAT+C/dokxZq/Ncy3BAuiDwE8JRkIwxrzHpjsEa0teT7Du5OPATlvWicDJwFPGmI0l9dhE8Orui8CfA/cRLAF0LsFamvuB8wtLBYnIRltuYXb0boK1K88jmASyDTjH+u4pilKHqP5S6hk1dhVlhhCRRQSv2C4HNhAo2haCB8FzBJM7vmSMGanI99fAnwBrCdacxBgjFTJXAzcQ7ELURjAzejdwD3CbMeaxEtlN2LUvgUsIHmAnASMEy/Z8yBjzYol8k73+K4FTgKUED44XgdttnfVBoSh1jOovpZ5RY1dR6ozJFnpXFEU5llH9pcwG6rOrKIqiKIqi1C1q7CqKoiiKoih1ixq7iqIoiqIoSt2iPruKoiiKoihK3aIju4qiKIqiKErdosauoiiKoiiKUreosasoiqIoiqLULWrsKoqiKIqiKHWLGruKoiiKoihK3fL/AbQFm/aRy9D6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDkr6ysQgHic"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}